{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682fca83",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5296b894",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /mnt/ssd/spack/opt/spack/linux-ubuntu16.04-haswell/gcc-7.5.0/libuuid-1.0.3-6o6eezlfuwg45vatkbt43theljdxxcks/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2022-03-02 19:54:44--  https://cloud.tsinghua.edu.cn/f/6e59181fd26d4a2dbad9/?dl=1\n",
      "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.8.7\n",
      "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.8.7|:443... connected.\n",
      "WARNING: cannot verify cloud.tsinghua.edu.cn's certificate, issued by ‘CN=R3,O=Let's Encrypt,C=US’:\n",
      "  Issued certificate has expired.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/44961d2b-5c12-421c-a54e-ca05b11a3db7/SHREC11-MAPS-48-4-split10.zip [following]\n",
      "--2022-03-02 19:54:45--  https://cloud.tsinghua.edu.cn/seafhttp/files/44961d2b-5c12-421c-a54e-ca05b11a3db7/SHREC11-MAPS-48-4-split10.zip\n",
      "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.8.7|:443... connected.\n",
      "WARNING: cannot verify cloud.tsinghua.edu.cn's certificate, issued by ‘CN=R3,O=Let's Encrypt,C=US’:\n",
      "  Issued certificate has expired.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2172924462 (2.0G) [application/zip]\n",
      "Saving to: ‘SHREC11-MAPS-48-4-split10.zip’\n",
      "\n",
      "SHREC11-MAPS-48-4-s 100%[===================>]   2.02G  35.4MB/s    in 61s     \n",
      "\n",
      "2022-03-02 19:55:45 (34.0 MB/s) - ‘SHREC11-MAPS-48-4-split10.zip’ saved [2172924462/2172924462]\n",
      "\n",
      "downloaded the data and putting it in:  ./data\n",
      "unzipping\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet && ./get_data.sh && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246f9d8",
   "metadata": {},
   "source": [
    "## 1. Expr: subdivnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d54e9f",
   "metadata": {},
   "source": [
    "### Generate Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8581173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\r\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet && python gen_data.py data/SHREC11-MAPS-48-4-split10/ants/test/1-0.obj && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d0feb",
   "metadata": {},
   "source": [
    "### Free Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fdd5fe",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "040dc9cc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Inference:\r\n",
      "func(adj, x, w0, w1, w2, w3, y) {\r\n",
      "adj:\r\n",
      "  [in] [CPU] adj: i32[12288, 3] {\r\n",
      "x:\r\n",
      "    [in] [CPU] x: f32[12288, 13] {\r\n",
      "w0:\r\n",
      "      [in] [CPU] w0: f32[13, 64] {\r\n",
      "w1:\r\n",
      "        [in] [CPU] w1: f32[13, 64] {\r\n",
      "w2:\r\n",
      "          [in] [CPU] w2: f32[13, 64] {\r\n",
      "w3:\r\n",
      "            [in] [CPU] w3: f32[13, 64] {\r\n",
      "y:\r\n",
      "              [out] [CPU] y: f32[12288, 64] {\r\n",
      "                for i in 0 : 12288 : 1 {\r\n",
      "y$1:\r\n",
      "                  [cache] [CPU] y$1: f32[13] {\r\n",
      "recur:L_elem:\r\n",
      "                    for recur:i in 0 : 13 : 1 {\r\n",
      "                      y$1[recur:i] = 0\r\n",
      "                    }\r\n",
      "y$2:\r\n",
      "                    [cache] [CPU] y$2: f32[13] {\r\n",
      "recur$1:L_elem:\r\n",
      "                      for recur$1:i in 0 : 13 : 1 {\r\n",
      "                        y$2[recur$1:i] = 0\r\n",
      "                      }\r\n",
      "y$3:\r\n",
      "                      [cache] [CPU] y$3: f32[13] {\r\n",
      "recur$2:L_elem:\r\n",
      "                        for recur$2:i in 0 : 13 : 1 {\r\n",
      "                          y$3[recur$2:i] = 0\r\n",
      "                        }\r\n",
      "                        for p in 0 : 3 : 1 {\r\n",
      "L_elem:\r\n",
      "                          for i$1 in 0 : 13 : 1 {\r\n",
      "                            assert ((13 == 13) || (13 == 1)) {\r\n",
      "                              y$1[i$1] = (x[adj[i, p], (i$1 % 13)] + y$1[i$1])\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "out:\r\n",
      "                          [cache] [CPU] out: f32[max(13, 13)] {\r\n",
      "recur$4:L_elem:\r\n",
      "                            for recur$4:i in 0 : max(13, 13) : 1 {\r\n",
      "                              assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                  out[recur$4:i] = (x[adj[i, p], (recur$4:i % 13)] - x[adj[i, ((p + 1) % 3)], (recur$4:i % 13)])\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "y$4:\r\n",
      "                            [cache] [CPU] y$4: f32[max(13, 13)] {\r\n",
      "                              assert (max(13, 13) == max(13, 13)) {\r\n",
      "recur$5:L_elem:\r\n",
      "                                for recur$5:i in 0 : max(13, 13) : 1 {\r\n",
      "                                  y$4[recur$5:i] = abs(out[recur$5:i])\r\n",
      "                                }\r\n",
      "L_elem$1:\r\n",
      "                                for i$2 in 0 : 13 : 1 {\r\n",
      "                                  assert ((max(13, 13) == 13) || (max(13, 13) == 1)) {\r\n",
      "                                    y$2[i$2] = (y$4[(i$2 % max(13, 13))] + y$2[i$2])\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "out$1:\r\n",
      "                                [cache] [CPU] out$1: f32[max(13, 13)] {\r\n",
      "recur$7:L_elem:\r\n",
      "                                  for recur$7:i in 0 : max(13, 13) : 1 {\r\n",
      "                                    assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                      assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                        out$1[recur$7:i] = (x[adj[i, p], (recur$7:i % 13)] - x[i, (recur$7:i % 13)])\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "y$5:\r\n",
      "                                  [cache] [CPU] y$5: f32[max(13, 13)] {\r\n",
      "                                    assert (max(13, 13) == max(13, 13)) {\r\n",
      "recur$8:L_elem:\r\n",
      "                                      for recur$8:i in 0 : max(13, 13) : 1 {\r\n",
      "                                        y$5[recur$8:i] = abs(out$1[recur$8:i])\r\n",
      "                                      }\r\n",
      "L_elem$2:\r\n",
      "                                      for i$3 in 0 : 13 : 1 {\r\n",
      "                                        assert ((max(13, 13) == 13) || (max(13, 13) == 1)) {\r\n",
      "                                          y$3[i$3] = (y$5[(i$3 % max(13, 13))] + y$3[i$3])\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "einsum:Y:\r\n",
      "                        [cache] [CPU] einsum:Y: f32[64] {\r\n",
      "                          assert ((64 == 64) || (64 == 1)) {\r\n",
      "                            // prefer libs\r\n",
      "                            for einsum:i in 0 : max(64, 64) : 1 {\r\n",
      "                              einsum:Y[(einsum:i % 64)] = 0\r\n",
      "                              assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                // prefer libs\r\n",
      "                                for einsum:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                  einsum:Y[(einsum:i % 64)] = (einsum:Y[(einsum:i % 64)] + (x[i, (einsum:i$1 % 13)] * w0[(0 + (einsum:i$1 % (13 - 0))), (einsum:i % 64)]))\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "einsum$1:Y:\r\n",
      "                            [cache] [CPU] einsum$1:Y: f32[64] {\r\n",
      "                              assert ((64 == 64) || (64 == 1)) {\r\n",
      "                                // prefer libs\r\n",
      "                                for einsum$1:i in 0 : max(64, 64) : 1 {\r\n",
      "                                  einsum$1:Y[(einsum$1:i % 64)] = 0\r\n",
      "                                  assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                    // prefer libs\r\n",
      "                                    for einsum$1:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                      einsum$1:Y[(einsum$1:i % 64)] = (einsum$1:Y[(einsum$1:i % 64)] + (y$1[(einsum$1:i$1 % 13)] * w1[(0 + (einsum$1:i$1 % (13 - 0))), (einsum$1:i % 64)]))\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "einsum$2:Y:\r\n",
      "                                [cache] [CPU] einsum$2:Y: f32[64] {\r\n",
      "                                  assert ((64 == 64) || (64 == 1)) {\r\n",
      "                                    // prefer libs\r\n",
      "                                    for einsum$2:i in 0 : max(64, 64) : 1 {\r\n",
      "                                      einsum$2:Y[(einsum$2:i % 64)] = 0\r\n",
      "                                      assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                        // prefer libs\r\n",
      "                                        for einsum$2:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                          einsum$2:Y[(einsum$2:i % 64)] = (einsum$2:Y[(einsum$2:i % 64)] + (y$2[(einsum$2:i$1 % 13)] * w2[(0 + (einsum$2:i$1 % (13 - 0))), (einsum$2:i % 64)]))\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "einsum$3:Y:\r\n",
      "                                    [cache] [CPU] einsum$3:Y: f32[64] {\r\n",
      "                                      assert ((64 == 64) || (64 == 1)) {\r\n",
      "                                        // prefer libs\r\n",
      "                                        for einsum$3:i in 0 : max(64, 64) : 1 {\r\n",
      "                                          einsum$3:Y[(einsum$3:i % 64)] = 0\r\n",
      "                                          assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                              einsum$3:Y[(einsum$3:i % 64)] = (einsum$3:Y[(einsum$3:i % 64)] + (y$3[(einsum$3:i$1 % 13)] * w3[(0 + (einsum$3:i$1 % (13 - 0))), (einsum$3:i % 64)]))\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "out$2:\r\n",
      "                                        [cache] [CPU] out$2: f32[max(64, 64)] {\r\n",
      "recur$10:L_elem:\r\n",
      "                                          for recur$10:i in 0 : max(64, 64) : 1 {\r\n",
      "                                            assert ((64 == max(64, 64)) || (64 == 1)) {\r\n",
      "                                              assert ((64 == max(64, 64)) || (64 == 1)) {\r\n",
      "                                                out$2[recur$10:i] = (einsum:Y[(recur$10:i % 64)] + einsum$1:Y[(recur$10:i % 64)])\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "out$3:\r\n",
      "                                          [cache] [CPU] out$3: f32[max(max(64, 64), 64)] {\r\n",
      "recur$11:L_elem:\r\n",
      "                                            for recur$11:i in 0 : max(max(64, 64), 64) : 1 {\r\n",
      "                                              assert ((max(64, 64) == max(max(64, 64), 64)) || (max(64, 64) == 1)) {\r\n",
      "                                                assert ((64 == max(max(64, 64), 64)) || (64 == 1)) {\r\n",
      "                                                  out$3[recur$11:i] = (out$2[(recur$11:i % max(64, 64))] + einsum$2:Y[(recur$11:i % 64)])\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "out$4:\r\n",
      "                                            [cache] [CPU] out$4: f32[max(max(max(64, 64), 64), 64)] {\r\n",
      "recur$12:L_elem:\r\n",
      "                                              for recur$12:i in 0 : max(max(max(64, 64), 64), 64) : 1 {\r\n",
      "                                                assert ((max(max(64, 64), 64) == max(max(max(64, 64), 64), 64)) || (max(max(64, 64), 64) == 1)) {\r\n",
      "                                                  assert ((64 == max(max(max(64, 64), 64), 64)) || (64 == 1)) {\r\n",
      "                                                    out$4[recur$12:i] = (out$3[(recur$12:i % max(max(64, 64), 64))] + einsum$3:Y[(recur$12:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "L_elem$3:\r\n",
      "                                              for i$4 in 0 : 64 : 1 {\r\n",
      "                                                assert ((max(max(max(64, 64), 64), 64) == 64) || (max(max(max(64, 64), 64), 64) == 1)) {\r\n",
      "                                                  y[i, i$4] = out$4[(i$4 % max(max(max(64, 64), 64), 64))]\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "func(adj, x, w0, w1, w2, w3, y) {\r\n",
      "adj:\r\n",
      "  [in] [CPU] adj: i32[12288, 3] {\r\n",
      "x:\r\n",
      "    [in] [CPU] x: f32[12288, 13] {\r\n",
      "w0:\r\n",
      "      [in] [CPU] w0: f32[13, 64] {\r\n",
      "w1:\r\n",
      "        [in] [CPU] w1: f32[13, 64] {\r\n",
      "w2:\r\n",
      "          [in] [CPU] w2: f32[13, 64] {\r\n",
      "w3:\r\n",
      "            [in] [CPU] w3: f32[13, 64] {\r\n",
      "y:\r\n",
      "              [out] [CPU] y: f32[12288, 64] {\r\n",
      "                // parallel = openmp\r\n",
      "                for i in 0 : 12288 : 1 {\r\n",
      "y$1:\r\n",
      "                  [cache] [CPU] y$1: f32[13] {\r\n",
      "y$2:\r\n",
      "                    [cache] [CPU] y$2: f32[13] {\r\n",
      "y$3:\r\n",
      "                      [cache] [CPU] y$3: f32[13] {\r\n",
      "fused.fused.recur:L_elem.recur$1:L_elem.recur$2:L_elem:\r\n",
      "                        for recur:i in 0 : 13 : 1 {\r\n",
      "                          y$1[recur:i] = 0\r\n",
      "                          y$2[recur:i] = 0\r\n",
      "                          y$3[recur:i] = 0\r\n",
      "                        }\r\n",
      "                        // unroll\r\n",
      "                        for p in 0 : 3 : 1 {\r\n",
      "fused.fused.fused.fused.fused.fused.L_elem.recur$4:L_elem.recur$5:L_elem.L_elem$1.recur$7:L_elem.recur$8:L_elem.L_elem$2:\r\n",
      "                          for i$1 in 0 : 13 : 1 {\r\n",
      "                            y$1[i$1] += x[adj[i, p], i$1]\r\n",
      "                            y$2[i$1] += abs((x[adj[i, p], i$1] - x[adj[i, ((p + 1) %% 3)], i$1]))\r\n",
      "                            y$3[i$1] += abs((x[adj[i, p], i$1] - x[i, i$1]))\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "fused.fused.fused.fused.fused.fused.fused.#30.#36.#42.#48.recur$10:L_elem.recur$11:L_elem.recur$12:L_elem.L_elem$3:\r\n",
      "                        for einsum:i in 0 : 64 : 1 {\r\n",
      "einsum:Y:\r\n",
      "                          [cache] [CPU] einsum:Y: f32[1] {\r\n",
      "                            einsum:Y[0] = 0\r\n",
      "einsum$1:Y:\r\n",
      "                            [cache] [CPU] einsum$1:Y: f32[1] {\r\n",
      "                              einsum$1:Y[0] = 0\r\n",
      "einsum$2:Y:\r\n",
      "                              [cache] [CPU] einsum$2:Y: f32[1] {\r\n",
      "                                einsum$2:Y[0] = 0\r\n",
      "einsum$3:Y:\r\n",
      "                                [cache] [CPU] einsum$3:Y: f32[1] {\r\n",
      "                                  einsum$3:Y[0] = 0\r\n",
      "fused.fused.fused.#27.#33.#39.#45:\r\n",
      "                                  for einsum:i$1 in 0 : 13 : 1 {\r\n",
      "                                    einsum:Y[0] += (x[i, einsum:i$1] * w0[einsum:i$1, einsum:i])\r\n",
      "                                    einsum$1:Y[0] += (y$1[einsum:i$1] * w1[einsum:i$1, einsum:i])\r\n",
      "                                    einsum$2:Y[0] += (y$2[einsum:i$1] * w2[einsum:i$1, einsum:i])\r\n",
      "                                    einsum$3:Y[0] += (y$3[einsum:i$1] * w3[einsum:i$1, einsum:i])\r\n",
      "                                  }\r\n",
      "                                  y[i, einsum:i] = (((einsum:Y[0] + einsum$1:Y[0]) + einsum$2:Y[0]) + einsum$3:Y[0])\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "\u001b[33m 1\u001b[0m \r\n",
      "\u001b[33m 2\u001b[0m #include <cpu_runtime.h>\r\n",
      "\u001b[33m 3\u001b[0m \r\n",
      "\u001b[33m 4\u001b[0m extern \"C\" {\r\n",
      "\u001b[33m 5\u001b[0m void __attribute__ ((noinline)) _run(void **_params, void **_returns, size_t **_retShapes, size_t *_retDims) {\r\n",
      "\u001b[33m 6\u001b[0m   const int32_t (*restrict adj)[3] = (int32_t(*)[3])_params[0];\r\n",
      "\u001b[33m 7\u001b[0m   const float (*restrict x)[13] = (float(*)[13])_params[1];\r\n",
      "\u001b[33m 8\u001b[0m   const float (*restrict w0)[64] = (float(*)[64])_params[2];\r\n",
      "\u001b[33m 9\u001b[0m   const float (*restrict w1)[64] = (float(*)[64])_params[3];\r\n",
      "\u001b[33m10\u001b[0m   const float (*restrict w2)[64] = (float(*)[64])_params[4];\r\n",
      "\u001b[33m11\u001b[0m   const float (*restrict w3)[64] = (float(*)[64])_params[5];\r\n",
      "\u001b[33m12\u001b[0m   float (*restrict y)[64] = (float(*)[64])_params[6];\r\n",
      "\u001b[33m13\u001b[0m #pragma omp parallel for\r\n",
      "\u001b[33m14\u001b[0m   for (int i = 0; i < 12288; i++) {\r\n",
      "\u001b[33m15\u001b[0m     float y_361[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m16\u001b[0m     float y_362[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m17\u001b[0m     float y_363[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m18\u001b[0m     for (int recur_58i = 0; recur_58i < 13; recur_58i++) {\r\n",
      "\u001b[33m19\u001b[0m       y_361[recur_58i] = 0;\r\n",
      "\u001b[33m20\u001b[0m       y_362[recur_58i] = 0;\r\n",
      "\u001b[33m21\u001b[0m       y_363[recur_58i] = 0;\r\n",
      "\u001b[33m22\u001b[0m     }\r\n",
      "\u001b[33m23\u001b[0m #pragma GCC unroll 3\r\n",
      "\u001b[33m24\u001b[0m     for (int p = 0; p < 3; p++) {\r\n",
      "\u001b[33m25\u001b[0m       for (int i_361 = 0; i_361 < 13; i_361++) {\r\n",
      "\u001b[33m26\u001b[0m         y_361[i_361] += x[adj[i][p]][i_361];\r\n",
      "\u001b[33m27\u001b[0m         y_362[i_361] += std::abs((x[adj[i][p]][i_361] - x[adj[i][((p + 1) % 3)]][i_361]));\r\n",
      "\u001b[33m28\u001b[0m         y_363[i_361] += std::abs((x[adj[i][p]][i_361] - x[i][i_361]));\r\n",
      "\u001b[33m29\u001b[0m       }\r\n",
      "\u001b[33m30\u001b[0m     }\r\n",
      "\u001b[33m31\u001b[0m     for (int einsum_58i = 0; einsum_58i < 64; einsum_58i++) {\r\n",
      "\u001b[33m32\u001b[0m       float einsum_58Y[1];\r\n",
      "\u001b[33m33\u001b[0m       einsum_58Y[0] = 0;\r\n",
      "\u001b[33m34\u001b[0m       {\r\n",
      "\u001b[33m35\u001b[0m         float einsum_361_58Y[1];\r\n",
      "\u001b[33m36\u001b[0m         einsum_361_58Y[0] = 0;\r\n",
      "\u001b[33m37\u001b[0m         {\r\n",
      "\u001b[33m38\u001b[0m           float einsum_362_58Y[1];\r\n",
      "\u001b[33m39\u001b[0m           einsum_362_58Y[0] = 0;\r\n",
      "\u001b[33m40\u001b[0m           {\r\n",
      "\u001b[33m41\u001b[0m             float einsum_363_58Y[1];\r\n",
      "\u001b[33m42\u001b[0m             einsum_363_58Y[0] = 0;\r\n",
      "\u001b[33m43\u001b[0m             for (int einsum_58i_361 = 0; einsum_58i_361 < 13; einsum_58i_361++) {\r\n",
      "\u001b[33m44\u001b[0m               einsum_58Y[0] += (x[i][einsum_58i_361] * w0[einsum_58i_361][einsum_58i]);\r\n",
      "\u001b[33m45\u001b[0m               einsum_361_58Y[0] += (y_361[einsum_58i_361] * w1[einsum_58i_361][einsum_58i]);\r\n",
      "\u001b[33m46\u001b[0m               einsum_362_58Y[0] += (y_362[einsum_58i_361] * w2[einsum_58i_361][einsum_58i]);\r\n",
      "\u001b[33m47\u001b[0m               einsum_363_58Y[0] += (y_363[einsum_58i_361] * w3[einsum_58i_361][einsum_58i]);\r\n",
      "\u001b[33m48\u001b[0m             }\r\n",
      "\u001b[33m49\u001b[0m             y[i][einsum_58i] = (((einsum_58Y[0] + einsum_361_58Y[0]) + einsum_362_58Y[0]) + einsum_363_58Y[0]);\r\n",
      "\u001b[33m50\u001b[0m           }\r\n",
      "\u001b[33m51\u001b[0m         }\r\n",
      "\u001b[33m52\u001b[0m       }\r\n",
      "\u001b[33m53\u001b[0m     }\r\n",
      "\u001b[33m54\u001b[0m   }\r\n",
      "\u001b[33m55\u001b[0m }\r\n",
      "\u001b[33m56\u001b[0m \r\n",
      "\u001b[33m57\u001b[0m void run(void **_params, void **_returns, size_t **_retShapes, size_t *_retDims, CPUContext_t _ctx) {\r\n",
      "\u001b[33m58\u001b[0m   _ctx->setStackLim(8388780);\r\n",
      "\u001b[33m59\u001b[0m   _run(_params, _returns, _retShapes, _retDims);\r\n",
      "\u001b[33m60\u001b[0m }\r\n",
      "\u001b[33m61\u001b[0m }\r\n",
      "Inference compiling time: 11.628365278244019s\r\n",
      "# Forward:\r\n",
      "func(adj, x, w0, w1, w2, w3, y) {\r\n",
      "adj:\r\n",
      "  [in] [CPU] adj: i32[12288, 3] {\r\n",
      "x:\r\n",
      "    [in] [CPU] x: f32[12288, 13] {\r\n",
      "w0:\r\n",
      "      [in] [CPU] w0: f32[13, 64] {\r\n",
      "w1:\r\n",
      "        [in] [CPU] w1: f32[13, 64] {\r\n",
      "w2:\r\n",
      "          [in] [CPU] w2: f32[13, 64] {\r\n",
      "w3:\r\n",
      "            [in] [CPU] w3: f32[13, 64] {\r\n",
      "y:\r\n",
      "              [out] [CPU] y: f32[12288, 64] {\r\n",
      "                for i in 0 : 12288 : 1 {\r\n",
      "y$1:\r\n",
      "                  [cache] [CPU] y$1: f32[13] {\r\n",
      "y$2:\r\n",
      "                    [cache] [CPU] y$2: f32[13] {\r\n",
      "y$3:\r\n",
      "                      [cache] [CPU] y$3: f32[13] {\r\n",
      "einsum:Y:\r\n",
      "                        [cache] [CPU] einsum:Y: f32[64] {\r\n",
      "recur:L_elem:\r\n",
      "                          for recur:i in 0 : 13 : 1 {\r\n",
      "                            y$1[recur:i] = 0\r\n",
      "                          }\r\n",
      "recur$1:L_elem:\r\n",
      "                          for recur$1:i in 0 : 13 : 1 {\r\n",
      "                            y$2[recur$1:i] = 0\r\n",
      "                          }\r\n",
      "recur$2:L_elem:\r\n",
      "                          for recur$2:i in 0 : 13 : 1 {\r\n",
      "                            y$3[recur$2:i] = 0\r\n",
      "                          }\r\n",
      "                          for p in 0 : 3 : 1 {\r\n",
      "out:\r\n",
      "                            [cache] [CPU] out: f32[max(13, 13)] {\r\n",
      "y$4:\r\n",
      "                              [cache] [CPU] y$4: f32[max(13, 13)] {\r\n",
      "L_elem:\r\n",
      "                                for i$1 in 0 : 13 : 1 {\r\n",
      "                                  assert ((13 == 13) || (13 == 1)) {\r\n",
      "                                    y$1[i$1] += x[adj[i, p], (i$1 % 13)]\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "recur$4:L_elem:\r\n",
      "                                for recur$4:i in 0 : max(13, 13) : 1 {\r\n",
      "                                  assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                    assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                      out[recur$4:i] = (x[adj[i, p], (recur$4:i % 13)] - x[adj[i, ((p + 1) % 3)], (recur$4:i % 13)])\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                                assert (max(13, 13) == max(13, 13)) {\r\n",
      "out$1:\r\n",
      "                                  [cache] [CPU] out$1: f32[max(13, 13)] {\r\n",
      "y$5:\r\n",
      "                                    [cache] [CPU] y$5: f32[max(13, 13)] {\r\n",
      "recur$5:L_elem:\r\n",
      "                                      for recur$5:i in 0 : max(13, 13) : 1 {\r\n",
      "                                        y$4[recur$5:i] = abs(out[recur$5:i])\r\n",
      "                                      }\r\n",
      "L_elem$1:\r\n",
      "                                      for i$2 in 0 : 13 : 1 {\r\n",
      "                                        assert ((max(13, 13) == 13) || (max(13, 13) == 1)) {\r\n",
      "                                          y$2[i$2] += y$4[(i$2 % max(13, 13))]\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "recur$7:L_elem:\r\n",
      "                                      for recur$7:i in 0 : max(13, 13) : 1 {\r\n",
      "                                        assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                          assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                            out$1[recur$7:i] = (x[adj[i, p], (recur$7:i % 13)] - x[i, (recur$7:i % 13)])\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                      assert (max(13, 13) == max(13, 13)) {\r\n",
      "recur$8:L_elem:\r\n",
      "                                        for recur$8:i in 0 : max(13, 13) : 1 {\r\n",
      "                                          y$5[recur$8:i] = abs(out$1[recur$8:i])\r\n",
      "                                        }\r\n",
      "L_elem$2:\r\n",
      "                                        for i$3 in 0 : 13 : 1 {\r\n",
      "                                          assert ((max(13, 13) == 13) || (max(13, 13) == 1)) {\r\n",
      "                                            y$3[i$3] += y$5[(i$3 % max(13, 13))]\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                          assert ((64 == 64) || (64 == 1)) {\r\n",
      "einsum$1:Y:\r\n",
      "                            [cache] [CPU] einsum$1:Y: f32[64] {\r\n",
      "                              // prefer libs\r\n",
      "                              for einsum:i in 0 : max(64, 64) : 1 {\r\n",
      "                                einsum:Y[(einsum:i % 64)] = 0\r\n",
      "                                assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                  // prefer libs\r\n",
      "                                  for einsum:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                    einsum:Y[(einsum:i % 64)] += (x[i, (einsum:i$1 % 13)] * w0[(0 + (einsum:i$1 % (13 - 0))), (einsum:i % 64)])\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                              assert ((64 == 64) || (64 == 1)) {\r\n",
      "einsum$2:Y:\r\n",
      "                                [cache] [CPU] einsum$2:Y: f32[64] {\r\n",
      "                                  // prefer libs\r\n",
      "                                  for einsum$1:i in 0 : max(64, 64) : 1 {\r\n",
      "                                    einsum$1:Y[(einsum$1:i % 64)] = 0\r\n",
      "                                    assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                      // prefer libs\r\n",
      "                                      for einsum$1:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                        einsum$1:Y[(einsum$1:i % 64)] += (y$1[(einsum$1:i$1 % 13)] * w1[(0 + (einsum$1:i$1 % (13 - 0))), (einsum$1:i % 64)])\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                  assert ((64 == 64) || (64 == 1)) {\r\n",
      "einsum$3:Y:\r\n",
      "                                    [cache] [CPU] einsum$3:Y: f32[64] {\r\n",
      "                                      // prefer libs\r\n",
      "                                      for einsum$2:i in 0 : max(64, 64) : 1 {\r\n",
      "                                        einsum$2:Y[(einsum$2:i % 64)] = 0\r\n",
      "                                        assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$2:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                            einsum$2:Y[(einsum$2:i % 64)] += (y$2[(einsum$2:i$1 % 13)] * w2[(0 + (einsum$2:i$1 % (13 - 0))), (einsum$2:i % 64)])\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                      assert ((64 == 64) || (64 == 1)) {\r\n",
      "out$2:\r\n",
      "                                        [cache] [CPU] out$2: f32[max(64, 64)] {\r\n",
      "out$3:\r\n",
      "                                          [cache] [CPU] out$3: f32[max(max(64, 64), 64)] {\r\n",
      "out$4:\r\n",
      "                                            [cache] [CPU] out$4: f32[max(max(max(64, 64), 64), 64)] {\r\n",
      "                                              // prefer libs\r\n",
      "                                              for einsum$3:i in 0 : max(64, 64) : 1 {\r\n",
      "                                                einsum$3:Y[(einsum$3:i % 64)] = 0\r\n",
      "                                                assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                                  // prefer libs\r\n",
      "                                                  for einsum$3:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                                    einsum$3:Y[(einsum$3:i % 64)] += (y$3[(einsum$3:i$1 % 13)] * w3[(0 + (einsum$3:i$1 % (13 - 0))), (einsum$3:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "recur$10:L_elem:\r\n",
      "                                              for recur$10:i in 0 : max(64, 64) : 1 {\r\n",
      "                                                assert ((64 == max(64, 64)) || (64 == 1)) {\r\n",
      "                                                  assert ((64 == max(64, 64)) || (64 == 1)) {\r\n",
      "                                                    out$2[recur$10:i] = (einsum:Y[(recur$10:i % 64)] + einsum$1:Y[(recur$10:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "recur$11:L_elem:\r\n",
      "                                              for recur$11:i in 0 : max(max(64, 64), 64) : 1 {\r\n",
      "                                                assert ((max(64, 64) == max(max(64, 64), 64)) || (max(64, 64) == 1)) {\r\n",
      "                                                  assert ((64 == max(max(64, 64), 64)) || (64 == 1)) {\r\n",
      "                                                    out$3[recur$11:i] = (out$2[(recur$11:i % max(64, 64))] + einsum$2:Y[(recur$11:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "recur$12:L_elem:\r\n",
      "                                              for recur$12:i in 0 : max(max(max(64, 64), 64), 64) : 1 {\r\n",
      "                                                assert ((max(max(64, 64), 64) == max(max(max(64, 64), 64), 64)) || (max(max(64, 64), 64) == 1)) {\r\n",
      "                                                  assert ((64 == max(max(max(64, 64), 64), 64)) || (64 == 1)) {\r\n",
      "                                                    out$4[recur$12:i] = (out$3[(recur$12:i % max(max(64, 64), 64))] + einsum$3:Y[(recur$12:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "L_elem$3:\r\n",
      "                                              for i$4 in 0 : 64 : 1 {\r\n",
      "                                                assert ((max(max(max(64, 64), 64), 64) == 64) || (max(max(max(64, 64), 64), 64) == 1)) {\r\n",
      "                                                  y[i, i$4] = out$4[(i$4 % max(max(max(64, 64), 64), 64))]\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "func(adj, x, w0, w1, w2, w3, y) {\r\n",
      "adj:\r\n",
      "  [in] [CPU] adj: i32[12288, 3] {\r\n",
      "x:\r\n",
      "    [in] [CPU] x: f32[12288, 13] {\r\n",
      "w0:\r\n",
      "      [in] [CPU] w0: f32[13, 64] {\r\n",
      "w1:\r\n",
      "        [in] [CPU] w1: f32[13, 64] {\r\n",
      "w2:\r\n",
      "          [in] [CPU] w2: f32[13, 64] {\r\n",
      "w3:\r\n",
      "            [in] [CPU] w3: f32[13, 64] {\r\n",
      "y:\r\n",
      "              [out] [CPU] y: f32[12288, 64] {\r\n",
      "                // parallel = openmp\r\n",
      "                for i in 0 : 12288 : 1 {\r\n",
      "y$1:\r\n",
      "                  [cache] [CPU] y$1: f32[13] {\r\n",
      "y$2:\r\n",
      "                    [cache] [CPU] y$2: f32[13] {\r\n",
      "y$3:\r\n",
      "                      [cache] [CPU] y$3: f32[13] {\r\n",
      "fused.fused.recur:L_elem.recur$1:L_elem.recur$2:L_elem:\r\n",
      "                        for recur:i in 0 : 13 : 1 {\r\n",
      "                          y$1[recur:i] = 0\r\n",
      "                          y$2[recur:i] = 0\r\n",
      "                          y$3[recur:i] = 0\r\n",
      "                        }\r\n",
      "                        // unroll\r\n",
      "                        for p in 0 : 3 : 1 {\r\n",
      "fused.fused.fused.fused.fused.fused.L_elem.recur$4:L_elem.recur$5:L_elem.L_elem$1.recur$7:L_elem.recur$8:L_elem.L_elem$2:\r\n",
      "                          for i$1 in 0 : 13 : 1 {\r\n",
      "                            y$1[i$1] += x[adj[i, p], i$1]\r\n",
      "                            y$2[i$1] += abs((x[adj[i, p], i$1] - x[adj[i, ((p + 1) %% 3)], i$1]))\r\n",
      "                            y$3[i$1] += abs((x[adj[i, p], i$1] - x[i, i$1]))\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "fused.fused.fused.fused.fused.fused.fused.#30.#36.#42.#48.recur$10:L_elem.recur$11:L_elem.recur$12:L_elem.L_elem$3:\r\n",
      "                        for einsum:i in 0 : 64 : 1 {\r\n",
      "einsum:Y:\r\n",
      "                          [cache] [CPU] einsum:Y: f32[1] {\r\n",
      "                            einsum:Y[0] = 0\r\n",
      "einsum$1:Y:\r\n",
      "                            [cache] [CPU] einsum$1:Y: f32[1] {\r\n",
      "                              einsum$1:Y[0] = 0\r\n",
      "einsum$2:Y:\r\n",
      "                              [cache] [CPU] einsum$2:Y: f32[1] {\r\n",
      "                                einsum$2:Y[0] = 0\r\n",
      "einsum$3:Y:\r\n",
      "                                [cache] [CPU] einsum$3:Y: f32[1] {\r\n",
      "                                  einsum$3:Y[0] = 0\r\n",
      "fused.fused.fused.#27.#33.#39.#45:\r\n",
      "                                  for einsum:i$1 in 0 : 13 : 1 {\r\n",
      "                                    einsum:Y[0] += (x[i, einsum:i$1] * w0[einsum:i$1, einsum:i])\r\n",
      "                                    einsum$1:Y[0] += (y$1[einsum:i$1] * w1[einsum:i$1, einsum:i])\r\n",
      "                                    einsum$2:Y[0] += (y$2[einsum:i$1] * w2[einsum:i$1, einsum:i])\r\n",
      "                                    einsum$3:Y[0] += (y$3[einsum:i$1] * w3[einsum:i$1, einsum:i])\r\n",
      "                                  }\r\n",
      "                                  y[i, einsum:i] = (((einsum:Y[0] + einsum$1:Y[0]) + einsum$2:Y[0]) + einsum$3:Y[0])\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "\u001b[33m 1\u001b[0m \r\n",
      "\u001b[33m 2\u001b[0m #include <cpu_runtime.h>\r\n",
      "\u001b[33m 3\u001b[0m \r\n",
      "\u001b[33m 4\u001b[0m extern \"C\" {\r\n",
      "\u001b[33m 5\u001b[0m void __attribute__ ((noinline)) _run(void **_params, void **_returns, size_t **_retShapes, size_t *_retDims) {\r\n",
      "\u001b[33m 6\u001b[0m   const int32_t (*restrict adj)[3] = (int32_t(*)[3])_params[0];\r\n",
      "\u001b[33m 7\u001b[0m   const float (*restrict x)[13] = (float(*)[13])_params[1];\r\n",
      "\u001b[33m 8\u001b[0m   const float (*restrict w0)[64] = (float(*)[64])_params[2];\r\n",
      "\u001b[33m 9\u001b[0m   const float (*restrict w1)[64] = (float(*)[64])_params[3];\r\n",
      "\u001b[33m10\u001b[0m   const float (*restrict w2)[64] = (float(*)[64])_params[4];\r\n",
      "\u001b[33m11\u001b[0m   const float (*restrict w3)[64] = (float(*)[64])_params[5];\r\n",
      "\u001b[33m12\u001b[0m   float (*restrict y)[64] = (float(*)[64])_params[6];\r\n",
      "\u001b[33m13\u001b[0m #pragma omp parallel for\r\n",
      "\u001b[33m14\u001b[0m   for (int i = 0; i < 12288; i++) {\r\n",
      "\u001b[33m15\u001b[0m     float y_361[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m16\u001b[0m     float y_362[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m17\u001b[0m     float y_363[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m18\u001b[0m     for (int recur_58i = 0; recur_58i < 13; recur_58i++) {\r\n",
      "\u001b[33m19\u001b[0m       y_361[recur_58i] = 0;\r\n",
      "\u001b[33m20\u001b[0m       y_362[recur_58i] = 0;\r\n",
      "\u001b[33m21\u001b[0m       y_363[recur_58i] = 0;\r\n",
      "\u001b[33m22\u001b[0m     }\r\n",
      "\u001b[33m23\u001b[0m #pragma GCC unroll 3\r\n",
      "\u001b[33m24\u001b[0m     for (int p = 0; p < 3; p++) {\r\n",
      "\u001b[33m25\u001b[0m       for (int i_361 = 0; i_361 < 13; i_361++) {\r\n",
      "\u001b[33m26\u001b[0m         y_361[i_361] += x[adj[i][p]][i_361];\r\n",
      "\u001b[33m27\u001b[0m         y_362[i_361] += std::abs((x[adj[i][p]][i_361] - x[adj[i][((p + 1) % 3)]][i_361]));\r\n",
      "\u001b[33m28\u001b[0m         y_363[i_361] += std::abs((x[adj[i][p]][i_361] - x[i][i_361]));\r\n",
      "\u001b[33m29\u001b[0m       }\r\n",
      "\u001b[33m30\u001b[0m     }\r\n",
      "\u001b[33m31\u001b[0m     for (int einsum_58i = 0; einsum_58i < 64; einsum_58i++) {\r\n",
      "\u001b[33m32\u001b[0m       float einsum_58Y[1];\r\n",
      "\u001b[33m33\u001b[0m       einsum_58Y[0] = 0;\r\n",
      "\u001b[33m34\u001b[0m       {\r\n",
      "\u001b[33m35\u001b[0m         float einsum_361_58Y[1];\r\n",
      "\u001b[33m36\u001b[0m         einsum_361_58Y[0] = 0;\r\n",
      "\u001b[33m37\u001b[0m         {\r\n",
      "\u001b[33m38\u001b[0m           float einsum_362_58Y[1];\r\n",
      "\u001b[33m39\u001b[0m           einsum_362_58Y[0] = 0;\r\n",
      "\u001b[33m40\u001b[0m           {\r\n",
      "\u001b[33m41\u001b[0m             float einsum_363_58Y[1];\r\n",
      "\u001b[33m42\u001b[0m             einsum_363_58Y[0] = 0;\r\n",
      "\u001b[33m43\u001b[0m             for (int einsum_58i_361 = 0; einsum_58i_361 < 13; einsum_58i_361++) {\r\n",
      "\u001b[33m44\u001b[0m               einsum_58Y[0] += (x[i][einsum_58i_361] * w0[einsum_58i_361][einsum_58i]);\r\n",
      "\u001b[33m45\u001b[0m               einsum_361_58Y[0] += (y_361[einsum_58i_361] * w1[einsum_58i_361][einsum_58i]);\r\n",
      "\u001b[33m46\u001b[0m               einsum_362_58Y[0] += (y_362[einsum_58i_361] * w2[einsum_58i_361][einsum_58i]);\r\n",
      "\u001b[33m47\u001b[0m               einsum_363_58Y[0] += (y_363[einsum_58i_361] * w3[einsum_58i_361][einsum_58i]);\r\n",
      "\u001b[33m48\u001b[0m             }\r\n",
      "\u001b[33m49\u001b[0m             y[i][einsum_58i] = (((einsum_58Y[0] + einsum_361_58Y[0]) + einsum_362_58Y[0]) + einsum_363_58Y[0]);\r\n",
      "\u001b[33m50\u001b[0m           }\r\n",
      "\u001b[33m51\u001b[0m         }\r\n",
      "\u001b[33m52\u001b[0m       }\r\n",
      "\u001b[33m53\u001b[0m     }\r\n",
      "\u001b[33m54\u001b[0m   }\r\n",
      "\u001b[33m55\u001b[0m }\r\n",
      "\u001b[33m56\u001b[0m \r\n",
      "\u001b[33m57\u001b[0m void run(void **_params, void **_returns, size_t **_retShapes, size_t *_retDims, CPUContext_t _ctx) {\r\n",
      "\u001b[33m58\u001b[0m   _ctx->setStackLim(8388780);\r\n",
      "\u001b[33m59\u001b[0m   _run(_params, _returns, _retShapes, _retDims);\r\n",
      "\u001b[33m60\u001b[0m }\r\n",
      "\u001b[33m61\u001b[0m }\r\n",
      "# Backward:\r\n",
      "func(adj, x, w0, w1, w2, w3, y, x.grad, w0.grad, w1.grad, w3.grad, w2.grad, y.grad) {\r\n",
      "adj:\r\n",
      "  [in] [CPU] adj: i32[12288, 3] {\r\n",
      "x:\r\n",
      "    [in] [CPU] x: f32[12288, 13] {\r\n",
      "x.grad:\r\n",
      "      [out] [CPU] x.grad: f32[12288, 13] {\r\n",
      "w0:\r\n",
      "        [in] [CPU] w0: f32[13, 64] {\r\n",
      "w0.grad:\r\n",
      "          [out] [CPU] w0.grad: f32[13, 64] {\r\n",
      "w1:\r\n",
      "            [in] [CPU] w1: f32[13, 64] {\r\n",
      "w1.grad:\r\n",
      "              [out] [CPU] w1.grad: f32[13, 64] {\r\n",
      "w2:\r\n",
      "                [in] [CPU] w2: f32[13, 64] {\r\n",
      "w2.grad:\r\n",
      "                  [out] [CPU] w2.grad: f32[13, 64] {\r\n",
      "w3:\r\n",
      "                    [in] [CPU] w3: f32[13, 64] {\r\n",
      "w3.grad:\r\n",
      "                      [out] [CPU] w3.grad: f32[13, 64] {\r\n",
      "y:\r\n",
      "                        [in] [CPU] y: f32[12288, 64] {\r\n",
      "y.grad:\r\n",
      "                          [inout] [CPU] y.grad: f32[12288, 64] {\r\n",
      "                            for .x.grad.i0 in 12287 : -1 : -1 {\r\n",
      "                              for .x.grad.i1 in 12 : -1 : -1 {\r\n",
      "                                x.grad[.x.grad.i0, .x.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for .w0.grad.i0 in 12 : -1 : -1 {\r\n",
      "                              for .w0.grad.i1 in 63 : -1 : -1 {\r\n",
      "                                w0.grad[.w0.grad.i0, .w0.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for .w1.grad.i0 in 12 : -1 : -1 {\r\n",
      "                              for .w1.grad.i1 in 63 : -1 : -1 {\r\n",
      "                                w1.grad[.w1.grad.i0, .w1.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for .w2.grad.i0 in 12 : -1 : -1 {\r\n",
      "                              for .w2.grad.i1 in 63 : -1 : -1 {\r\n",
      "                                w2.grad[.w2.grad.i0, .w2.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for .w3.grad.i0 in 12 : -1 : -1 {\r\n",
      "                              for .w3.grad.i1 in 63 : -1 : -1 {\r\n",
      "                                w3.grad[.w3.grad.i0, .w3.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for i in 12287 : -1 : -1 {\r\n",
      "y$1:\r\n",
      "                              [cache] [CPU] y$1: f32[13] {\r\n",
      "y$1.grad:\r\n",
      "                                [cache] [CPU] y$1.grad: f32[13] {\r\n",
      "                                  for .y$1.grad.i0 in 12 : -1 : -1 {\r\n",
      "                                    y$1.grad[.y$1.grad.i0] = 0\r\n",
      "                                  }\r\n",
      "y$2:\r\n",
      "                                  [cache] [CPU] y$2: f32[13] {\r\n",
      "y$2.grad:\r\n",
      "                                    [cache] [CPU] y$2.grad: f32[13] {\r\n",
      "                                      for .y$2.grad.i0 in 12 : -1 : -1 {\r\n",
      "                                        y$2.grad[.y$2.grad.i0] = 0\r\n",
      "                                      }\r\n",
      "y$3:\r\n",
      "                                      [cache] [CPU] y$3: f32[13] {\r\n",
      "y$3.grad:\r\n",
      "                                        [cache] [CPU] y$3.grad: f32[13] {\r\n",
      "                                          for .y$3.grad.i0 in 12 : -1 : -1 {\r\n",
      "                                            y$3.grad[.y$3.grad.i0] = 0\r\n",
      "                                          }\r\n",
      "                                          for recur:i in 0 : 13 : 1 {\r\n",
      "                                            y$1[recur:i] = 0\r\n",
      "                                          }\r\n",
      "                                          for recur$1:i in 0 : 13 : 1 {\r\n",
      "                                            y$2[recur$1:i] = 0\r\n",
      "                                          }\r\n",
      "                                          for recur$2:i in 0 : 13 : 1 {\r\n",
      "                                            y$3[recur$2:i] = 0\r\n",
      "                                          }\r\n",
      "                                          for p in 0 : 3 : 1 {\r\n",
      "                                            for i$1 in 0 : 13 : 1 {\r\n",
      "                                              y$1[i$1] += x[adj[i, p], i$1]\r\n",
      "                                            }\r\n",
      "                                            [cache] [CPU] out: f32[13] {\r\n",
      "                                              for recur$4:i in 0 : 13 : 1 {\r\n",
      "                                                out[recur$4:i] = (x[adj[i, p], recur$4:i] - x[adj[i, ((p + 1) % 3)], recur$4:i])\r\n",
      "                                              }\r\n",
      "                                              [cache] [CPU] y$4: f32[13] {\r\n",
      "                                                for recur$5:i in 0 : 13 : 1 {\r\n",
      "                                                  y$4[recur$5:i] = abs(out[recur$5:i])\r\n",
      "                                                }\r\n",
      "                                                for i$2 in 0 : 13 : 1 {\r\n",
      "                                                  y$2[i$2] += y$4[i$2]\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                            [cache] [CPU] out$1: f32[13] {\r\n",
      "                                              for recur$7:i in 0 : 13 : 1 {\r\n",
      "                                                out$1[recur$7:i] = (x[adj[i, p], recur$7:i] - x[i, recur$7:i])\r\n",
      "                                              }\r\n",
      "                                              [cache] [CPU] y$5: f32[13] {\r\n",
      "                                                for recur$8:i in 0 : 13 : 1 {\r\n",
      "                                                  y$5[recur$8:i] = abs(out$1[recur$8:i])\r\n",
      "                                                }\r\n",
      "                                                for i$3 in 0 : 13 : 1 {\r\n",
      "                                                  y$3[i$3] += y$5[i$3]\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$1:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$1:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$2:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$2:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$3:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$1:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$1:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$2:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$2:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$3:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$2:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$2:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$3:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$3:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "einsum:Y.grad:\r\n",
      "                                          [cache] [CPU] einsum:Y.grad: f32[64] {\r\n",
      "einsum$1:Y.grad:\r\n",
      "                                            [cache] [CPU] einsum$1:Y.grad: f32[64] {\r\n",
      "einsum$2:Y.grad:\r\n",
      "                                              [cache] [CPU] einsum$2:Y.grad: f32[64] {\r\n",
      "einsum$3:Y.grad:\r\n",
      "                                                [cache] [CPU] einsum$3:Y.grad: f32[64] {\r\n",
      "out$2.grad:\r\n",
      "                                                  [cache] [CPU] out$2.grad: f32[64] {\r\n",
      "out$3.grad:\r\n",
      "                                                    [cache] [CPU] out$3.grad: f32[64] {\r\n",
      "out$4.grad:\r\n",
      "                                                      [cache] [CPU] out$4.grad: f32[64] {\r\n",
      "L_elem$3:\r\n",
      "                                                        for i$4 in 63 : -1 : -1 {\r\n",
      "                                                          out$4.grad[i$4] = y.grad[i, i$4]\r\n",
      "                                                        }\r\n",
      "recur$12:L_elem:\r\n",
      "                                                        for recur$12:i in 63 : -1 : -1 {\r\n",
      "                                                          out$3.grad[recur$12:i] = out$4.grad[recur$12:i]\r\n",
      "                                                          einsum$3:Y.grad[recur$12:i] = out$4.grad[recur$12:i]\r\n",
      "                                                        }\r\n",
      "                                                      }\r\n",
      "recur$11:L_elem:\r\n",
      "                                                      for recur$11:i in 63 : -1 : -1 {\r\n",
      "                                                        out$2.grad[recur$11:i] = out$3.grad[recur$11:i]\r\n",
      "                                                        einsum$2:Y.grad[recur$11:i] = out$3.grad[recur$11:i]\r\n",
      "                                                      }\r\n",
      "                                                    }\r\n",
      "recur$10:L_elem:\r\n",
      "                                                    for recur$10:i in 63 : -1 : -1 {\r\n",
      "                                                      einsum:Y.grad[recur$10:i] = out$2.grad[recur$10:i]\r\n",
      "                                                      einsum$1:Y.grad[recur$10:i] = out$2.grad[recur$10:i]\r\n",
      "                                                    }\r\n",
      "                                                  }\r\n",
      "                                                  // prefer libs\r\n",
      "                                                  for einsum$3:i in 63 : -1 : -1 {\r\n",
      "                                                    // prefer libs\r\n",
      "                                                    for einsum$3:i$1 in 12 : -1 : -1 {\r\n",
      "                                                      y$3.grad[einsum$3:i$1] += (einsum$3:Y.grad[einsum$3:i] * w3[einsum$3:i$1, einsum$3:i])\r\n",
      "                                                      w3.grad[einsum$3:i$1, einsum$3:i] += (einsum$3:Y.grad[einsum$3:i] * y$3[einsum$3:i$1])\r\n",
      "                                                    }\r\n",
      "                                                    einsum$3:Y.grad[einsum$3:i] = 0\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                                // prefer libs\r\n",
      "                                                for einsum$2:i in 63 : -1 : -1 {\r\n",
      "                                                  // prefer libs\r\n",
      "                                                  for einsum$2:i$1 in 12 : -1 : -1 {\r\n",
      "                                                    y$2.grad[einsum$2:i$1] += (einsum$2:Y.grad[einsum$2:i] * w2[einsum$2:i$1, einsum$2:i])\r\n",
      "                                                    w2.grad[einsum$2:i$1, einsum$2:i] += (einsum$2:Y.grad[einsum$2:i] * y$2[einsum$2:i$1])\r\n",
      "                                                  }\r\n",
      "                                                  einsum$2:Y.grad[einsum$2:i] = 0\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                              // prefer libs\r\n",
      "                                              for einsum$1:i in 63 : -1 : -1 {\r\n",
      "                                                // prefer libs\r\n",
      "                                                for einsum$1:i$1 in 12 : -1 : -1 {\r\n",
      "                                                  y$1.grad[einsum$1:i$1] += (einsum$1:Y.grad[einsum$1:i] * w1[einsum$1:i$1, einsum$1:i])\r\n",
      "                                                  w1.grad[einsum$1:i$1, einsum$1:i] += (einsum$1:Y.grad[einsum$1:i] * y$1[einsum$1:i$1])\r\n",
      "                                                }\r\n",
      "                                                einsum$1:Y.grad[einsum$1:i] = 0\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum:i in 63 : -1 : -1 {\r\n",
      "                                              // prefer libs\r\n",
      "                                              for einsum:i$1 in 12 : -1 : -1 {\r\n",
      "                                                x.grad[i, einsum:i$1] += (einsum:Y.grad[einsum:i] * w0[einsum:i$1, einsum:i])\r\n",
      "                                                w0.grad[einsum:i$1, einsum:i] += (einsum:Y.grad[einsum:i] * x[i, einsum:i$1])\r\n",
      "                                              }\r\n",
      "                                              einsum:Y.grad[einsum:i] = 0\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for p in 2 : -1 : -1 {\r\n",
      "out:\r\n",
      "                                            [cache] [CPU] out: f32[13] {\r\n",
      "                                              for recur$4:i in 0 : 13 : 1 {\r\n",
      "                                                out[recur$4:i] = (x[adj[i, p], recur$4:i] - x[adj[i, ((p + 1) % 3)], recur$4:i])\r\n",
      "                                              }\r\n",
      "                                              for recur$5:i in 0 : 13 : 1 {\r\n",
      "                                                /* empty */\r\n",
      "                                              }\r\n",
      "                                              for recur$7:i in 0 : 13 : 1 {\r\n",
      "                                                /* empty */\r\n",
      "                                              }\r\n",
      "                                              for recur$8:i in 0 : 13 : 1 {\r\n",
      "                                                /* empty */\r\n",
      "                                              }\r\n",
      "out$1:\r\n",
      "                                              [cache] [CPU] out$1.out$1: f32[13] {\r\n",
      "                                                for recur$7:i in 0 : 13 : 1 {\r\n",
      "                                                  out$1.out$1[recur$7:i] = (x[adj[i, p], recur$7:i] - x[i, recur$7:i])\r\n",
      "                                                }\r\n",
      "                                                for recur$8:i in 0 : 13 : 1 {\r\n",
      "                                                  /* empty */\r\n",
      "                                                }\r\n",
      "out$1.grad:\r\n",
      "                                                [cache] [CPU] out$1.grad: f32[13] {\r\n",
      "y$5.grad:\r\n",
      "                                                  [cache] [CPU] y$5.grad: f32[13] {\r\n",
      "L_elem$2:\r\n",
      "                                                    for i$3 in 12 : -1 : -1 {\r\n",
      "                                                      y$5.grad[i$3] = y$3.grad[i$3]\r\n",
      "                                                    }\r\n",
      "recur$8:L_elem:\r\n",
      "                                                    for recur$8:i in 12 : -1 : -1 {\r\n",
      "                                                      out$1.grad[recur$8:i] = ((out$1.out$1[recur$8:i] >= 0) ? y$5.grad[recur$8:i] : (0 - y$5.grad[recur$8:i]))\r\n",
      "                                                    }\r\n",
      "                                                  }\r\n",
      "recur$7:L_elem:\r\n",
      "                                                  for recur$7:i in 12 : -1 : -1 {\r\n",
      "                                                    x.grad[adj[i, p], recur$7:i] += out$1.grad[recur$7:i]\r\n",
      "                                                    x.grad[i, recur$7:i] += (0 - out$1.grad[recur$7:i])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "out.grad:\r\n",
      "                                              [cache] [CPU] out.grad: f32[13] {\r\n",
      "y$4.grad:\r\n",
      "                                                [cache] [CPU] y$4.grad: f32[13] {\r\n",
      "L_elem$1:\r\n",
      "                                                  for i$2 in 12 : -1 : -1 {\r\n",
      "                                                    y$4.grad[i$2] = y$2.grad[i$2]\r\n",
      "                                                  }\r\n",
      "recur$5:L_elem:\r\n",
      "                                                  for recur$5:i in 12 : -1 : -1 {\r\n",
      "                                                    out.grad[recur$5:i] = ((out[recur$5:i] >= 0) ? y$4.grad[recur$5:i] : (0 - y$4.grad[recur$5:i]))\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "recur$4:L_elem:\r\n",
      "                                                for recur$4:i in 12 : -1 : -1 {\r\n",
      "                                                  x.grad[adj[i, p], recur$4:i] += out.grad[recur$4:i]\r\n",
      "                                                  x.grad[adj[i, ((p + 1) % 3)], recur$4:i] += (0 - out.grad[recur$4:i])\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "L_elem:\r\n",
      "                                            for i$1 in 12 : -1 : -1 {\r\n",
      "                                              x.grad[adj[i, p], i$1] += y$1.grad[i$1]\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "recur$2:L_elem:\r\n",
      "                                          for recur$2:i in 12 : -1 : -1 {\r\n",
      "                                            y$3.grad[recur$2:i] = 0\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "recur$1:L_elem:\r\n",
      "                                      for recur$1:i in 12 : -1 : -1 {\r\n",
      "                                        y$2.grad[recur$1:i] = 0\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "recur:L_elem:\r\n",
      "                                  for recur:i in 12 : -1 : -1 {\r\n",
      "                                    y$1.grad[recur:i] = 0\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "func(adj, x, w0, w1, w2, w3, y, x.grad, w0.grad, w1.grad, w3.grad, w2.grad, y.grad) {\r\n",
      "adj:\r\n",
      "  [in] [CPU] adj: i32[12288, 3] {\r\n",
      "x:\r\n",
      "    [in] [CPU] x: f32[12288, 13] {\r\n",
      "x.grad:\r\n",
      "      [out] [CPU] x.grad: f32[12288, 13] {\r\n",
      "w0:\r\n",
      "        [in] [CPU] w0: f32[13, 64] {\r\n",
      "w0.grad:\r\n",
      "          [out] [CPU] w0.grad: f32[13, 64] {\r\n",
      "w1:\r\n",
      "            [in] [CPU] w1: f32[13, 64] {\r\n",
      "w1.grad:\r\n",
      "              [out] [CPU] w1.grad: f32[13, 64] {\r\n",
      "w2:\r\n",
      "                [in] [CPU] w2: f32[13, 64] {\r\n",
      "w2.grad:\r\n",
      "                  [out] [CPU] w2.grad: f32[13, 64] {\r\n",
      "w3:\r\n",
      "                    [in] [CPU] w3: f32[13, 64] {\r\n",
      "w3.grad:\r\n",
      "                      [out] [CPU] w3.grad: f32[13, 64] {\r\n",
      "y:\r\n",
      "                        [in] [CPU] y: f32[12288, 64] {\r\n",
      "y.grad:\r\n",
      "                          [inout] [CPU] y.grad: f32[12288, 64] {\r\n",
      "merged.#462.#461:\r\n",
      "                            // parallel = openmp\r\n",
      "                            for m..x.grad.i0..x.grad.i1 in 0 : 159744 : 1 {\r\n",
      "                              x.grad[towards0(((-1 * m..x.grad.i0..x.grad.i1) + 159743) / 13), (12 + ((m..x.grad.i0..x.grad.i1 %% 13) * -1))] = 0\r\n",
      "                            }\r\n",
      "merged.fused.fused.fused.#458.#454.#450.#446.fused.fused.fused.#457.#453.#449.#445:\r\n",
      "                            // parallel = openmp\r\n",
      "                            for m..w0.grad.i0..w0.grad.i1 in 0 : 832 : 1 {\r\n",
      "                              w0.grad[towards0(((-1 * m..w0.grad.i0..w0.grad.i1) + 831) / 64), (((m..w0.grad.i0..w0.grad.i1 %% 64) * -1) + 63)] = 0\r\n",
      "                              w1.grad[towards0(((-1 * m..w0.grad.i0..w0.grad.i1) + 831) / 64), (((m..w0.grad.i0..w0.grad.i1 %% 64) * -1) + 63)] = 0\r\n",
      "                              w2.grad[towards0(((-1 * m..w0.grad.i0..w0.grad.i1) + 831) / 64), (((m..w0.grad.i0..w0.grad.i1 %% 64) * -1) + 63)] = 0\r\n",
      "                              w3.grad[towards0(((-1 * m..w0.grad.i0..w0.grad.i1) + 831) / 64), (((m..w0.grad.i0..w0.grad.i1 %% 64) * -1) + 63)] = 0\r\n",
      "                            }\r\n",
      "                            [cache] [CPU] __reduce_#74_3: f32[13, 64] {\r\n",
      "                              [cache] [CPU] __reduce_#74_2: f32[13, 64] {\r\n",
      "                                [cache] [CPU] __reduce_#74_1: f32[13, 64] {\r\n",
      "                                  [cache] [CPU] __reduce_#74_0: f32[13, 64] {\r\n",
      "                                    for __reduce_#74_0.0 in 0 : 13 : 1 {\r\n",
      "                                      for __reduce_#74_0.1 in 0 : 64 : 1 {\r\n",
      "                                        __reduce_#74_0[__reduce_#74_0.0, __reduce_#74_0.1] = 0.000000\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                    for __reduce_#74_1.0 in 0 : 13 : 1 {\r\n",
      "                                      for __reduce_#74_1.1 in 0 : 64 : 1 {\r\n",
      "                                        __reduce_#74_1[__reduce_#74_1.0, __reduce_#74_1.1] = 0.000000\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                    for __reduce_#74_2.0 in 0 : 13 : 1 {\r\n",
      "                                      for __reduce_#74_2.1 in 0 : 64 : 1 {\r\n",
      "                                        __reduce_#74_2[__reduce_#74_2.0, __reduce_#74_2.1] = 0.000000\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                    for __reduce_#74_3.0 in 0 : 13 : 1 {\r\n",
      "                                      for __reduce_#74_3.1 in 0 : 64 : 1 {\r\n",
      "                                        __reduce_#74_3[__reduce_#74_3.0, __reduce_#74_3.1] = 0.000000\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                    // parallel = openmp\r\n",
      "                                    // reduction +: __reduce_#74_0[:, :]\r\n",
      "                                    // reduction +: __reduce_#74_1[:, :]\r\n",
      "                                    // reduction +: __reduce_#74_2[:, :]\r\n",
      "                                    // reduction +: __reduce_#74_3[:, :]\r\n",
      "                                    for i in 12287 : -1 : -1 {\r\n",
      "y$1:\r\n",
      "                                      [cache] [CPU] y$1: f32[13] {\r\n",
      "y$1.grad:\r\n",
      "                                        [cache] [CPU] y$1.grad: f32[13] {\r\n",
      "y$2:\r\n",
      "                                          [cache] [CPU] y$2: f32[13] {\r\n",
      "y$2.grad:\r\n",
      "                                            [cache] [CPU] y$2.grad: f32[13] {\r\n",
      "y$3:\r\n",
      "                                              [cache] [CPU] y$3: f32[13] {\r\n",
      "y$3.grad:\r\n",
      "                                                [cache] [CPU] y$3.grad: f32[13] {\r\n",
      "fused.fused.fused.fused.fused.#442.#439.#436.#139.#141.#143:\r\n",
      "                                                  for .y$1.grad.i0 in 0 : 13 : 1 {\r\n",
      "                                                    y$1.grad[((.y$1.grad.i0 * -1) + 12)] = 0\r\n",
      "                                                    y$2.grad[((.y$1.grad.i0 * -1) + 12)] = 0\r\n",
      "                                                    y$3.grad[((.y$1.grad.i0 * -1) + 12)] = 0\r\n",
      "                                                    y$1[.y$1.grad.i0] = 0\r\n",
      "                                                    y$2[.y$1.grad.i0] = 0\r\n",
      "                                                    y$3[.y$1.grad.i0] = 0\r\n",
      "                                                  }\r\n",
      "                                                  // unroll\r\n",
      "                                                  for p in 0 : 3 : 1 {\r\n",
      "fused.fused.fused.fused.fused.fused.#145.#147.#149.#151.#153.#155.#157:\r\n",
      "                                                    for i$1 in 0 : 13 : 1 {\r\n",
      "                                                      y$1[i$1] += x[adj[i, p], i$1]\r\n",
      "                                                      y$2[i$1] += abs((x[adj[i, p], i$1] - x[adj[i, ((p + 1) %% 3)], i$1]))\r\n",
      "                                                      y$3[i$1] += abs((x[adj[i, p], i$1] - x[i, i$1]))\r\n",
      "                                                    }\r\n",
      "                                                  }\r\n",
      "                                                  [cache] [CPU] x.grad.atomic_cache.#357: f32[13] {\r\n",
      "                                                    for x.grad.atomic_cache.#357.i0 in 0 : 13 : 1 {\r\n",
      "                                                      x.grad.atomic_cache.#357[x.grad.atomic_cache.#357.i0] = 0.000000\r\n",
      "                                                    }\r\n",
      "fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30:\r\n",
      "                                                    for i$4 in 0 : 64 : 1 {\r\n",
      "einsum:Y.grad:\r\n",
      "                                                      [cache] [CPU] einsum:Y.grad: f32[1] {\r\n",
      "einsum$1:Y.grad:\r\n",
      "                                                        [cache] [CPU] einsum$1:Y.grad: f32[1] {\r\n",
      "einsum$2:Y.grad:\r\n",
      "                                                          [cache] [CPU] einsum$2:Y.grad: f32[1] {\r\n",
      "einsum$3:Y.grad:\r\n",
      "                                                            [cache] [CPU] einsum$3:Y.grad: f32[1] {\r\n",
      "out$2.grad:\r\n",
      "                                                              [cache] [CPU] out$2.grad: f32[1] {\r\n",
      "out$3.grad:\r\n",
      "                                                                [cache] [CPU] out$3.grad: f32[1] {\r\n",
      "out$4.grad:\r\n",
      "                                                                  [cache] [CPU] out$4.grad: f32[1] {\r\n",
      "                                                                    out$4.grad[0] = y.grad[i, ((i$4 * -1) + 63)]\r\n",
      "                                                                    out$3.grad[0] = out$4.grad[0]\r\n",
      "                                                                    einsum$3:Y.grad[0] = out$4.grad[0]\r\n",
      "                                                                  }\r\n",
      "                                                                  out$2.grad[0] = out$3.grad[0]\r\n",
      "                                                                  einsum$2:Y.grad[0] = out$3.grad[0]\r\n",
      "                                                                }\r\n",
      "                                                                einsum:Y.grad[0] = out$2.grad[0]\r\n",
      "                                                                einsum$1:Y.grad[0] = out$2.grad[0]\r\n",
      "                                                              }\r\n",
      "fused.fused.fused.#45.#39.#33.#27:\r\n",
      "                                                              for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                                                y$3.grad[((einsum$3:i$1 * -1) + 12)] += (einsum$3:Y.grad[0] * w3[((einsum$3:i$1 * -1) + 12), ((i$4 * -1) + 63)])\r\n",
      "                                                                __reduce_#74_0[((einsum$3:i$1 * -1) + 12), ((i$4 * -1) + 63)] += (einsum$3:Y.grad[0] * y$3[((einsum$3:i$1 * -1) + 12)])\r\n",
      "                                                                y$2.grad[((einsum$3:i$1 * -1) + 12)] += (einsum$2:Y.grad[0] * w2[((einsum$3:i$1 * -1) + 12), ((i$4 * -1) + 63)])\r\n",
      "                                                                __reduce_#74_1[((einsum$3:i$1 * -1) + 12), ((i$4 * -1) + 63)] += (einsum$2:Y.grad[0] * y$2[((einsum$3:i$1 * -1) + 12)])\r\n",
      "                                                                y$1.grad[((einsum$3:i$1 * -1) + 12)] += (einsum$1:Y.grad[0] * w1[((einsum$3:i$1 * -1) + 12), ((i$4 * -1) + 63)])\r\n",
      "                                                                __reduce_#74_2[((einsum$3:i$1 * -1) + 12), ((i$4 * -1) + 63)] += (einsum$1:Y.grad[0] * y$1[((einsum$3:i$1 * -1) + 12)])\r\n",
      "                                                                x.grad.atomic_cache.#357[((einsum$3:i$1 * -1) + 12)] += (einsum:Y.grad[0] * w0[((einsum$3:i$1 * -1) + 12), ((i$4 * -1) + 63)])\r\n",
      "                                                                __reduce_#74_3[((einsum$3:i$1 * -1) + 12), ((i$4 * -1) + 63)] += (einsum:Y.grad[0] * x[i, ((einsum$3:i$1 * -1) + 12)])\r\n",
      "                                                              }\r\n",
      "                                                              einsum$3:Y.grad[0] = 0\r\n",
      "                                                            }\r\n",
      "                                                            einsum$2:Y.grad[0] = 0\r\n",
      "                                                          }\r\n",
      "                                                          einsum$1:Y.grad[0] = 0\r\n",
      "                                                        }\r\n",
      "                                                        einsum:Y.grad[0] = 0\r\n",
      "                                                      }\r\n",
      "                                                    }\r\n",
      "                                                    for x.grad.atomic_cache.#357.i0 in 0 : 13 : 1 {\r\n",
      "                                                      // atomic\r\n",
      "                                                      x.grad[i, x.grad.atomic_cache.#357.i0] += x.grad.atomic_cache.#357[x.grad.atomic_cache.#357.i0]\r\n",
      "                                                    }\r\n",
      "                                                  }\r\n",
      "                                                  [cache] [CPU] x.grad.atomic_cache.#403: f32[13] {\r\n",
      "                                                    for x.grad.atomic_cache.#403.i0 in 0 : 13 : 1 {\r\n",
      "                                                      x.grad.atomic_cache.#403[x.grad.atomic_cache.#403.i0] = 0.000000\r\n",
      "                                                    }\r\n",
      "                                                    // unroll\r\n",
      "                                                    for p in 2 : -1 : -1 {\r\n",
      "out:\r\n",
      "                                                      [cache] [CPU] out: f32[13] {\r\n",
      "out$1:\r\n",
      "                                                        [cache] [CPU] out$1.out$1: f32[13] {\r\n",
      "out$1.grad:\r\n",
      "                                                          [cache] [CPU] out$1.grad: f32[13] {\r\n",
      "y$5.grad:\r\n",
      "                                                            [cache] [CPU] y$5.grad: f32[13] {\r\n",
      "fused.fused.#368.#388.L_elem$2:\r\n",
      "                                                              for recur$4:i in 0 : 13 : 1 {\r\n",
      "                                                                out[recur$4:i] = (x[adj[i, p], recur$4:i] - x[adj[i, ((p + 1) %% 3)], recur$4:i])\r\n",
      "                                                                out$1.out$1[recur$4:i] = (x[adj[i, p], recur$4:i] - x[i, recur$4:i])\r\n",
      "                                                                y$5.grad[((recur$4:i * -1) + 12)] = y$3.grad[((recur$4:i * -1) + 12)]\r\n",
      "                                                              }\r\n",
      "fused.fused.fused.fused.fused.recur$8:L_elem.recur$7:L_elem.L_elem$1.recur$5:L_elem.recur$4:L_elem.L_elem:\r\n",
      "                                                              for recur$8:i in 0 : 13 : 1 {\r\n",
      "                                                                out$1.grad[((recur$8:i * -1) + 12)] = ((out$1.out$1[((recur$8:i * -1) + 12)] >= 0) ? y$5.grad[((recur$8:i * -1) + 12)] : (-1 * y$5.grad[((recur$8:i * -1) + 12)]))\r\n",
      "                                                                // atomic\r\n",
      "                                                                x.grad[adj[i, p], ((recur$8:i * -1) + 12)] += out$1.grad[((recur$8:i * -1) + 12)]\r\n",
      "                                                                x.grad.atomic_cache.#403[((recur$8:i * -1) + 12)] += (-1 * out$1.grad[((recur$8:i * -1) + 12)])\r\n",
      "out.grad:\r\n",
      "                                                                [cache] [CPU] out.grad: f32[1] {\r\n",
      "y$4.grad:\r\n",
      "                                                                  [cache] [CPU] y$4.grad: f32[1] {\r\n",
      "                                                                    y$4.grad[0] = y$2.grad[((recur$8:i * -1) + 12)]\r\n",
      "                                                                    out.grad[0] = ((out[((recur$8:i * -1) + 12)] >= 0) ? y$4.grad[0] : (-1 * y$4.grad[0]))\r\n",
      "                                                                  }\r\n",
      "                                                                  // atomic\r\n",
      "                                                                  x.grad[adj[i, p], ((recur$8:i * -1) + 12)] += out.grad[0]\r\n",
      "                                                                  // atomic\r\n",
      "                                                                  x.grad[adj[i, ((p + 1) %% 3)], ((recur$8:i * -1) + 12)] += (-1 * out.grad[0])\r\n",
      "                                                                }\r\n",
      "                                                                // atomic\r\n",
      "                                                                x.grad[adj[i, p], ((recur$8:i * -1) + 12)] += y$1.grad[((recur$8:i * -1) + 12)]\r\n",
      "                                                              }\r\n",
      "                                                            }\r\n",
      "                                                          }\r\n",
      "                                                        }\r\n",
      "                                                      }\r\n",
      "                                                    }\r\n",
      "                                                    for x.grad.atomic_cache.#403.i0 in 0 : 13 : 1 {\r\n",
      "                                                      // atomic\r\n",
      "                                                      x.grad[i, x.grad.atomic_cache.#403.i0] += x.grad.atomic_cache.#403[x.grad.atomic_cache.#403.i0]\r\n",
      "                                                    }\r\n",
      "                                                  }\r\n",
      "fused.fused.recur$2:L_elem.recur$1:L_elem.recur:L_elem:\r\n",
      "                                                  for recur$2:i in 0 : 13 : 1 {\r\n",
      "                                                    y$3.grad[((recur$2:i * -1) + 12)] = 0\r\n",
      "                                                    y$2.grad[((recur$2:i * -1) + 12)] = 0\r\n",
      "                                                    y$1.grad[((recur$2:i * -1) + 12)] = 0\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                    for __reduce_#74_0.0 in 0 : 13 : 1 {\r\n",
      "                                      for __reduce_#74_0.1 in 0 : 64 : 1 {\r\n",
      "                                        w3.grad[__reduce_#74_0.0, __reduce_#74_0.1] += __reduce_#74_0[__reduce_#74_0.0, __reduce_#74_0.1]\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                    for __reduce_#74_1.0 in 0 : 13 : 1 {\r\n",
      "                                      for __reduce_#74_1.1 in 0 : 64 : 1 {\r\n",
      "                                        w2.grad[__reduce_#74_1.0, __reduce_#74_1.1] += __reduce_#74_1[__reduce_#74_1.0, __reduce_#74_1.1]\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                    for __reduce_#74_2.0 in 0 : 13 : 1 {\r\n",
      "                                      for __reduce_#74_2.1 in 0 : 64 : 1 {\r\n",
      "                                        w1.grad[__reduce_#74_2.0, __reduce_#74_2.1] += __reduce_#74_2[__reduce_#74_2.0, __reduce_#74_2.1]\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                    for __reduce_#74_3.0 in 0 : 13 : 1 {\r\n",
      "                                      for __reduce_#74_3.1 in 0 : 64 : 1 {\r\n",
      "                                        w0.grad[__reduce_#74_3.0, __reduce_#74_3.1] += __reduce_#74_3[__reduce_#74_3.0, __reduce_#74_3.1]\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "\u001b[33m  1\u001b[0m \r\n",
      "\u001b[33m  2\u001b[0m #include <cpu_runtime.h>\r\n",
      "\u001b[33m  3\u001b[0m \r\n",
      "\u001b[33m  4\u001b[0m extern \"C\" {\r\n",
      "\u001b[33m  5\u001b[0m void __attribute__ ((noinline)) _run(void **_params, void **_returns, size_t **_retShapes, size_t *_retDims) {\r\n",
      "\u001b[33m  6\u001b[0m   const int32_t (*restrict adj)[3] = (int32_t(*)[3])_params[0];\r\n",
      "\u001b[33m  7\u001b[0m   const float (*restrict x)[13] = (float(*)[13])_params[1];\r\n",
      "\u001b[33m  8\u001b[0m   float (*restrict x_46grad)[13] = (float(*)[13])_params[7];\r\n",
      "\u001b[33m  9\u001b[0m   const float (*restrict w0)[64] = (float(*)[64])_params[2];\r\n",
      "\u001b[33m 10\u001b[0m   float (*restrict w0_46grad)[64] = (float(*)[64])_params[8];\r\n",
      "\u001b[33m 11\u001b[0m   const float (*restrict w1)[64] = (float(*)[64])_params[3];\r\n",
      "\u001b[33m 12\u001b[0m   float (*restrict w1_46grad)[64] = (float(*)[64])_params[9];\r\n",
      "\u001b[33m 13\u001b[0m   const float (*restrict w2)[64] = (float(*)[64])_params[4];\r\n",
      "\u001b[33m 14\u001b[0m   float (*restrict w2_46grad)[64] = (float(*)[64])_params[11];\r\n",
      "\u001b[33m 15\u001b[0m   const float (*restrict w3)[64] = (float(*)[64])_params[5];\r\n",
      "\u001b[33m 16\u001b[0m   float (*restrict w3_46grad)[64] = (float(*)[64])_params[10];\r\n",
      "\u001b[33m 17\u001b[0m   const float (*restrict y)[64] = (float(*)[64])_params[6];\r\n",
      "\u001b[33m 18\u001b[0m   float (*restrict y_46grad)[64] = (float(*)[64])_params[12];\r\n",
      "\u001b[33m 19\u001b[0m #pragma omp parallel for\r\n",
      "\u001b[33m 20\u001b[0m   for (int m_46_46x_46grad_46i0_46_46x_46grad_46i1 = 0; m_46_46x_46grad_46i0_46_46x_46grad_46i1 < 159744; m_46_46x_46grad_46i0_46_46x_46grad_46i1++) {\r\n",
      "\u001b[33m 21\u001b[0m     x_46grad[(((-1 * m_46_46x_46grad_46i0_46_46x_46grad_46i1) + 159743) / 13)][(12 + ((m_46_46x_46grad_46i0_46_46x_46grad_46i1 % 13) * -1))] = 0;\r\n",
      "\u001b[33m 22\u001b[0m   }\r\n",
      "\u001b[33m 23\u001b[0m #pragma omp parallel for\r\n",
      "\u001b[33m 24\u001b[0m   for (int m_46_46w0_46grad_46i0_46_46w0_46grad_46i1 = 0; m_46_46w0_46grad_46i0_46_46w0_46grad_46i1 < 832; m_46_46w0_46grad_46i0_46_46w0_46grad_46i1++) {\r\n",
      "\u001b[33m 25\u001b[0m     w0_46grad[(((-1 * m_46_46w0_46grad_46i0_46_46w0_46grad_46i1) + 831) / 64)][(((m_46_46w0_46grad_46i0_46_46w0_46grad_46i1 % 64) * -1) + 63)] = 0;\r\n",
      "\u001b[33m 26\u001b[0m     w1_46grad[(((-1 * m_46_46w0_46grad_46i0_46_46w0_46grad_46i1) + 831) / 64)][(((m_46_46w0_46grad_46i0_46_46w0_46grad_46i1 % 64) * -1) + 63)] = 0;\r\n",
      "\u001b[33m 27\u001b[0m     w2_46grad[(((-1 * m_46_46w0_46grad_46i0_46_46w0_46grad_46i1) + 831) / 64)][(((m_46_46w0_46grad_46i0_46_46w0_46grad_46i1 % 64) * -1) + 63)] = 0;\r\n",
      "\u001b[33m 28\u001b[0m     w3_46grad[(((-1 * m_46_46w0_46grad_46i0_46_46w0_46grad_46i1) + 831) / 64)][(((m_46_46w0_46grad_46i0_46_46w0_46grad_46i1 % 64) * -1) + 63)] = 0;\r\n",
      "\u001b[33m 29\u001b[0m   }\r\n",
      "\u001b[33m 30\u001b[0m   {\r\n",
      "\u001b[33m 31\u001b[0m     float ____reduce___3574__3[13][64] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 32\u001b[0m     float ____reduce___3574__2[13][64] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 33\u001b[0m     float ____reduce___3574__1[13][64] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 34\u001b[0m     float ____reduce___3574__0[13][64] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 35\u001b[0m     for (int ____reduce___3574__0_460 = 0; ____reduce___3574__0_460 < 13; ____reduce___3574__0_460++) {\r\n",
      "\u001b[33m 36\u001b[0m       for (int ____reduce___3574__0_461 = 0; ____reduce___3574__0_461 < 64; ____reduce___3574__0_461++) {\r\n",
      "\u001b[33m 37\u001b[0m         ____reduce___3574__0[____reduce___3574__0_460][____reduce___3574__0_461] = 0.000000f;\r\n",
      "\u001b[33m 38\u001b[0m       }\r\n",
      "\u001b[33m 39\u001b[0m     }\r\n",
      "\u001b[33m 40\u001b[0m     for (int ____reduce___3574__1_460 = 0; ____reduce___3574__1_460 < 13; ____reduce___3574__1_460++) {\r\n",
      "\u001b[33m 41\u001b[0m       for (int ____reduce___3574__1_461 = 0; ____reduce___3574__1_461 < 64; ____reduce___3574__1_461++) {\r\n",
      "\u001b[33m 42\u001b[0m         ____reduce___3574__1[____reduce___3574__1_460][____reduce___3574__1_461] = 0.000000f;\r\n",
      "\u001b[33m 43\u001b[0m       }\r\n",
      "\u001b[33m 44\u001b[0m     }\r\n",
      "\u001b[33m 45\u001b[0m     for (int ____reduce___3574__2_460 = 0; ____reduce___3574__2_460 < 13; ____reduce___3574__2_460++) {\r\n",
      "\u001b[33m 46\u001b[0m       for (int ____reduce___3574__2_461 = 0; ____reduce___3574__2_461 < 64; ____reduce___3574__2_461++) {\r\n",
      "\u001b[33m 47\u001b[0m         ____reduce___3574__2[____reduce___3574__2_460][____reduce___3574__2_461] = 0.000000f;\r\n",
      "\u001b[33m 48\u001b[0m       }\r\n",
      "\u001b[33m 49\u001b[0m     }\r\n",
      "\u001b[33m 50\u001b[0m     for (int ____reduce___3574__3_460 = 0; ____reduce___3574__3_460 < 13; ____reduce___3574__3_460++) {\r\n",
      "\u001b[33m 51\u001b[0m       for (int ____reduce___3574__3_461 = 0; ____reduce___3574__3_461 < 64; ____reduce___3574__3_461++) {\r\n",
      "\u001b[33m 52\u001b[0m         ____reduce___3574__3[____reduce___3574__3_460][____reduce___3574__3_461] = 0.000000f;\r\n",
      "\u001b[33m 53\u001b[0m       }\r\n",
      "\u001b[33m 54\u001b[0m     }\r\n",
      "\u001b[33m 55\u001b[0m #pragma omp parallel for reduction(+: ____reduce___3574__0[:][:], ____reduce___3574__1[:][:], ____reduce___3574__2[:][:], ____reduce___3574__3[:][:])\r\n",
      "\u001b[33m 56\u001b[0m     for (int i_46cnt = 0; i_46cnt < 12288; i_46cnt++) {\r\n",
      "\u001b[33m 57\u001b[0m       int i = 12287 + i_46cnt * -1;\r\n",
      "\u001b[33m 58\u001b[0m       float y_361[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 59\u001b[0m       float y_361_46grad[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 60\u001b[0m       float y_362[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 61\u001b[0m       float y_362_46grad[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 62\u001b[0m       float y_363[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 63\u001b[0m       float y_363_46grad[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 64\u001b[0m       for (int _46y_361_46grad_46i0 = 0; _46y_361_46grad_46i0 < 13; _46y_361_46grad_46i0++) {\r\n",
      "\u001b[33m 65\u001b[0m         y_361_46grad[((_46y_361_46grad_46i0 * -1) + 12)] = 0;\r\n",
      "\u001b[33m 66\u001b[0m         y_362_46grad[((_46y_361_46grad_46i0 * -1) + 12)] = 0;\r\n",
      "\u001b[33m 67\u001b[0m         y_363_46grad[((_46y_361_46grad_46i0 * -1) + 12)] = 0;\r\n",
      "\u001b[33m 68\u001b[0m         y_361[_46y_361_46grad_46i0] = 0;\r\n",
      "\u001b[33m 69\u001b[0m         y_362[_46y_361_46grad_46i0] = 0;\r\n",
      "\u001b[33m 70\u001b[0m         y_363[_46y_361_46grad_46i0] = 0;\r\n",
      "\u001b[33m 71\u001b[0m       }\r\n",
      "\u001b[33m 72\u001b[0m #pragma GCC unroll 3\r\n",
      "\u001b[33m 73\u001b[0m       for (int p = 0; p < 3; p++) {\r\n",
      "\u001b[33m 74\u001b[0m         for (int i_361 = 0; i_361 < 13; i_361++) {\r\n",
      "\u001b[33m 75\u001b[0m           y_361[i_361] += x[adj[i][p]][i_361];\r\n",
      "\u001b[33m 76\u001b[0m           y_362[i_361] += std::abs((x[adj[i][p]][i_361] - x[adj[i][((p + 1) % 3)]][i_361]));\r\n",
      "\u001b[33m 77\u001b[0m           y_363[i_361] += std::abs((x[adj[i][p]][i_361] - x[i][i_361]));\r\n",
      "\u001b[33m 78\u001b[0m         }\r\n",
      "\u001b[33m 79\u001b[0m       }\r\n",
      "\u001b[33m 80\u001b[0m       {\r\n",
      "\u001b[33m 81\u001b[0m         float x_46grad_46atomic__cache_46_35357[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m 82\u001b[0m         for (int x_46grad_46atomic__cache_46_35357_46i0 = 0; x_46grad_46atomic__cache_46_35357_46i0 < 13; x_46grad_46atomic__cache_46_35357_46i0++) {\r\n",
      "\u001b[33m 83\u001b[0m           x_46grad_46atomic__cache_46_35357[x_46grad_46atomic__cache_46_35357_46i0] = 0.000000f;\r\n",
      "\u001b[33m 84\u001b[0m         }\r\n",
      "\u001b[33m 85\u001b[0m         for (int i_364 = 0; i_364 < 64; i_364++) {\r\n",
      "\u001b[33m 86\u001b[0m           float einsum_58Y_46grad[1];\r\n",
      "\u001b[33m 87\u001b[0m           {\r\n",
      "\u001b[33m 88\u001b[0m             float einsum_361_58Y_46grad[1];\r\n",
      "\u001b[33m 89\u001b[0m             {\r\n",
      "\u001b[33m 90\u001b[0m               float einsum_362_58Y_46grad[1];\r\n",
      "\u001b[33m 91\u001b[0m               {\r\n",
      "\u001b[33m 92\u001b[0m                 float einsum_363_58Y_46grad[1];\r\n",
      "\u001b[33m 93\u001b[0m                 {\r\n",
      "\u001b[33m 94\u001b[0m                   float out_362_46grad[1];\r\n",
      "\u001b[33m 95\u001b[0m                   {\r\n",
      "\u001b[33m 96\u001b[0m                     float out_363_46grad[1];\r\n",
      "\u001b[33m 97\u001b[0m                     {\r\n",
      "\u001b[33m 98\u001b[0m                       float out_364_46grad[1];\r\n",
      "\u001b[33m 99\u001b[0m                       out_364_46grad[0] = y_46grad[i][((i_364 * -1) + 63)];\r\n",
      "\u001b[33m100\u001b[0m                       out_363_46grad[0] = out_364_46grad[0];\r\n",
      "\u001b[33m101\u001b[0m                       einsum_363_58Y_46grad[0] = out_364_46grad[0];\r\n",
      "\u001b[33m102\u001b[0m                     }\r\n",
      "\u001b[33m103\u001b[0m                     out_362_46grad[0] = out_363_46grad[0];\r\n",
      "\u001b[33m104\u001b[0m                     einsum_362_58Y_46grad[0] = out_363_46grad[0];\r\n",
      "\u001b[33m105\u001b[0m                   }\r\n",
      "\u001b[33m106\u001b[0m                   einsum_58Y_46grad[0] = out_362_46grad[0];\r\n",
      "\u001b[33m107\u001b[0m                   einsum_361_58Y_46grad[0] = out_362_46grad[0];\r\n",
      "\u001b[33m108\u001b[0m                 }\r\n",
      "\u001b[33m109\u001b[0m                 for (int einsum_363_58i_361 = 0; einsum_363_58i_361 < 13; einsum_363_58i_361++) {\r\n",
      "\u001b[33m110\u001b[0m                   y_363_46grad[((einsum_363_58i_361 * -1) + 12)] += (einsum_363_58Y_46grad[0] * w3[((einsum_363_58i_361 * -1) + 12)][((i_364 * -1) + 63)]);\r\n",
      "\u001b[33m111\u001b[0m                   ____reduce___3574__0[((einsum_363_58i_361 * -1) + 12)][((i_364 * -1) + 63)] += (einsum_363_58Y_46grad[0] * y_363[((einsum_363_58i_361 * -1) + 12)]);\r\n",
      "\u001b[33m112\u001b[0m                   y_362_46grad[((einsum_363_58i_361 * -1) + 12)] += (einsum_362_58Y_46grad[0] * w2[((einsum_363_58i_361 * -1) + 12)][((i_364 * -1) + 63)]);\r\n",
      "\u001b[33m113\u001b[0m                   ____reduce___3574__1[((einsum_363_58i_361 * -1) + 12)][((i_364 * -1) + 63)] += (einsum_362_58Y_46grad[0] * y_362[((einsum_363_58i_361 * -1) + 12)]);\r\n",
      "\u001b[33m114\u001b[0m                   y_361_46grad[((einsum_363_58i_361 * -1) + 12)] += (einsum_361_58Y_46grad[0] * w1[((einsum_363_58i_361 * -1) + 12)][((i_364 * -1) + 63)]);\r\n",
      "\u001b[33m115\u001b[0m                   ____reduce___3574__2[((einsum_363_58i_361 * -1) + 12)][((i_364 * -1) + 63)] += (einsum_361_58Y_46grad[0] * y_361[((einsum_363_58i_361 * -1) + 12)]);\r\n",
      "\u001b[33m116\u001b[0m                   x_46grad_46atomic__cache_46_35357[((einsum_363_58i_361 * -1) + 12)] += (einsum_58Y_46grad[0] * w0[((einsum_363_58i_361 * -1) + 12)][((i_364 * -1) + 63)]);\r\n",
      "\u001b[33m117\u001b[0m                   ____reduce___3574__3[((einsum_363_58i_361 * -1) + 12)][((i_364 * -1) + 63)] += (einsum_58Y_46grad[0] * x[i][((einsum_363_58i_361 * -1) + 12)]);\r\n",
      "\u001b[33m118\u001b[0m                 }\r\n",
      "\u001b[33m119\u001b[0m                 einsum_363_58Y_46grad[0] = 0;\r\n",
      "\u001b[33m120\u001b[0m               }\r\n",
      "\u001b[33m121\u001b[0m               einsum_362_58Y_46grad[0] = 0;\r\n",
      "\u001b[33m122\u001b[0m             }\r\n",
      "\u001b[33m123\u001b[0m             einsum_361_58Y_46grad[0] = 0;\r\n",
      "\u001b[33m124\u001b[0m           }\r\n",
      "\u001b[33m125\u001b[0m           einsum_58Y_46grad[0] = 0;\r\n",
      "\u001b[33m126\u001b[0m         }\r\n",
      "\u001b[33m127\u001b[0m         for (int x_46grad_46atomic__cache_46_35357_46i0 = 0; x_46grad_46atomic__cache_46_35357_46i0 < 13; x_46grad_46atomic__cache_46_35357_46i0++) {\r\n",
      "\u001b[33m128\u001b[0m #pragma omp atomic\r\n",
      "\u001b[33m129\u001b[0m           x_46grad[i][x_46grad_46atomic__cache_46_35357_46i0] += x_46grad_46atomic__cache_46_35357[x_46grad_46atomic__cache_46_35357_46i0];\r\n",
      "\u001b[33m130\u001b[0m         }\r\n",
      "\u001b[33m131\u001b[0m       }\r\n",
      "\u001b[33m132\u001b[0m       {\r\n",
      "\u001b[33m133\u001b[0m         float x_46grad_46atomic__cache_46_35403[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m134\u001b[0m         for (int x_46grad_46atomic__cache_46_35403_46i0 = 0; x_46grad_46atomic__cache_46_35403_46i0 < 13; x_46grad_46atomic__cache_46_35403_46i0++) {\r\n",
      "\u001b[33m135\u001b[0m           x_46grad_46atomic__cache_46_35403[x_46grad_46atomic__cache_46_35403_46i0] = 0.000000f;\r\n",
      "\u001b[33m136\u001b[0m         }\r\n",
      "\u001b[33m137\u001b[0m #pragma GCC unroll 3\r\n",
      "\u001b[33m138\u001b[0m         for (int p_46cnt = 0; p_46cnt < 3; p_46cnt++) {\r\n",
      "\u001b[33m139\u001b[0m           int p = 2 + p_46cnt * -1;\r\n",
      "\u001b[33m140\u001b[0m           float out[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m141\u001b[0m           float out_361_46out_361[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m142\u001b[0m           float out_361_46grad[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m143\u001b[0m           float y_365_46grad[13] __attribute__((aligned(64)));\r\n",
      "\u001b[33m144\u001b[0m           for (int recur_364_58i = 0; recur_364_58i < 13; recur_364_58i++) {\r\n",
      "\u001b[33m145\u001b[0m             out[recur_364_58i] = (x[adj[i][p]][recur_364_58i] - x[adj[i][((p + 1) % 3)]][recur_364_58i]);\r\n",
      "\u001b[33m146\u001b[0m             out_361_46out_361[recur_364_58i] = (x[adj[i][p]][recur_364_58i] - x[i][recur_364_58i]);\r\n",
      "\u001b[33m147\u001b[0m             y_365_46grad[((recur_364_58i * -1) + 12)] = y_363_46grad[((recur_364_58i * -1) + 12)];\r\n",
      "\u001b[33m148\u001b[0m           }\r\n",
      "\u001b[33m149\u001b[0m           for (int recur_368_58i = 0; recur_368_58i < 13; recur_368_58i++) {\r\n",
      "\u001b[33m150\u001b[0m             out_361_46grad[((recur_368_58i * -1) + 12)] = ((out_361_46out_361[((recur_368_58i * -1) + 12)] >= 0) ? y_365_46grad[((recur_368_58i * -1) + 12)] : (-1 * y_365_46grad[((recur_368_58i * -1) + 12)]));\r\n",
      "\u001b[33m151\u001b[0m #pragma omp atomic\r\n",
      "\u001b[33m152\u001b[0m             x_46grad[adj[i][p]][((recur_368_58i * -1) + 12)] += out_361_46grad[((recur_368_58i * -1) + 12)];\r\n",
      "\u001b[33m153\u001b[0m             x_46grad_46atomic__cache_46_35403[((recur_368_58i * -1) + 12)] += (-1 * out_361_46grad[((recur_368_58i * -1) + 12)]);\r\n",
      "\u001b[33m154\u001b[0m             {\r\n",
      "\u001b[33m155\u001b[0m               float out_46grad[1];\r\n",
      "\u001b[33m156\u001b[0m               {\r\n",
      "\u001b[33m157\u001b[0m                 float y_364_46grad[1];\r\n",
      "\u001b[33m158\u001b[0m                 y_364_46grad[0] = y_362_46grad[((recur_368_58i * -1) + 12)];\r\n",
      "\u001b[33m159\u001b[0m                 out_46grad[0] = ((out[((recur_368_58i * -1) + 12)] >= 0) ? y_364_46grad[0] : (-1 * y_364_46grad[0]));\r\n",
      "\u001b[33m160\u001b[0m               }\r\n",
      "\u001b[33m161\u001b[0m #pragma omp atomic\r\n",
      "\u001b[33m162\u001b[0m               x_46grad[adj[i][p]][((recur_368_58i * -1) + 12)] += out_46grad[0];\r\n",
      "\u001b[33m163\u001b[0m #pragma omp atomic\r\n",
      "\u001b[33m164\u001b[0m               x_46grad[adj[i][((p + 1) % 3)]][((recur_368_58i * -1) + 12)] += (-1 * out_46grad[0]);\r\n",
      "\u001b[33m165\u001b[0m             }\r\n",
      "\u001b[33m166\u001b[0m #pragma omp atomic\r\n",
      "\u001b[33m167\u001b[0m             x_46grad[adj[i][p]][((recur_368_58i * -1) + 12)] += y_361_46grad[((recur_368_58i * -1) + 12)];\r\n",
      "\u001b[33m168\u001b[0m           }\r\n",
      "\u001b[33m169\u001b[0m         }\r\n",
      "\u001b[33m170\u001b[0m         for (int x_46grad_46atomic__cache_46_35403_46i0 = 0; x_46grad_46atomic__cache_46_35403_46i0 < 13; x_46grad_46atomic__cache_46_35403_46i0++) {\r\n",
      "\u001b[33m171\u001b[0m #pragma omp atomic\r\n",
      "\u001b[33m172\u001b[0m           x_46grad[i][x_46grad_46atomic__cache_46_35403_46i0] += x_46grad_46atomic__cache_46_35403[x_46grad_46atomic__cache_46_35403_46i0];\r\n",
      "\u001b[33m173\u001b[0m         }\r\n",
      "\u001b[33m174\u001b[0m       }\r\n",
      "\u001b[33m175\u001b[0m       for (int recur_362_58i = 0; recur_362_58i < 13; recur_362_58i++) {\r\n",
      "\u001b[33m176\u001b[0m         y_363_46grad[((recur_362_58i * -1) + 12)] = 0;\r\n",
      "\u001b[33m177\u001b[0m         y_362_46grad[((recur_362_58i * -1) + 12)] = 0;\r\n",
      "\u001b[33m178\u001b[0m         y_361_46grad[((recur_362_58i * -1) + 12)] = 0;\r\n",
      "\u001b[33m179\u001b[0m       }\r\n",
      "\u001b[33m180\u001b[0m     }\r\n",
      "\u001b[33m181\u001b[0m     for (int ____reduce___3574__0_460 = 0; ____reduce___3574__0_460 < 13; ____reduce___3574__0_460++) {\r\n",
      "\u001b[33m182\u001b[0m       for (int ____reduce___3574__0_461 = 0; ____reduce___3574__0_461 < 64; ____reduce___3574__0_461++) {\r\n",
      "\u001b[33m183\u001b[0m         w3_46grad[____reduce___3574__0_460][____reduce___3574__0_461] += ____reduce___3574__0[____reduce___3574__0_460][____reduce___3574__0_461];\r\n",
      "\u001b[33m184\u001b[0m       }\r\n",
      "\u001b[33m185\u001b[0m     }\r\n",
      "\u001b[33m186\u001b[0m     for (int ____reduce___3574__1_460 = 0; ____reduce___3574__1_460 < 13; ____reduce___3574__1_460++) {\r\n",
      "\u001b[33m187\u001b[0m       for (int ____reduce___3574__1_461 = 0; ____reduce___3574__1_461 < 64; ____reduce___3574__1_461++) {\r\n",
      "\u001b[33m188\u001b[0m         w2_46grad[____reduce___3574__1_460][____reduce___3574__1_461] += ____reduce___3574__1[____reduce___3574__1_460][____reduce___3574__1_461];\r\n",
      "\u001b[33m189\u001b[0m       }\r\n",
      "\u001b[33m190\u001b[0m     }\r\n",
      "\u001b[33m191\u001b[0m     for (int ____reduce___3574__2_460 = 0; ____reduce___3574__2_460 < 13; ____reduce___3574__2_460++) {\r\n",
      "\u001b[33m192\u001b[0m       for (int ____reduce___3574__2_461 = 0; ____reduce___3574__2_461 < 64; ____reduce___3574__2_461++) {\r\n",
      "\u001b[33m193\u001b[0m         w1_46grad[____reduce___3574__2_460][____reduce___3574__2_461] += ____reduce___3574__2[____reduce___3574__2_460][____reduce___3574__2_461];\r\n",
      "\u001b[33m194\u001b[0m       }\r\n",
      "\u001b[33m195\u001b[0m     }\r\n",
      "\u001b[33m196\u001b[0m     for (int ____reduce___3574__3_460 = 0; ____reduce___3574__3_460 < 13; ____reduce___3574__3_460++) {\r\n",
      "\u001b[33m197\u001b[0m       for (int ____reduce___3574__3_461 = 0; ____reduce___3574__3_461 < 64; ____reduce___3574__3_461++) {\r\n",
      "\u001b[33m198\u001b[0m         w0_46grad[____reduce___3574__3_460][____reduce___3574__3_461] += ____reduce___3574__3[____reduce___3574__3_460][____reduce___3574__3_461];\r\n",
      "\u001b[33m199\u001b[0m       }\r\n",
      "\u001b[33m200\u001b[0m     }\r\n",
      "\u001b[33m201\u001b[0m   }\r\n",
      "\u001b[33m202\u001b[0m }\r\n",
      "\u001b[33m203\u001b[0m \r\n",
      "\u001b[33m204\u001b[0m void run(void **_params, void **_returns, size_t **_retShapes, size_t *_retDims, CPUContext_t _ctx) {\r\n",
      "\u001b[33m205\u001b[0m   _ctx->setStackLim(8402500);\r\n",
      "\u001b[33m206\u001b[0m   _run(_params, _returns, _retShapes, _retDims);\r\n",
      "\u001b[33m207\u001b[0m }\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m208\u001b[0m }/home/pldi22_ae/.ir/NDnY3e/run.cpp: In function 'void _run(void**, void**, size_t**, size_t*)':\n",
      "/home/pldi22_ae/.ir/NDnY3e/run.cpp:17:26: warning: unused variable 'y' [-Wunused-variable]\n",
      "   const float (*restrict y)[64] = (float(*)[64])_params[6];\n",
      "                          ^\n",
      "\n",
      "10 warmup, 100 repeats for evalution\n",
      "Inference Time = 0.3627634048461914 ms\n",
      "Forward Time = 0.2965974807739258 ms\n",
      "Backward Time = 4.521887302398682 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/ours && srun -p PLDI main.sh cpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcbdd3c",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aba4d7b1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Inference:\r\n",
      "func(adj, x, w0, w1, w2, w3, y) {\r\n",
      "adj:\r\n",
      "  [in] [GPUGlobal] adj: i32[12288, 3] {\r\n",
      "x:\r\n",
      "    [in] [GPUGlobal] x: f32[12288, 13] {\r\n",
      "w0:\r\n",
      "      [in] [GPUGlobal] w0: f32[13, 64] {\r\n",
      "w1:\r\n",
      "        [in] [GPUGlobal] w1: f32[13, 64] {\r\n",
      "w2:\r\n",
      "          [in] [GPUGlobal] w2: f32[13, 64] {\r\n",
      "w3:\r\n",
      "            [in] [GPUGlobal] w3: f32[13, 64] {\r\n",
      "y:\r\n",
      "              [out] [GPUGlobal] y: f32[12288, 64] {\r\n",
      "                for i in 0 : 12288 : 1 {\r\n",
      "y$1:\r\n",
      "                  [cache] [GPUGlobal] y$1: f32[13] {\r\n",
      "recur:L_elem:\r\n",
      "                    for recur:i in 0 : 13 : 1 {\r\n",
      "                      y$1[recur:i] = 0\r\n",
      "                    }\r\n",
      "y$2:\r\n",
      "                    [cache] [GPUGlobal] y$2: f32[13] {\r\n",
      "recur$1:L_elem:\r\n",
      "                      for recur$1:i in 0 : 13 : 1 {\r\n",
      "                        y$2[recur$1:i] = 0\r\n",
      "                      }\r\n",
      "y$3:\r\n",
      "                      [cache] [GPUGlobal] y$3: f32[13] {\r\n",
      "recur$2:L_elem:\r\n",
      "                        for recur$2:i in 0 : 13 : 1 {\r\n",
      "                          y$3[recur$2:i] = 0\r\n",
      "                        }\r\n",
      "                        for p in 0 : 3 : 1 {\r\n",
      "L_elem:\r\n",
      "                          for i$1 in 0 : 13 : 1 {\r\n",
      "                            assert ((13 == 13) || (13 == 1)) {\r\n",
      "                              y$1[i$1] = (x[adj[i, p], (i$1 % 13)] + y$1[i$1])\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "out:\r\n",
      "                          [cache] [GPUGlobal] out: f32[max(13, 13)] {\r\n",
      "recur$4:L_elem:\r\n",
      "                            for recur$4:i in 0 : max(13, 13) : 1 {\r\n",
      "                              assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                  out[recur$4:i] = (x[adj[i, p], (recur$4:i % 13)] - x[adj[i, ((p + 1) % 3)], (recur$4:i % 13)])\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "y$4:\r\n",
      "                            [cache] [GPUGlobal] y$4: f32[max(13, 13)] {\r\n",
      "                              assert (max(13, 13) == max(13, 13)) {\r\n",
      "recur$5:L_elem:\r\n",
      "                                for recur$5:i in 0 : max(13, 13) : 1 {\r\n",
      "                                  y$4[recur$5:i] = abs(out[recur$5:i])\r\n",
      "                                }\r\n",
      "L_elem$1:\r\n",
      "                                for i$2 in 0 : 13 : 1 {\r\n",
      "                                  assert ((max(13, 13) == 13) || (max(13, 13) == 1)) {\r\n",
      "                                    y$2[i$2] = (y$4[(i$2 % max(13, 13))] + y$2[i$2])\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "out$1:\r\n",
      "                                [cache] [GPUGlobal] out$1: f32[max(13, 13)] {\r\n",
      "recur$7:L_elem:\r\n",
      "                                  for recur$7:i in 0 : max(13, 13) : 1 {\r\n",
      "                                    assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                      assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                        out$1[recur$7:i] = (x[adj[i, p], (recur$7:i % 13)] - x[i, (recur$7:i % 13)])\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "y$5:\r\n",
      "                                  [cache] [GPUGlobal] y$5: f32[max(13, 13)] {\r\n",
      "                                    assert (max(13, 13) == max(13, 13)) {\r\n",
      "recur$8:L_elem:\r\n",
      "                                      for recur$8:i in 0 : max(13, 13) : 1 {\r\n",
      "                                        y$5[recur$8:i] = abs(out$1[recur$8:i])\r\n",
      "                                      }\r\n",
      "L_elem$2:\r\n",
      "                                      for i$3 in 0 : 13 : 1 {\r\n",
      "                                        assert ((max(13, 13) == 13) || (max(13, 13) == 1)) {\r\n",
      "                                          y$3[i$3] = (y$5[(i$3 % max(13, 13))] + y$3[i$3])\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "einsum:Y:\r\n",
      "                        [cache] [GPUGlobal] einsum:Y: f32[64] {\r\n",
      "                          assert ((64 == 64) || (64 == 1)) {\r\n",
      "                            // prefer libs\r\n",
      "                            for einsum:i in 0 : max(64, 64) : 1 {\r\n",
      "                              einsum:Y[(einsum:i % 64)] = 0\r\n",
      "                              assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                // prefer libs\r\n",
      "                                for einsum:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                  einsum:Y[(einsum:i % 64)] = (einsum:Y[(einsum:i % 64)] + (x[i, (einsum:i$1 % 13)] * w0[(0 + (einsum:i$1 % (13 - 0))), (einsum:i % 64)]))\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "einsum$1:Y:\r\n",
      "                            [cache] [GPUGlobal] einsum$1:Y: f32[64] {\r\n",
      "                              assert ((64 == 64) || (64 == 1)) {\r\n",
      "                                // prefer libs\r\n",
      "                                for einsum$1:i in 0 : max(64, 64) : 1 {\r\n",
      "                                  einsum$1:Y[(einsum$1:i % 64)] = 0\r\n",
      "                                  assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                    // prefer libs\r\n",
      "                                    for einsum$1:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                      einsum$1:Y[(einsum$1:i % 64)] = (einsum$1:Y[(einsum$1:i % 64)] + (y$1[(einsum$1:i$1 % 13)] * w1[(0 + (einsum$1:i$1 % (13 - 0))), (einsum$1:i % 64)]))\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "einsum$2:Y:\r\n",
      "                                [cache] [GPUGlobal] einsum$2:Y: f32[64] {\r\n",
      "                                  assert ((64 == 64) || (64 == 1)) {\r\n",
      "                                    // prefer libs\r\n",
      "                                    for einsum$2:i in 0 : max(64, 64) : 1 {\r\n",
      "                                      einsum$2:Y[(einsum$2:i % 64)] = 0\r\n",
      "                                      assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                        // prefer libs\r\n",
      "                                        for einsum$2:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                          einsum$2:Y[(einsum$2:i % 64)] = (einsum$2:Y[(einsum$2:i % 64)] + (y$2[(einsum$2:i$1 % 13)] * w2[(0 + (einsum$2:i$1 % (13 - 0))), (einsum$2:i % 64)]))\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "einsum$3:Y:\r\n",
      "                                    [cache] [GPUGlobal] einsum$3:Y: f32[64] {\r\n",
      "                                      assert ((64 == 64) || (64 == 1)) {\r\n",
      "                                        // prefer libs\r\n",
      "                                        for einsum$3:i in 0 : max(64, 64) : 1 {\r\n",
      "                                          einsum$3:Y[(einsum$3:i % 64)] = 0\r\n",
      "                                          assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                              einsum$3:Y[(einsum$3:i % 64)] = (einsum$3:Y[(einsum$3:i % 64)] + (y$3[(einsum$3:i$1 % 13)] * w3[(0 + (einsum$3:i$1 % (13 - 0))), (einsum$3:i % 64)]))\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "out$2:\r\n",
      "                                        [cache] [GPUGlobal] out$2: f32[max(64, 64)] {\r\n",
      "recur$10:L_elem:\r\n",
      "                                          for recur$10:i in 0 : max(64, 64) : 1 {\r\n",
      "                                            assert ((64 == max(64, 64)) || (64 == 1)) {\r\n",
      "                                              assert ((64 == max(64, 64)) || (64 == 1)) {\r\n",
      "                                                out$2[recur$10:i] = (einsum:Y[(recur$10:i % 64)] + einsum$1:Y[(recur$10:i % 64)])\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "out$3:\r\n",
      "                                          [cache] [GPUGlobal] out$3: f32[max(max(64, 64), 64)] {\r\n",
      "recur$11:L_elem:\r\n",
      "                                            for recur$11:i in 0 : max(max(64, 64), 64) : 1 {\r\n",
      "                                              assert ((max(64, 64) == max(max(64, 64), 64)) || (max(64, 64) == 1)) {\r\n",
      "                                                assert ((64 == max(max(64, 64), 64)) || (64 == 1)) {\r\n",
      "                                                  out$3[recur$11:i] = (out$2[(recur$11:i % max(64, 64))] + einsum$2:Y[(recur$11:i % 64)])\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "out$4:\r\n",
      "                                            [cache] [GPUGlobal] out$4: f32[max(max(max(64, 64), 64), 64)] {\r\n",
      "recur$12:L_elem:\r\n",
      "                                              for recur$12:i in 0 : max(max(max(64, 64), 64), 64) : 1 {\r\n",
      "                                                assert ((max(max(64, 64), 64) == max(max(max(64, 64), 64), 64)) || (max(max(64, 64), 64) == 1)) {\r\n",
      "                                                  assert ((64 == max(max(max(64, 64), 64), 64)) || (64 == 1)) {\r\n",
      "                                                    out$4[recur$12:i] = (out$3[(recur$12:i % max(max(64, 64), 64))] + einsum$3:Y[(recur$12:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "L_elem$3:\r\n",
      "                                              for i$4 in 0 : 64 : 1 {\r\n",
      "                                                assert ((max(max(max(64, 64), 64), 64) == 64) || (max(max(max(64, 64), 64), 64) == 1)) {\r\n",
      "                                                  y[i, i$4] = out$4[(i$4 % max(max(max(64, 64), 64), 64))]\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "func(adj, x, w0, w1, w2, w3, y) {\r\n",
      "adj:\r\n",
      "  [in] [GPUGlobal] adj: i32[36864] {\r\n",
      "x:\r\n",
      "    [in] [GPUGlobal] x: f32[159744] {\r\n",
      "w0:\r\n",
      "      [in] [GPUGlobal] w0: f32[832] {\r\n",
      "w1:\r\n",
      "        [in] [GPUGlobal] w1: f32[832] {\r\n",
      "w2:\r\n",
      "          [in] [GPUGlobal] w2: f32[832] {\r\n",
      "w3:\r\n",
      "            [in] [GPUGlobal] w3: f32[832] {\r\n",
      "y:\r\n",
      "              [out] [GPUGlobal] y: f32[786432] {\r\n",
      "                // parallel = blockIdx.x\r\n",
      "                for .blockIdx.x in 0 : 1536 : 1 {\r\n",
      "                  // parallel = threadIdx.y\r\n",
      "                  for .threadIdx.y in 0 : 8 : 1 {\r\n",
      "                    // parallel = threadIdx.x\r\n",
      "                    for .threadIdx.x in 0 : 32 : 1 {\r\n",
      "y$1:\r\n",
      "                      [cache] [GPUShared] y$1: f32[104] {\r\n",
      "y$2:\r\n",
      "                        [cache] [GPUShared] y$2: f32[104] {\r\n",
      "y$3:\r\n",
      "                          [cache] [GPUShared] y$3: f32[104] {\r\n",
      "                            if (.threadIdx.x == 0) {\r\n",
      "fused.fused.recur:L_elem.recur$1:L_elem.recur$2:L_elem:\r\n",
      "                              for recur:i in 0 : 13 : 1 {\r\n",
      "                                y$1[((.threadIdx.y * 13) + recur:i)] = 0\r\n",
      "                                y$2[((.threadIdx.y * 13) + recur:i)] = 0\r\n",
      "                                y$3[((.threadIdx.y * 13) + recur:i)] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            intrinsic(\"__syncwarp()\")\r\n",
      "                            if (.threadIdx.x < 13) {\r\n",
      "                              // unroll\r\n",
      "                              for p in 0 : 3 : 1 {\r\n",
      "                                y$1[((.threadIdx.y * 13) + .threadIdx.x)] += x[((adj[(((24 * .blockIdx.x) + (3 * .threadIdx.y)) + p)] * 13) + .threadIdx.x)]\r\n",
      "                                y$2[((.threadIdx.y * 13) + .threadIdx.x)] += abs((x[((adj[(((24 * .blockIdx.x) + (3 * .threadIdx.y)) + p)] * 13) + .threadIdx.x)] - x[((adj[(((24 * .blockIdx.x) + (3 * .threadIdx.y)) + ((p + 1) %% 3))] * 13) + .threadIdx.x)]))\r\n",
      "                                y$3[((.threadIdx.y * 13) + .threadIdx.x)] += abs((x[((adj[(((24 * .blockIdx.x) + (3 * .threadIdx.y)) + p)] * 13) + .threadIdx.x)] - x[(((104 * .blockIdx.x) + .threadIdx.x) + (13 * .threadIdx.y))]))\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            intrinsic(\"__syncwarp()\")\r\n",
      "fused.fused.fused.fused.fused.fused.fused.#30.#36.#42.#48.recur$10:L_elem.recur$11:L_elem.recur$12:L_elem.L_elem$3.0:\r\n",
      "                            // unroll\r\n",
      "                            for einsum:i.0 in 0 : 2 : 1 {\r\n",
      "einsum:Y:\r\n",
      "                              [cache] [GPULocal] einsum:Y: f32[1] {\r\n",
      "                                einsum:Y[0] = 0\r\n",
      "einsum$1:Y:\r\n",
      "                                [cache] [GPULocal] einsum$1:Y: f32[1] {\r\n",
      "                                  einsum$1:Y[0] = 0\r\n",
      "einsum$2:Y:\r\n",
      "                                  [cache] [GPULocal] einsum$2:Y: f32[1] {\r\n",
      "                                    einsum$2:Y[0] = 0\r\n",
      "einsum$3:Y:\r\n",
      "                                    [cache] [GPULocal] einsum$3:Y: f32[1] {\r\n",
      "                                      einsum$3:Y[0] = 0\r\n",
      "fused.fused.fused.#27.#33.#39.#45:\r\n",
      "                                      for einsum:i$1 in 0 : 13 : 1 {\r\n",
      "                                        einsum:Y[0] += (x[(((104 * .blockIdx.x) + (13 * .threadIdx.y)) + einsum:i$1)] * w0[((einsum:i$1 * 64) + ((einsum:i.0 * 32) + .threadIdx.x))])\r\n",
      "                                        einsum$1:Y[0] += (y$1[((.threadIdx.y * 13) + einsum:i$1)] * w1[((einsum:i$1 * 64) + ((einsum:i.0 * 32) + .threadIdx.x))])\r\n",
      "                                        einsum$2:Y[0] += (y$2[((.threadIdx.y * 13) + einsum:i$1)] * w2[((einsum:i$1 * 64) + ((einsum:i.0 * 32) + .threadIdx.x))])\r\n",
      "                                        einsum$3:Y[0] += (y$3[((.threadIdx.y * 13) + einsum:i$1)] * w3[((einsum:i$1 * 64) + ((einsum:i.0 * 32) + .threadIdx.x))])\r\n",
      "                                      }\r\n",
      "                                      y[((((512 * .blockIdx.x) + (32 * einsum:i.0)) + .threadIdx.x) + (64 * .threadIdx.y))] = (((einsum:Y[0] + einsum$1:Y[0]) + einsum$2:Y[0]) + einsum$3:Y[0])\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "\u001b[33m 1\u001b[0m \r\n",
      "\u001b[33m 2\u001b[0m #include <gpu_runtime.h>\r\n",
      "\u001b[33m 3\u001b[0m \r\n",
      "\u001b[33m 4\u001b[0m extern __shared__ uint8_t __shmem[];\r\n",
      "\u001b[33m 5\u001b[0m \r\n",
      "\u001b[33m 6\u001b[0m extern \"C\" {\r\n",
      "\u001b[33m 7\u001b[0m __global__ void __launch_bounds__(32 * 8 * 1) kernel0(float (*restrict y), const int32_t (*restrict adj), const float (*restrict w3), const float (*restrict x), const float (*restrict w0), const float (*restrict w1), const float (*restrict w2), uint8_t *__glmem) {\r\n",
      "\u001b[33m 8\u001b[0m   float (*y_361) = (float(*))(__shmem + 0);\r\n",
      "\u001b[33m 9\u001b[0m   float (*y_362) = (float(*))(__shmem + 416);\r\n",
      "\u001b[33m10\u001b[0m   float (*y_363) = (float(*))(__shmem + 832);\r\n",
      "\u001b[33m11\u001b[0m   if (((int)threadIdx.x == 0)) {\r\n",
      "\u001b[33m12\u001b[0m     for (int recur_58i = 0; recur_58i < 13; recur_58i++) {\r\n",
      "\u001b[33m13\u001b[0m       y_361[(((int)threadIdx.y * 13) + recur_58i)] = 0;\r\n",
      "\u001b[33m14\u001b[0m       y_362[(((int)threadIdx.y * 13) + recur_58i)] = 0;\r\n",
      "\u001b[33m15\u001b[0m       y_363[(((int)threadIdx.y * 13) + recur_58i)] = 0;\r\n",
      "\u001b[33m16\u001b[0m     }\r\n",
      "\u001b[33m17\u001b[0m   }\r\n",
      "\u001b[33m18\u001b[0m   (__syncwarp());\r\n",
      "\u001b[33m19\u001b[0m   if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m20\u001b[0m #pragma unroll 3\r\n",
      "\u001b[33m21\u001b[0m     for (int p = 0; p < 3; p++) {\r\n",
      "\u001b[33m22\u001b[0m       y_361[(((int)threadIdx.y * 13) + (int)threadIdx.x)] += x[((adj[(((24 * (int)blockIdx.x) + (3 * (int)threadIdx.y)) + p)] * 13) + (int)threadIdx.x)];\r\n",
      "\u001b[33m23\u001b[0m       y_362[(((int)threadIdx.y * 13) + (int)threadIdx.x)] += runtime_abs((x[((adj[(((24 * (int)blockIdx.x) + (3 * (int)threadIdx.y)) + p)] * 13) + (int)threadIdx.x)] - x[((adj[(((24 * (int)blockIdx.x) + (3 * (int)threadIdx.y)) + ((p + 1) % 3))] * 13) + (int)threadIdx.x)]));\r\n",
      "\u001b[33m24\u001b[0m       y_363[(((int)threadIdx.y * 13) + (int)threadIdx.x)] += runtime_abs((x[((adj[(((24 * (int)blockIdx.x) + (3 * (int)threadIdx.y)) + p)] * 13) + (int)threadIdx.x)] - x[(((104 * (int)blockIdx.x) + (int)threadIdx.x) + (13 * (int)threadIdx.y))]));\r\n",
      "\u001b[33m25\u001b[0m     }\r\n",
      "\u001b[33m26\u001b[0m   }\r\n",
      "\u001b[33m27\u001b[0m   (__syncwarp());\r\n",
      "\u001b[33m28\u001b[0m #pragma unroll 2\r\n",
      "\u001b[33m29\u001b[0m   for (int einsum_58i_460 = 0; einsum_58i_460 < 2; einsum_58i_460++) {\r\n",
      "\u001b[33m30\u001b[0m     float einsum_58Y[1];\r\n",
      "\u001b[33m31\u001b[0m     einsum_58Y[0] = 0;\r\n",
      "\u001b[33m32\u001b[0m     {\r\n",
      "\u001b[33m33\u001b[0m       float einsum_361_58Y[1];\r\n",
      "\u001b[33m34\u001b[0m       einsum_361_58Y[0] = 0;\r\n",
      "\u001b[33m35\u001b[0m       {\r\n",
      "\u001b[33m36\u001b[0m         float einsum_362_58Y[1];\r\n",
      "\u001b[33m37\u001b[0m         einsum_362_58Y[0] = 0;\r\n",
      "\u001b[33m38\u001b[0m         {\r\n",
      "\u001b[33m39\u001b[0m           float einsum_363_58Y[1];\r\n",
      "\u001b[33m40\u001b[0m           einsum_363_58Y[0] = 0;\r\n",
      "\u001b[33m41\u001b[0m           for (int einsum_58i_361 = 0; einsum_58i_361 < 13; einsum_58i_361++) {\r\n",
      "\u001b[33m42\u001b[0m             einsum_58Y[0] += (x[(((104 * (int)blockIdx.x) + (13 * (int)threadIdx.y)) + einsum_58i_361)] * w0[((einsum_58i_361 * 64) + ((einsum_58i_460 * 32) + (int)threadIdx.x))]);\r\n",
      "\u001b[33m43\u001b[0m             einsum_361_58Y[0] += (y_361[(((int)threadIdx.y * 13) + einsum_58i_361)] * w1[((einsum_58i_361 * 64) + ((einsum_58i_460 * 32) + (int)threadIdx.x))]);\r\n",
      "\u001b[33m44\u001b[0m             einsum_362_58Y[0] += (y_362[(((int)threadIdx.y * 13) + einsum_58i_361)] * w2[((einsum_58i_361 * 64) + ((einsum_58i_460 * 32) + (int)threadIdx.x))]);\r\n",
      "\u001b[33m45\u001b[0m             einsum_363_58Y[0] += (y_363[(((int)threadIdx.y * 13) + einsum_58i_361)] * w3[((einsum_58i_361 * 64) + ((einsum_58i_460 * 32) + (int)threadIdx.x))]);\r\n",
      "\u001b[33m46\u001b[0m           }\r\n",
      "\u001b[33m47\u001b[0m           y[((((512 * (int)blockIdx.x) + (32 * einsum_58i_460)) + (int)threadIdx.x) + (64 * (int)threadIdx.y))] = (((einsum_58Y[0] + einsum_361_58Y[0]) + einsum_362_58Y[0]) + einsum_363_58Y[0]);\r\n",
      "\u001b[33m48\u001b[0m         }\r\n",
      "\u001b[33m49\u001b[0m       }\r\n",
      "\u001b[33m50\u001b[0m     }\r\n",
      "\u001b[33m51\u001b[0m   }\r\n",
      "\u001b[33m52\u001b[0m }\r\n",
      "\u001b[33m53\u001b[0m \r\n",
      "\u001b[33m54\u001b[0m void run(void **_params, void **_returns, size_t **_retShapes, size_t *_retDims, GPUContext_t _ctx) {\r\n",
      "\u001b[33m55\u001b[0m   const int32_t (*restrict adj) = (int32_t(*))_params[0];\r\n",
      "\u001b[33m56\u001b[0m   const float (*restrict x) = (float(*))_params[1];\r\n",
      "\u001b[33m57\u001b[0m   const float (*restrict w0) = (float(*))_params[2];\r\n",
      "\u001b[33m58\u001b[0m   const float (*restrict w1) = (float(*))_params[3];\r\n",
      "\u001b[33m59\u001b[0m   const float (*restrict w2) = (float(*))_params[4];\r\n",
      "\u001b[33m60\u001b[0m   const float (*restrict w3) = (float(*))_params[5];\r\n",
      "\u001b[33m61\u001b[0m   float (*restrict y) = (float(*))_params[6];\r\n",
      "\u001b[33m62\u001b[0m   {\r\n",
      "\u001b[33m63\u001b[0m     uint8_t *__glmem = NULL;\r\n",
      "\u001b[33m64\u001b[0m     cudaFuncSetAttribute(kernel0, cudaFuncAttributeMaxDynamicSharedMemorySize, 1248);\r\n",
      "\u001b[33m65\u001b[0m     kernel0<<<dim3(1536, 1, 1), dim3(32, 8, 1), 1248>>>(y, adj, w3, x, w0, w1, w2, __glmem);\r\n",
      "\u001b[33m66\u001b[0m   }\r\n",
      "\u001b[33m67\u001b[0m }\r\n",
      "\u001b[33m68\u001b[0m \r\n",
      "\u001b[33m69\u001b[0m }\r\n",
      "Inference compiling time: 14.724793672561646s\r\n",
      "# Forward:\r\n",
      "func(adj, x, w0, w1, w2, w3, y) {\r\n",
      "adj:\r\n",
      "  [in] [GPUGlobal] adj: i32[12288, 3] {\r\n",
      "x:\r\n",
      "    [in] [GPUGlobal] x: f32[12288, 13] {\r\n",
      "w0:\r\n",
      "      [in] [GPUGlobal] w0: f32[13, 64] {\r\n",
      "w1:\r\n",
      "        [in] [GPUGlobal] w1: f32[13, 64] {\r\n",
      "w2:\r\n",
      "          [in] [GPUGlobal] w2: f32[13, 64] {\r\n",
      "w3:\r\n",
      "            [in] [GPUGlobal] w3: f32[13, 64] {\r\n",
      "y:\r\n",
      "              [out] [GPUGlobal] y: f32[12288, 64] {\r\n",
      "                for i in 0 : 12288 : 1 {\r\n",
      "y$1:\r\n",
      "                  [cache] [GPUGlobal] y$1: f32[13] {\r\n",
      "y$2:\r\n",
      "                    [cache] [GPUGlobal] y$2: f32[13] {\r\n",
      "y$3:\r\n",
      "                      [cache] [GPUGlobal] y$3: f32[13] {\r\n",
      "einsum:Y:\r\n",
      "                        [cache] [GPUGlobal] einsum:Y: f32[64] {\r\n",
      "recur:L_elem:\r\n",
      "                          for recur:i in 0 : 13 : 1 {\r\n",
      "                            y$1[recur:i] = 0\r\n",
      "                          }\r\n",
      "recur$1:L_elem:\r\n",
      "                          for recur$1:i in 0 : 13 : 1 {\r\n",
      "                            y$2[recur$1:i] = 0\r\n",
      "                          }\r\n",
      "recur$2:L_elem:\r\n",
      "                          for recur$2:i in 0 : 13 : 1 {\r\n",
      "                            y$3[recur$2:i] = 0\r\n",
      "                          }\r\n",
      "                          for p in 0 : 3 : 1 {\r\n",
      "out:\r\n",
      "                            [cache] [GPUGlobal] out: f32[max(13, 13)] {\r\n",
      "y$4:\r\n",
      "                              [cache] [GPUGlobal] y$4: f32[max(13, 13)] {\r\n",
      "L_elem:\r\n",
      "                                for i$1 in 0 : 13 : 1 {\r\n",
      "                                  assert ((13 == 13) || (13 == 1)) {\r\n",
      "                                    y$1[i$1] += x[adj[i, p], (i$1 % 13)]\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "recur$4:L_elem:\r\n",
      "                                for recur$4:i in 0 : max(13, 13) : 1 {\r\n",
      "                                  assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                    assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                      out[recur$4:i] = (x[adj[i, p], (recur$4:i % 13)] - x[adj[i, ((p + 1) % 3)], (recur$4:i % 13)])\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                                assert (max(13, 13) == max(13, 13)) {\r\n",
      "out$1:\r\n",
      "                                  [cache] [GPUGlobal] out$1: f32[max(13, 13)] {\r\n",
      "y$5:\r\n",
      "                                    [cache] [GPUGlobal] y$5: f32[max(13, 13)] {\r\n",
      "recur$5:L_elem:\r\n",
      "                                      for recur$5:i in 0 : max(13, 13) : 1 {\r\n",
      "                                        y$4[recur$5:i] = abs(out[recur$5:i])\r\n",
      "                                      }\r\n",
      "L_elem$1:\r\n",
      "                                      for i$2 in 0 : 13 : 1 {\r\n",
      "                                        assert ((max(13, 13) == 13) || (max(13, 13) == 1)) {\r\n",
      "                                          y$2[i$2] += y$4[(i$2 % max(13, 13))]\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "recur$7:L_elem:\r\n",
      "                                      for recur$7:i in 0 : max(13, 13) : 1 {\r\n",
      "                                        assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                          assert ((13 == max(13, 13)) || (13 == 1)) {\r\n",
      "                                            out$1[recur$7:i] = (x[adj[i, p], (recur$7:i % 13)] - x[i, (recur$7:i % 13)])\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                      assert (max(13, 13) == max(13, 13)) {\r\n",
      "recur$8:L_elem:\r\n",
      "                                        for recur$8:i in 0 : max(13, 13) : 1 {\r\n",
      "                                          y$5[recur$8:i] = abs(out$1[recur$8:i])\r\n",
      "                                        }\r\n",
      "L_elem$2:\r\n",
      "                                        for i$3 in 0 : 13 : 1 {\r\n",
      "                                          assert ((max(13, 13) == 13) || (max(13, 13) == 1)) {\r\n",
      "                                            y$3[i$3] += y$5[(i$3 % max(13, 13))]\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                          assert ((64 == 64) || (64 == 1)) {\r\n",
      "einsum$1:Y:\r\n",
      "                            [cache] [GPUGlobal] einsum$1:Y: f32[64] {\r\n",
      "                              // prefer libs\r\n",
      "                              for einsum:i in 0 : max(64, 64) : 1 {\r\n",
      "                                einsum:Y[(einsum:i % 64)] = 0\r\n",
      "                                assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                  // prefer libs\r\n",
      "                                  for einsum:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                    einsum:Y[(einsum:i % 64)] += (x[i, (einsum:i$1 % 13)] * w0[(0 + (einsum:i$1 % (13 - 0))), (einsum:i % 64)])\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                              assert ((64 == 64) || (64 == 1)) {\r\n",
      "einsum$2:Y:\r\n",
      "                                [cache] [GPUGlobal] einsum$2:Y: f32[64] {\r\n",
      "                                  // prefer libs\r\n",
      "                                  for einsum$1:i in 0 : max(64, 64) : 1 {\r\n",
      "                                    einsum$1:Y[(einsum$1:i % 64)] = 0\r\n",
      "                                    assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                      // prefer libs\r\n",
      "                                      for einsum$1:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                        einsum$1:Y[(einsum$1:i % 64)] += (y$1[(einsum$1:i$1 % 13)] * w1[(0 + (einsum$1:i$1 % (13 - 0))), (einsum$1:i % 64)])\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                  assert ((64 == 64) || (64 == 1)) {\r\n",
      "einsum$3:Y:\r\n",
      "                                    [cache] [GPUGlobal] einsum$3:Y: f32[64] {\r\n",
      "                                      // prefer libs\r\n",
      "                                      for einsum$2:i in 0 : max(64, 64) : 1 {\r\n",
      "                                        einsum$2:Y[(einsum$2:i % 64)] = 0\r\n",
      "                                        assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$2:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                            einsum$2:Y[(einsum$2:i % 64)] += (y$2[(einsum$2:i$1 % 13)] * w2[(0 + (einsum$2:i$1 % (13 - 0))), (einsum$2:i % 64)])\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                      assert ((64 == 64) || (64 == 1)) {\r\n",
      "out$2:\r\n",
      "                                        [cache] [GPUGlobal] out$2: f32[max(64, 64)] {\r\n",
      "out$3:\r\n",
      "                                          [cache] [GPUGlobal] out$3: f32[max(max(64, 64), 64)] {\r\n",
      "out$4:\r\n",
      "                                            [cache] [GPUGlobal] out$4: f32[max(max(max(64, 64), 64), 64)] {\r\n",
      "                                              // prefer libs\r\n",
      "                                              for einsum$3:i in 0 : max(64, 64) : 1 {\r\n",
      "                                                einsum$3:Y[(einsum$3:i % 64)] = 0\r\n",
      "                                                assert (((13 == max(13, (13 - 0))) || (13 == 1)) && (((13 - 0) == max(13, (13 - 0))) || ((13 - 0) == 1))) {\r\n",
      "                                                  // prefer libs\r\n",
      "                                                  for einsum$3:i$1 in 0 : max(13, (13 - 0)) : 1 {\r\n",
      "                                                    einsum$3:Y[(einsum$3:i % 64)] += (y$3[(einsum$3:i$1 % 13)] * w3[(0 + (einsum$3:i$1 % (13 - 0))), (einsum$3:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "recur$10:L_elem:\r\n",
      "                                              for recur$10:i in 0 : max(64, 64) : 1 {\r\n",
      "                                                assert ((64 == max(64, 64)) || (64 == 1)) {\r\n",
      "                                                  assert ((64 == max(64, 64)) || (64 == 1)) {\r\n",
      "                                                    out$2[recur$10:i] = (einsum:Y[(recur$10:i % 64)] + einsum$1:Y[(recur$10:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "recur$11:L_elem:\r\n",
      "                                              for recur$11:i in 0 : max(max(64, 64), 64) : 1 {\r\n",
      "                                                assert ((max(64, 64) == max(max(64, 64), 64)) || (max(64, 64) == 1)) {\r\n",
      "                                                  assert ((64 == max(max(64, 64), 64)) || (64 == 1)) {\r\n",
      "                                                    out$3[recur$11:i] = (out$2[(recur$11:i % max(64, 64))] + einsum$2:Y[(recur$11:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "recur$12:L_elem:\r\n",
      "                                              for recur$12:i in 0 : max(max(max(64, 64), 64), 64) : 1 {\r\n",
      "                                                assert ((max(max(64, 64), 64) == max(max(max(64, 64), 64), 64)) || (max(max(64, 64), 64) == 1)) {\r\n",
      "                                                  assert ((64 == max(max(max(64, 64), 64), 64)) || (64 == 1)) {\r\n",
      "                                                    out$4[recur$12:i] = (out$3[(recur$12:i % max(max(64, 64), 64))] + einsum$3:Y[(recur$12:i % 64)])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "L_elem$3:\r\n",
      "                                              for i$4 in 0 : 64 : 1 {\r\n",
      "                                                assert ((max(max(max(64, 64), 64), 64) == 64) || (max(max(max(64, 64), 64), 64) == 1)) {\r\n",
      "                                                  y[i, i$4] = out$4[(i$4 % max(max(max(64, 64), 64), 64))]\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "func(adj, x, w0, w1, w2, w3, y) {\r\n",
      "adj:\r\n",
      "  [in] [GPUGlobal] adj: i32[36864] {\r\n",
      "x:\r\n",
      "    [in] [GPUGlobal] x: f32[159744] {\r\n",
      "w0:\r\n",
      "      [in] [GPUGlobal] w0: f32[832] {\r\n",
      "w1:\r\n",
      "        [in] [GPUGlobal] w1: f32[832] {\r\n",
      "w2:\r\n",
      "          [in] [GPUGlobal] w2: f32[832] {\r\n",
      "w3:\r\n",
      "            [in] [GPUGlobal] w3: f32[832] {\r\n",
      "y:\r\n",
      "              [out] [GPUGlobal] y: f32[786432] {\r\n",
      "                // parallel = blockIdx.x\r\n",
      "                for .blockIdx.x in 0 : 1536 : 1 {\r\n",
      "                  // parallel = threadIdx.y\r\n",
      "                  for .threadIdx.y in 0 : 8 : 1 {\r\n",
      "                    // parallel = threadIdx.x\r\n",
      "                    for .threadIdx.x in 0 : 32 : 1 {\r\n",
      "y$1:\r\n",
      "                      [cache] [GPUShared] y$1: f32[104] {\r\n",
      "y$2:\r\n",
      "                        [cache] [GPUShared] y$2: f32[104] {\r\n",
      "y$3:\r\n",
      "                          [cache] [GPUShared] y$3: f32[104] {\r\n",
      "                            if (.threadIdx.x == 0) {\r\n",
      "fused.fused.recur:L_elem.recur$1:L_elem.recur$2:L_elem:\r\n",
      "                              for recur:i in 0 : 13 : 1 {\r\n",
      "                                y$1[((.threadIdx.y * 13) + recur:i)] = 0\r\n",
      "                                y$2[((.threadIdx.y * 13) + recur:i)] = 0\r\n",
      "                                y$3[((.threadIdx.y * 13) + recur:i)] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            intrinsic(\"__syncwarp()\")\r\n",
      "                            if (.threadIdx.x < 13) {\r\n",
      "                              // unroll\r\n",
      "                              for p in 0 : 3 : 1 {\r\n",
      "                                y$1[((.threadIdx.y * 13) + .threadIdx.x)] += x[((adj[(((24 * .blockIdx.x) + (3 * .threadIdx.y)) + p)] * 13) + .threadIdx.x)]\r\n",
      "                                y$2[((.threadIdx.y * 13) + .threadIdx.x)] += abs((x[((adj[(((24 * .blockIdx.x) + (3 * .threadIdx.y)) + p)] * 13) + .threadIdx.x)] - x[((adj[(((24 * .blockIdx.x) + (3 * .threadIdx.y)) + ((p + 1) %% 3))] * 13) + .threadIdx.x)]))\r\n",
      "                                y$3[((.threadIdx.y * 13) + .threadIdx.x)] += abs((x[((adj[(((24 * .blockIdx.x) + (3 * .threadIdx.y)) + p)] * 13) + .threadIdx.x)] - x[(((104 * .blockIdx.x) + .threadIdx.x) + (13 * .threadIdx.y))]))\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            intrinsic(\"__syncwarp()\")\r\n",
      "fused.fused.fused.fused.fused.fused.fused.#30.#36.#42.#48.recur$10:L_elem.recur$11:L_elem.recur$12:L_elem.L_elem$3.0:\r\n",
      "                            // unroll\r\n",
      "                            for einsum:i.0 in 0 : 2 : 1 {\r\n",
      "einsum:Y:\r\n",
      "                              [cache] [GPULocal] einsum:Y: f32[1] {\r\n",
      "                                einsum:Y[0] = 0\r\n",
      "einsum$1:Y:\r\n",
      "                                [cache] [GPULocal] einsum$1:Y: f32[1] {\r\n",
      "                                  einsum$1:Y[0] = 0\r\n",
      "einsum$2:Y:\r\n",
      "                                  [cache] [GPULocal] einsum$2:Y: f32[1] {\r\n",
      "                                    einsum$2:Y[0] = 0\r\n",
      "einsum$3:Y:\r\n",
      "                                    [cache] [GPULocal] einsum$3:Y: f32[1] {\r\n",
      "                                      einsum$3:Y[0] = 0\r\n",
      "fused.fused.fused.#27.#33.#39.#45:\r\n",
      "                                      for einsum:i$1 in 0 : 13 : 1 {\r\n",
      "                                        einsum:Y[0] += (x[(((104 * .blockIdx.x) + (13 * .threadIdx.y)) + einsum:i$1)] * w0[((einsum:i$1 * 64) + ((einsum:i.0 * 32) + .threadIdx.x))])\r\n",
      "                                        einsum$1:Y[0] += (y$1[((.threadIdx.y * 13) + einsum:i$1)] * w1[((einsum:i$1 * 64) + ((einsum:i.0 * 32) + .threadIdx.x))])\r\n",
      "                                        einsum$2:Y[0] += (y$2[((.threadIdx.y * 13) + einsum:i$1)] * w2[((einsum:i$1 * 64) + ((einsum:i.0 * 32) + .threadIdx.x))])\r\n",
      "                                        einsum$3:Y[0] += (y$3[((.threadIdx.y * 13) + einsum:i$1)] * w3[((einsum:i$1 * 64) + ((einsum:i.0 * 32) + .threadIdx.x))])\r\n",
      "                                      }\r\n",
      "                                      y[((((512 * .blockIdx.x) + (32 * einsum:i.0)) + .threadIdx.x) + (64 * .threadIdx.y))] = (((einsum:Y[0] + einsum$1:Y[0]) + einsum$2:Y[0]) + einsum$3:Y[0])\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "\u001b[33m 1\u001b[0m \r\n",
      "\u001b[33m 2\u001b[0m #include <gpu_runtime.h>\r\n",
      "\u001b[33m 3\u001b[0m \r\n",
      "\u001b[33m 4\u001b[0m extern __shared__ uint8_t __shmem[];\r\n",
      "\u001b[33m 5\u001b[0m \r\n",
      "\u001b[33m 6\u001b[0m extern \"C\" {\r\n",
      "\u001b[33m 7\u001b[0m __global__ void __launch_bounds__(32 * 8 * 1) kernel0(float (*restrict y), const int32_t (*restrict adj), const float (*restrict w3), const float (*restrict x), const float (*restrict w0), const float (*restrict w1), const float (*restrict w2), uint8_t *__glmem) {\r\n",
      "\u001b[33m 8\u001b[0m   float (*y_361) = (float(*))(__shmem + 0);\r\n",
      "\u001b[33m 9\u001b[0m   float (*y_362) = (float(*))(__shmem + 416);\r\n",
      "\u001b[33m10\u001b[0m   float (*y_363) = (float(*))(__shmem + 832);\r\n",
      "\u001b[33m11\u001b[0m   if (((int)threadIdx.x == 0)) {\r\n",
      "\u001b[33m12\u001b[0m     for (int recur_58i = 0; recur_58i < 13; recur_58i++) {\r\n",
      "\u001b[33m13\u001b[0m       y_361[(((int)threadIdx.y * 13) + recur_58i)] = 0;\r\n",
      "\u001b[33m14\u001b[0m       y_362[(((int)threadIdx.y * 13) + recur_58i)] = 0;\r\n",
      "\u001b[33m15\u001b[0m       y_363[(((int)threadIdx.y * 13) + recur_58i)] = 0;\r\n",
      "\u001b[33m16\u001b[0m     }\r\n",
      "\u001b[33m17\u001b[0m   }\r\n",
      "\u001b[33m18\u001b[0m   (__syncwarp());\r\n",
      "\u001b[33m19\u001b[0m   if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m20\u001b[0m #pragma unroll 3\r\n",
      "\u001b[33m21\u001b[0m     for (int p = 0; p < 3; p++) {\r\n",
      "\u001b[33m22\u001b[0m       y_361[(((int)threadIdx.y * 13) + (int)threadIdx.x)] += x[((adj[(((24 * (int)blockIdx.x) + (3 * (int)threadIdx.y)) + p)] * 13) + (int)threadIdx.x)];\r\n",
      "\u001b[33m23\u001b[0m       y_362[(((int)threadIdx.y * 13) + (int)threadIdx.x)] += runtime_abs((x[((adj[(((24 * (int)blockIdx.x) + (3 * (int)threadIdx.y)) + p)] * 13) + (int)threadIdx.x)] - x[((adj[(((24 * (int)blockIdx.x) + (3 * (int)threadIdx.y)) + ((p + 1) % 3))] * 13) + (int)threadIdx.x)]));\r\n",
      "\u001b[33m24\u001b[0m       y_363[(((int)threadIdx.y * 13) + (int)threadIdx.x)] += runtime_abs((x[((adj[(((24 * (int)blockIdx.x) + (3 * (int)threadIdx.y)) + p)] * 13) + (int)threadIdx.x)] - x[(((104 * (int)blockIdx.x) + (int)threadIdx.x) + (13 * (int)threadIdx.y))]));\r\n",
      "\u001b[33m25\u001b[0m     }\r\n",
      "\u001b[33m26\u001b[0m   }\r\n",
      "\u001b[33m27\u001b[0m   (__syncwarp());\r\n",
      "\u001b[33m28\u001b[0m #pragma unroll 2\r\n",
      "\u001b[33m29\u001b[0m   for (int einsum_58i_460 = 0; einsum_58i_460 < 2; einsum_58i_460++) {\r\n",
      "\u001b[33m30\u001b[0m     float einsum_58Y[1];\r\n",
      "\u001b[33m31\u001b[0m     einsum_58Y[0] = 0;\r\n",
      "\u001b[33m32\u001b[0m     {\r\n",
      "\u001b[33m33\u001b[0m       float einsum_361_58Y[1];\r\n",
      "\u001b[33m34\u001b[0m       einsum_361_58Y[0] = 0;\r\n",
      "\u001b[33m35\u001b[0m       {\r\n",
      "\u001b[33m36\u001b[0m         float einsum_362_58Y[1];\r\n",
      "\u001b[33m37\u001b[0m         einsum_362_58Y[0] = 0;\r\n",
      "\u001b[33m38\u001b[0m         {\r\n",
      "\u001b[33m39\u001b[0m           float einsum_363_58Y[1];\r\n",
      "\u001b[33m40\u001b[0m           einsum_363_58Y[0] = 0;\r\n",
      "\u001b[33m41\u001b[0m           for (int einsum_58i_361 = 0; einsum_58i_361 < 13; einsum_58i_361++) {\r\n",
      "\u001b[33m42\u001b[0m             einsum_58Y[0] += (x[(((104 * (int)blockIdx.x) + (13 * (int)threadIdx.y)) + einsum_58i_361)] * w0[((einsum_58i_361 * 64) + ((einsum_58i_460 * 32) + (int)threadIdx.x))]);\r\n",
      "\u001b[33m43\u001b[0m             einsum_361_58Y[0] += (y_361[(((int)threadIdx.y * 13) + einsum_58i_361)] * w1[((einsum_58i_361 * 64) + ((einsum_58i_460 * 32) + (int)threadIdx.x))]);\r\n",
      "\u001b[33m44\u001b[0m             einsum_362_58Y[0] += (y_362[(((int)threadIdx.y * 13) + einsum_58i_361)] * w2[((einsum_58i_361 * 64) + ((einsum_58i_460 * 32) + (int)threadIdx.x))]);\r\n",
      "\u001b[33m45\u001b[0m             einsum_363_58Y[0] += (y_363[(((int)threadIdx.y * 13) + einsum_58i_361)] * w3[((einsum_58i_361 * 64) + ((einsum_58i_460 * 32) + (int)threadIdx.x))]);\r\n",
      "\u001b[33m46\u001b[0m           }\r\n",
      "\u001b[33m47\u001b[0m           y[((((512 * (int)blockIdx.x) + (32 * einsum_58i_460)) + (int)threadIdx.x) + (64 * (int)threadIdx.y))] = (((einsum_58Y[0] + einsum_361_58Y[0]) + einsum_362_58Y[0]) + einsum_363_58Y[0]);\r\n",
      "\u001b[33m48\u001b[0m         }\r\n",
      "\u001b[33m49\u001b[0m       }\r\n",
      "\u001b[33m50\u001b[0m     }\r\n",
      "\u001b[33m51\u001b[0m   }\r\n",
      "\u001b[33m52\u001b[0m }\r\n",
      "\u001b[33m53\u001b[0m \r\n",
      "\u001b[33m54\u001b[0m void run(void **_params, void **_returns, size_t **_retShapes, size_t *_retDims, GPUContext_t _ctx) {\r\n",
      "\u001b[33m55\u001b[0m   const int32_t (*restrict adj) = (int32_t(*))_params[0];\r\n",
      "\u001b[33m56\u001b[0m   const float (*restrict x) = (float(*))_params[1];\r\n",
      "\u001b[33m57\u001b[0m   const float (*restrict w0) = (float(*))_params[2];\r\n",
      "\u001b[33m58\u001b[0m   const float (*restrict w1) = (float(*))_params[3];\r\n",
      "\u001b[33m59\u001b[0m   const float (*restrict w2) = (float(*))_params[4];\r\n",
      "\u001b[33m60\u001b[0m   const float (*restrict w3) = (float(*))_params[5];\r\n",
      "\u001b[33m61\u001b[0m   float (*restrict y) = (float(*))_params[6];\r\n",
      "\u001b[33m62\u001b[0m   {\r\n",
      "\u001b[33m63\u001b[0m     uint8_t *__glmem = NULL;\r\n",
      "\u001b[33m64\u001b[0m     cudaFuncSetAttribute(kernel0, cudaFuncAttributeMaxDynamicSharedMemorySize, 1248);\r\n",
      "\u001b[33m65\u001b[0m     kernel0<<<dim3(1536, 1, 1), dim3(32, 8, 1), 1248>>>(y, adj, w3, x, w0, w1, w2, __glmem);\r\n",
      "\u001b[33m66\u001b[0m   }\r\n",
      "\u001b[33m67\u001b[0m }\r\n",
      "\u001b[33m68\u001b[0m \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m69\u001b[0m }\r\n",
      "# Backward:\r\n",
      "func(adj, x, w0, w1, w2, w3, y, x.grad, w0.grad, w1.grad, w3.grad, w2.grad, y.grad) {\r\n",
      "adj:\r\n",
      "  [in] [GPUGlobal] adj: i32[12288, 3] {\r\n",
      "x:\r\n",
      "    [in] [GPUGlobal] x: f32[12288, 13] {\r\n",
      "x.grad:\r\n",
      "      [out] [GPUGlobal] x.grad: f32[12288, 13] {\r\n",
      "w0:\r\n",
      "        [in] [GPUGlobal] w0: f32[13, 64] {\r\n",
      "w0.grad:\r\n",
      "          [out] [GPUGlobal] w0.grad: f32[13, 64] {\r\n",
      "w1:\r\n",
      "            [in] [GPUGlobal] w1: f32[13, 64] {\r\n",
      "w1.grad:\r\n",
      "              [out] [GPUGlobal] w1.grad: f32[13, 64] {\r\n",
      "w2:\r\n",
      "                [in] [GPUGlobal] w2: f32[13, 64] {\r\n",
      "w2.grad:\r\n",
      "                  [out] [GPUGlobal] w2.grad: f32[13, 64] {\r\n",
      "w3:\r\n",
      "                    [in] [GPUGlobal] w3: f32[13, 64] {\r\n",
      "w3.grad:\r\n",
      "                      [out] [GPUGlobal] w3.grad: f32[13, 64] {\r\n",
      "y:\r\n",
      "                        [in] [GPUGlobal] y: f32[12288, 64] {\r\n",
      "y.grad:\r\n",
      "                          [inout] [GPUGlobal] y.grad: f32[12288, 64] {\r\n",
      "                            for .x.grad.i0 in 12287 : -1 : -1 {\r\n",
      "                              for .x.grad.i1 in 12 : -1 : -1 {\r\n",
      "                                x.grad[.x.grad.i0, .x.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for .w0.grad.i0 in 12 : -1 : -1 {\r\n",
      "                              for .w0.grad.i1 in 63 : -1 : -1 {\r\n",
      "                                w0.grad[.w0.grad.i0, .w0.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for .w1.grad.i0 in 12 : -1 : -1 {\r\n",
      "                              for .w1.grad.i1 in 63 : -1 : -1 {\r\n",
      "                                w1.grad[.w1.grad.i0, .w1.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for .w2.grad.i0 in 12 : -1 : -1 {\r\n",
      "                              for .w2.grad.i1 in 63 : -1 : -1 {\r\n",
      "                                w2.grad[.w2.grad.i0, .w2.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for .w3.grad.i0 in 12 : -1 : -1 {\r\n",
      "                              for .w3.grad.i1 in 63 : -1 : -1 {\r\n",
      "                                w3.grad[.w3.grad.i0, .w3.grad.i1] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            for i in 12287 : -1 : -1 {\r\n",
      "y$1:\r\n",
      "                              [cache] [GPUGlobal] y$1: f32[13] {\r\n",
      "y$1.grad:\r\n",
      "                                [cache] [GPUGlobal] y$1.grad: f32[13] {\r\n",
      "                                  for .y$1.grad.i0 in 12 : -1 : -1 {\r\n",
      "                                    y$1.grad[.y$1.grad.i0] = 0\r\n",
      "                                  }\r\n",
      "y$2:\r\n",
      "                                  [cache] [GPUGlobal] y$2: f32[13] {\r\n",
      "y$2.grad:\r\n",
      "                                    [cache] [GPUGlobal] y$2.grad: f32[13] {\r\n",
      "                                      for .y$2.grad.i0 in 12 : -1 : -1 {\r\n",
      "                                        y$2.grad[.y$2.grad.i0] = 0\r\n",
      "                                      }\r\n",
      "y$3:\r\n",
      "                                      [cache] [GPUGlobal] y$3: f32[13] {\r\n",
      "y$3.grad:\r\n",
      "                                        [cache] [GPUGlobal] y$3.grad: f32[13] {\r\n",
      "                                          for .y$3.grad.i0 in 12 : -1 : -1 {\r\n",
      "                                            y$3.grad[.y$3.grad.i0] = 0\r\n",
      "                                          }\r\n",
      "                                          for recur:i in 0 : 13 : 1 {\r\n",
      "                                            y$1[recur:i] = 0\r\n",
      "                                          }\r\n",
      "                                          for recur$1:i in 0 : 13 : 1 {\r\n",
      "                                            y$2[recur$1:i] = 0\r\n",
      "                                          }\r\n",
      "                                          for recur$2:i in 0 : 13 : 1 {\r\n",
      "                                            y$3[recur$2:i] = 0\r\n",
      "                                          }\r\n",
      "                                          for p in 0 : 3 : 1 {\r\n",
      "                                            for i$1 in 0 : 13 : 1 {\r\n",
      "                                              y$1[i$1] += x[adj[i, p], i$1]\r\n",
      "                                            }\r\n",
      "                                            [cache] [GPUGlobal] out: f32[13] {\r\n",
      "                                              for recur$4:i in 0 : 13 : 1 {\r\n",
      "                                                out[recur$4:i] = (x[adj[i, p], recur$4:i] - x[adj[i, ((p + 1) % 3)], recur$4:i])\r\n",
      "                                              }\r\n",
      "                                              [cache] [GPUGlobal] y$4: f32[13] {\r\n",
      "                                                for recur$5:i in 0 : 13 : 1 {\r\n",
      "                                                  y$4[recur$5:i] = abs(out[recur$5:i])\r\n",
      "                                                }\r\n",
      "                                                for i$2 in 0 : 13 : 1 {\r\n",
      "                                                  y$2[i$2] += y$4[i$2]\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                            [cache] [GPUGlobal] out$1: f32[13] {\r\n",
      "                                              for recur$7:i in 0 : 13 : 1 {\r\n",
      "                                                out$1[recur$7:i] = (x[adj[i, p], recur$7:i] - x[i, recur$7:i])\r\n",
      "                                              }\r\n",
      "                                              [cache] [GPUGlobal] y$5: f32[13] {\r\n",
      "                                                for recur$8:i in 0 : 13 : 1 {\r\n",
      "                                                  y$5[recur$8:i] = abs(out$1[recur$8:i])\r\n",
      "                                                }\r\n",
      "                                                for i$3 in 0 : 13 : 1 {\r\n",
      "                                                  y$3[i$3] += y$5[i$3]\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$1:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$1:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$2:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$2:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$3:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$1:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$1:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$2:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$2:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$3:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$2:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$2:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$3:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          // prefer libs\r\n",
      "                                          for einsum$3:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                              /* empty */\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$10:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$11:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "                                          for recur$12:i in 0 : 64 : 1 {\r\n",
      "                                            /* empty */\r\n",
      "                                          }\r\n",
      "einsum:Y.grad:\r\n",
      "                                          [cache] [GPUGlobal] einsum:Y.grad: f32[64] {\r\n",
      "einsum$1:Y.grad:\r\n",
      "                                            [cache] [GPUGlobal] einsum$1:Y.grad: f32[64] {\r\n",
      "einsum$2:Y.grad:\r\n",
      "                                              [cache] [GPUGlobal] einsum$2:Y.grad: f32[64] {\r\n",
      "einsum$3:Y.grad:\r\n",
      "                                                [cache] [GPUGlobal] einsum$3:Y.grad: f32[64] {\r\n",
      "out$2.grad:\r\n",
      "                                                  [cache] [GPUGlobal] out$2.grad: f32[64] {\r\n",
      "out$3.grad:\r\n",
      "                                                    [cache] [GPUGlobal] out$3.grad: f32[64] {\r\n",
      "out$4.grad:\r\n",
      "                                                      [cache] [GPUGlobal] out$4.grad: f32[64] {\r\n",
      "L_elem$3:\r\n",
      "                                                        for i$4 in 63 : -1 : -1 {\r\n",
      "                                                          out$4.grad[i$4] = y.grad[i, i$4]\r\n",
      "                                                        }\r\n",
      "recur$12:L_elem:\r\n",
      "                                                        for recur$12:i in 63 : -1 : -1 {\r\n",
      "                                                          out$3.grad[recur$12:i] = out$4.grad[recur$12:i]\r\n",
      "                                                          einsum$3:Y.grad[recur$12:i] = out$4.grad[recur$12:i]\r\n",
      "                                                        }\r\n",
      "                                                      }\r\n",
      "recur$11:L_elem:\r\n",
      "                                                      for recur$11:i in 63 : -1 : -1 {\r\n",
      "                                                        out$2.grad[recur$11:i] = out$3.grad[recur$11:i]\r\n",
      "                                                        einsum$2:Y.grad[recur$11:i] = out$3.grad[recur$11:i]\r\n",
      "                                                      }\r\n",
      "                                                    }\r\n",
      "recur$10:L_elem:\r\n",
      "                                                    for recur$10:i in 63 : -1 : -1 {\r\n",
      "                                                      einsum:Y.grad[recur$10:i] = out$2.grad[recur$10:i]\r\n",
      "                                                      einsum$1:Y.grad[recur$10:i] = out$2.grad[recur$10:i]\r\n",
      "                                                    }\r\n",
      "                                                  }\r\n",
      "                                                  // prefer libs\r\n",
      "                                                  for einsum$3:i in 63 : -1 : -1 {\r\n",
      "                                                    // prefer libs\r\n",
      "                                                    for einsum$3:i$1 in 12 : -1 : -1 {\r\n",
      "                                                      y$3.grad[einsum$3:i$1] += (einsum$3:Y.grad[einsum$3:i] * w3[einsum$3:i$1, einsum$3:i])\r\n",
      "                                                      w3.grad[einsum$3:i$1, einsum$3:i] += (einsum$3:Y.grad[einsum$3:i] * y$3[einsum$3:i$1])\r\n",
      "                                                    }\r\n",
      "                                                    einsum$3:Y.grad[einsum$3:i] = 0\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                                // prefer libs\r\n",
      "                                                for einsum$2:i in 63 : -1 : -1 {\r\n",
      "                                                  // prefer libs\r\n",
      "                                                  for einsum$2:i$1 in 12 : -1 : -1 {\r\n",
      "                                                    y$2.grad[einsum$2:i$1] += (einsum$2:Y.grad[einsum$2:i] * w2[einsum$2:i$1, einsum$2:i])\r\n",
      "                                                    w2.grad[einsum$2:i$1, einsum$2:i] += (einsum$2:Y.grad[einsum$2:i] * y$2[einsum$2:i$1])\r\n",
      "                                                  }\r\n",
      "                                                  einsum$2:Y.grad[einsum$2:i] = 0\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                              // prefer libs\r\n",
      "                                              for einsum$1:i in 63 : -1 : -1 {\r\n",
      "                                                // prefer libs\r\n",
      "                                                for einsum$1:i$1 in 12 : -1 : -1 {\r\n",
      "                                                  y$1.grad[einsum$1:i$1] += (einsum$1:Y.grad[einsum$1:i] * w1[einsum$1:i$1, einsum$1:i])\r\n",
      "                                                  w1.grad[einsum$1:i$1, einsum$1:i] += (einsum$1:Y.grad[einsum$1:i] * y$1[einsum$1:i$1])\r\n",
      "                                                }\r\n",
      "                                                einsum$1:Y.grad[einsum$1:i] = 0\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                            // prefer libs\r\n",
      "                                            for einsum:i in 63 : -1 : -1 {\r\n",
      "                                              // prefer libs\r\n",
      "                                              for einsum:i$1 in 12 : -1 : -1 {\r\n",
      "                                                x.grad[i, einsum:i$1] += (einsum:Y.grad[einsum:i] * w0[einsum:i$1, einsum:i])\r\n",
      "                                                w0.grad[einsum:i$1, einsum:i] += (einsum:Y.grad[einsum:i] * x[i, einsum:i$1])\r\n",
      "                                              }\r\n",
      "                                              einsum:Y.grad[einsum:i] = 0\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                          for p in 2 : -1 : -1 {\r\n",
      "out:\r\n",
      "                                            [cache] [GPUGlobal] out: f32[13] {\r\n",
      "                                              for recur$4:i in 0 : 13 : 1 {\r\n",
      "                                                out[recur$4:i] = (x[adj[i, p], recur$4:i] - x[adj[i, ((p + 1) % 3)], recur$4:i])\r\n",
      "                                              }\r\n",
      "                                              for recur$5:i in 0 : 13 : 1 {\r\n",
      "                                                /* empty */\r\n",
      "                                              }\r\n",
      "                                              for recur$7:i in 0 : 13 : 1 {\r\n",
      "                                                /* empty */\r\n",
      "                                              }\r\n",
      "                                              for recur$8:i in 0 : 13 : 1 {\r\n",
      "                                                /* empty */\r\n",
      "                                              }\r\n",
      "out$1:\r\n",
      "                                              [cache] [GPUGlobal] out$1.out$1: f32[13] {\r\n",
      "                                                for recur$7:i in 0 : 13 : 1 {\r\n",
      "                                                  out$1.out$1[recur$7:i] = (x[adj[i, p], recur$7:i] - x[i, recur$7:i])\r\n",
      "                                                }\r\n",
      "                                                for recur$8:i in 0 : 13 : 1 {\r\n",
      "                                                  /* empty */\r\n",
      "                                                }\r\n",
      "out$1.grad:\r\n",
      "                                                [cache] [GPUGlobal] out$1.grad: f32[13] {\r\n",
      "y$5.grad:\r\n",
      "                                                  [cache] [GPUGlobal] y$5.grad: f32[13] {\r\n",
      "L_elem$2:\r\n",
      "                                                    for i$3 in 12 : -1 : -1 {\r\n",
      "                                                      y$5.grad[i$3] = y$3.grad[i$3]\r\n",
      "                                                    }\r\n",
      "recur$8:L_elem:\r\n",
      "                                                    for recur$8:i in 12 : -1 : -1 {\r\n",
      "                                                      out$1.grad[recur$8:i] = ((out$1.out$1[recur$8:i] >= 0) ? y$5.grad[recur$8:i] : (0 - y$5.grad[recur$8:i]))\r\n",
      "                                                    }\r\n",
      "                                                  }\r\n",
      "recur$7:L_elem:\r\n",
      "                                                  for recur$7:i in 12 : -1 : -1 {\r\n",
      "                                                    x.grad[adj[i, p], recur$7:i] += out$1.grad[recur$7:i]\r\n",
      "                                                    x.grad[i, recur$7:i] += (0 - out$1.grad[recur$7:i])\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "out.grad:\r\n",
      "                                              [cache] [GPUGlobal] out.grad: f32[13] {\r\n",
      "y$4.grad:\r\n",
      "                                                [cache] [GPUGlobal] y$4.grad: f32[13] {\r\n",
      "L_elem$1:\r\n",
      "                                                  for i$2 in 12 : -1 : -1 {\r\n",
      "                                                    y$4.grad[i$2] = y$2.grad[i$2]\r\n",
      "                                                  }\r\n",
      "recur$5:L_elem:\r\n",
      "                                                  for recur$5:i in 12 : -1 : -1 {\r\n",
      "                                                    out.grad[recur$5:i] = ((out[recur$5:i] >= 0) ? y$4.grad[recur$5:i] : (0 - y$4.grad[recur$5:i]))\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "recur$4:L_elem:\r\n",
      "                                                for recur$4:i in 12 : -1 : -1 {\r\n",
      "                                                  x.grad[adj[i, p], recur$4:i] += out.grad[recur$4:i]\r\n",
      "                                                  x.grad[adj[i, ((p + 1) % 3)], recur$4:i] += (0 - out.grad[recur$4:i])\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "L_elem:\r\n",
      "                                            for i$1 in 12 : -1 : -1 {\r\n",
      "                                              x.grad[adj[i, p], i$1] += y$1.grad[i$1]\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "recur$2:L_elem:\r\n",
      "                                          for recur$2:i in 12 : -1 : -1 {\r\n",
      "                                            y$3.grad[recur$2:i] = 0\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "recur$1:L_elem:\r\n",
      "                                      for recur$1:i in 12 : -1 : -1 {\r\n",
      "                                        y$2.grad[recur$1:i] = 0\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "recur:L_elem:\r\n",
      "                                  for recur:i in 12 : -1 : -1 {\r\n",
      "                                    y$1.grad[recur:i] = 0\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "func(adj, x, w0, w1, w2, w3, y, x.grad, w0.grad, w1.grad, w3.grad, w2.grad, y.grad) {\r\n",
      "adj:\r\n",
      "  [in] [GPUGlobal] adj: i32[36864] {\r\n",
      "x:\r\n",
      "    [in] [GPUGlobal] x: f32[159744] {\r\n",
      "x.grad:\r\n",
      "      [out] [GPUGlobal] x.grad: f32[159744] {\r\n",
      "w0:\r\n",
      "        [in] [GPUGlobal] w0: f32[832] {\r\n",
      "w0.grad:\r\n",
      "          [out] [GPUGlobal] w0.grad: f32[832] {\r\n",
      "w1:\r\n",
      "            [in] [GPUGlobal] w1: f32[832] {\r\n",
      "w1.grad:\r\n",
      "              [out] [GPUGlobal] w1.grad: f32[832] {\r\n",
      "w2:\r\n",
      "                [in] [GPUGlobal] w2: f32[832] {\r\n",
      "w2.grad:\r\n",
      "                  [out] [GPUGlobal] w2.grad: f32[832] {\r\n",
      "w3:\r\n",
      "                    [in] [GPUGlobal] w3: f32[832] {\r\n",
      "w3.grad:\r\n",
      "                      [out] [GPUGlobal] w3.grad: f32[832] {\r\n",
      "y:\r\n",
      "                        [in] [GPUGlobal] y: f32[786432] {\r\n",
      "y.grad:\r\n",
      "                          [inout] [GPUGlobal] y.grad: f32[786432] {\r\n",
      "                            // parallel = blockIdx.x\r\n",
      "                            for .blockIdx.x in 0 : 1536 : 1 {\r\n",
      "                              // parallel = threadIdx.y\r\n",
      "                              for .threadIdx.y in 0 : 8 : 1 {\r\n",
      "                                // parallel = threadIdx.x\r\n",
      "                                for .threadIdx.x in 0 : 13 : 1 {\r\n",
      "                                  x.grad[((((-104 * .blockIdx.x) + (-1 * .threadIdx.x)) + (-13 * .threadIdx.y)) + 159743)] = 0\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            // parallel = blockIdx.x\r\n",
      "                            for .blockIdx.x in 0 : 26 : 1 {\r\n",
      "                              // parallel = threadIdx.x\r\n",
      "                              for .threadIdx.x in 0 : 32 : 1 {\r\n",
      "                                w0.grad[(((((-32 * .blockIdx.x) + (-32 * (.blockIdx.x %% 2))) + (-1 * .threadIdx.x)) + (-32 * ((.blockIdx.x + 1) %% 2))) + 863)] = 0\r\n",
      "                                w1.grad[(((((-32 * .blockIdx.x) + (-32 * (.blockIdx.x %% 2))) + (-1 * .threadIdx.x)) + (-32 * ((.blockIdx.x + 1) %% 2))) + 863)] = 0\r\n",
      "                                w2.grad[(((((-32 * .blockIdx.x) + (-32 * (.blockIdx.x %% 2))) + (-1 * .threadIdx.x)) + (-32 * ((.blockIdx.x + 1) %% 2))) + 863)] = 0\r\n",
      "                                w3.grad[(((((-32 * .blockIdx.x) + (-32 * (.blockIdx.x %% 2))) + (-1 * .threadIdx.x)) + (-32 * ((.blockIdx.x + 1) %% 2))) + 863)] = 0\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                            // parallel = blockIdx.x\r\n",
      "                            for .blockIdx.x in 0 : 1536 : 1 {\r\n",
      "                              // parallel = threadIdx.y\r\n",
      "                              for .threadIdx.y in 0 : 8 : 1 {\r\n",
      "                                // parallel = threadIdx.x\r\n",
      "                                for .threadIdx.x in 0 : 32 : 1 {\r\n",
      "y$1:\r\n",
      "                                  [cache] [GPUShared] y$1: f32[104] {\r\n",
      "y$1.grad:\r\n",
      "                                    [cache] [GPUShared] y$1.grad: f32[104] {\r\n",
      "y$2:\r\n",
      "                                      [cache] [GPUShared] y$2: f32[104] {\r\n",
      "y$2.grad:\r\n",
      "                                        [cache] [GPUShared] y$2.grad: f32[104] {\r\n",
      "y$3:\r\n",
      "                                          [cache] [GPUShared] y$3: f32[104] {\r\n",
      "y$3.grad:\r\n",
      "                                            [cache] [GPUShared] y$3.grad: f32[104] {\r\n",
      "                                              if (.threadIdx.x == 0) {\r\n",
      "fused.fused.fused.fused.fused.#442.#439.#436.#139.#141.#143:\r\n",
      "                                                for .y$1.grad.i0 in 0 : 13 : 1 {\r\n",
      "                                                  y$1.grad[(((13 * .threadIdx.y) + (-1 * .y$1.grad.i0)) + 12)] = 0\r\n",
      "                                                  y$2.grad[(((13 * .threadIdx.y) + (-1 * .y$1.grad.i0)) + 12)] = 0\r\n",
      "                                                  y$3.grad[(((13 * .threadIdx.y) + (-1 * .y$1.grad.i0)) + 12)] = 0\r\n",
      "                                                  y$1[((.threadIdx.y * 13) + .y$1.grad.i0)] = 0\r\n",
      "                                                  y$2[((.threadIdx.y * 13) + .y$1.grad.i0)] = 0\r\n",
      "                                                  y$3[((.threadIdx.y * 13) + .y$1.grad.i0)] = 0\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                              intrinsic(\"__syncwarp()\")\r\n",
      "                                              if (.threadIdx.x < 13) {\r\n",
      "                                                // unroll\r\n",
      "                                                for p in 0 : 3 : 1 {\r\n",
      "                                                  y$1[((.threadIdx.y * 13) + .threadIdx.x)] += x[((adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + p) + 36861)] * 13) + .threadIdx.x)]\r\n",
      "                                                  y$2[((.threadIdx.y * 13) + .threadIdx.x)] += abs((x[((adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + p) + 36861)] * 13) + .threadIdx.x)] - x[((adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + ((p + 1) %% 3)) + 36861)] * 13) + .threadIdx.x)]))\r\n",
      "                                                  y$3[((.threadIdx.y * 13) + .threadIdx.x)] += abs((x[((adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + p) + 36861)] * 13) + .threadIdx.x)] - x[((((-104 * .blockIdx.x) + .threadIdx.x) + (-13 * .threadIdx.y)) + 159731)]))\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                              [cache] [GPUShared] __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2: f32[3328] {\r\n",
      "                                                [cache] [GPUShared] __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1: f32[3328] {\r\n",
      "                                                  [cache] [GPUShared] __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0: f32[3328] {\r\n",
      "                                                    for __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2.0 in 0 : 13 : 1 {\r\n",
      "                                                      __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2[(((13 * .threadIdx.x) + (416 * .threadIdx.y)) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2.0)] = 0.000000\r\n",
      "                                                    }\r\n",
      "                                                    for __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1.0 in 0 : 13 : 1 {\r\n",
      "                                                      __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1[(((13 * .threadIdx.x) + (416 * .threadIdx.y)) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1.0)] = 0.000000\r\n",
      "                                                    }\r\n",
      "                                                    for __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0.0 in 0 : 13 : 1 {\r\n",
      "                                                      __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0[(((13 * .threadIdx.x) + (416 * .threadIdx.y)) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0.0)] = 0.000000\r\n",
      "                                                    }\r\n",
      "                                                    [cache] [GPULocal] x.grad.atomic_cache.#357: f32[13] {\r\n",
      "                                                      for x.grad.atomic_cache.#357.i0 in 0 : 13 : 1 {\r\n",
      "                                                        x.grad.atomic_cache.#357[x.grad.atomic_cache.#357.i0] = 0.000000\r\n",
      "                                                      }\r\n",
      "                                                      intrinsic(\"__syncwarp()\")\r\n",
      "fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.0:\r\n",
      "                                                      // unroll\r\n",
      "                                                      for i$4.0 in 0 : 2 : 1 {\r\n",
      "einsum:Y.grad:\r\n",
      "                                                        [cache] [GPULocal] einsum:Y.grad: f32[1] {\r\n",
      "einsum$1:Y.grad:\r\n",
      "                                                          [cache] [GPULocal] einsum$1:Y.grad: f32[1] {\r\n",
      "einsum$2:Y.grad:\r\n",
      "                                                            [cache] [GPULocal] einsum$2:Y.grad: f32[1] {\r\n",
      "einsum$3:Y.grad:\r\n",
      "                                                              [cache] [GPULocal] einsum$3:Y.grad: f32[1] {\r\n",
      "out$2.grad:\r\n",
      "                                                                [cache] [GPULocal] out$2.grad: f32[1] {\r\n",
      "out$3.grad:\r\n",
      "                                                                  [cache] [GPULocal] out$3.grad: f32[1] {\r\n",
      "out$4.grad:\r\n",
      "                                                                    [cache] [GPULocal] out$4.grad: f32[1] {\r\n",
      "                                                                      out$4.grad[0] = y.grad[(((((-512 * .blockIdx.x) + (-1 * .threadIdx.x)) + (-64 * .threadIdx.y)) + (-32 * i$4.0)) + 786431)]\r\n",
      "                                                                      out$3.grad[0] = out$4.grad[0]\r\n",
      "                                                                      einsum$3:Y.grad[0] = out$4.grad[0]\r\n",
      "                                                                    }\r\n",
      "                                                                    out$2.grad[0] = out$3.grad[0]\r\n",
      "                                                                    einsum$2:Y.grad[0] = out$3.grad[0]\r\n",
      "                                                                  }\r\n",
      "                                                                  einsum:Y.grad[0] = out$2.grad[0]\r\n",
      "                                                                  einsum$1:Y.grad[0] = out$2.grad[0]\r\n",
      "                                                                }\r\n",
      "fused.fused.fused.#45.#39.#33.#27:\r\n",
      "                                                                for einsum$3:i$1 in 0 : 13 : 1 {\r\n",
      "                                                                  __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0[((((-1 * einsum$3:i$1) + (13 * .threadIdx.x)) + (416 * .threadIdx.y)) + 12)] += (einsum$3:Y.grad[0] * w3[((((-64 * einsum$3:i$1) + (-1 * .threadIdx.x)) + (-32 * i$4.0)) + 831)])\r\n",
      "                                                                  // atomic\r\n",
      "                                                                  w3.grad[((((-64 * einsum$3:i$1) + (-1 * .threadIdx.x)) + (-32 * i$4.0)) + 831)] += (einsum$3:Y.grad[0] * y$3[(((-1 * einsum$3:i$1) + (13 * .threadIdx.y)) + 12)])\r\n",
      "                                                                  __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1[((((-1 * einsum$3:i$1) + (13 * .threadIdx.x)) + (416 * .threadIdx.y)) + 12)] += (einsum$2:Y.grad[0] * w2[((((-64 * einsum$3:i$1) + (-1 * .threadIdx.x)) + (-32 * i$4.0)) + 831)])\r\n",
      "                                                                  // atomic\r\n",
      "                                                                  w2.grad[((((-64 * einsum$3:i$1) + (-1 * .threadIdx.x)) + (-32 * i$4.0)) + 831)] += (einsum$2:Y.grad[0] * y$2[(((-1 * einsum$3:i$1) + (13 * .threadIdx.y)) + 12)])\r\n",
      "                                                                  __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2[((((-1 * einsum$3:i$1) + (13 * .threadIdx.x)) + (416 * .threadIdx.y)) + 12)] += (einsum$1:Y.grad[0] * w1[((((-64 * einsum$3:i$1) + (-1 * .threadIdx.x)) + (-32 * i$4.0)) + 831)])\r\n",
      "                                                                  // atomic\r\n",
      "                                                                  w1.grad[((((-64 * einsum$3:i$1) + (-1 * .threadIdx.x)) + (-32 * i$4.0)) + 831)] += (einsum$1:Y.grad[0] * y$1[(((-1 * einsum$3:i$1) + (13 * .threadIdx.y)) + 12)])\r\n",
      "                                                                  x.grad.atomic_cache.#357[((einsum$3:i$1 * -1) + 12)] += (einsum:Y.grad[0] * w0[((((-64 * einsum$3:i$1) + (-1 * .threadIdx.x)) + (-32 * i$4.0)) + 831)])\r\n",
      "                                                                  // atomic\r\n",
      "                                                                  w0.grad[((((-64 * einsum$3:i$1) + (-1 * .threadIdx.x)) + (-32 * i$4.0)) + 831)] += (einsum:Y.grad[0] * x[((((-1 * einsum$3:i$1) + (-104 * .blockIdx.x)) + (-13 * .threadIdx.y)) + 159743)])\r\n",
      "                                                                }\r\n",
      "                                                                einsum$3:Y.grad[0] = 0\r\n",
      "                                                              }\r\n",
      "                                                              einsum$2:Y.grad[0] = 0\r\n",
      "                                                            }\r\n",
      "                                                            einsum$1:Y.grad[0] = 0\r\n",
      "                                                          }\r\n",
      "                                                          einsum:Y.grad[0] = 0\r\n",
      "                                                        }\r\n",
      "                                                      }\r\n",
      "                                                      for x.grad.atomic_cache.#357.i0 in 0 : 13 : 1 {\r\n",
      "                                                        // atomic\r\n",
      "                                                        x.grad[((((-104 * .blockIdx.x) + (-13 * .threadIdx.y)) + x.grad.atomic_cache.#357.i0) + 159731)] += x.grad.atomic_cache.#357[x.grad.atomic_cache.#357.i0]\r\n",
      "                                                      }\r\n",
      "                                                    }\r\n",
      "                                                    for __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0.0 in 0 : 13 : 1 {\r\n",
      "                                                      // unroll\r\n",
      "                                                      for __reduce_p in 0 : 5 : 1 {\r\n",
      "                                                        if (((.threadIdx.x % (intrinsic(\"1 << (__reduce_p)\") * 2)) == 0) && ((.threadIdx.x + intrinsic(\"1 << (__reduce_p)\")) < 32)) {\r\n",
      "                                                          __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0[(((13 * .threadIdx.x) + (416 * .threadIdx.y)) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0.0)] += __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0[((((.threadIdx.y * 32) + (.threadIdx.x + intrinsic(\"1 << (__reduce_p)\"))) * 13) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0.0)]\r\n",
      "                                                        }\r\n",
      "                                                        intrinsic(\"__syncwarp()\")\r\n",
      "                                                      }\r\n",
      "                                                      y$3.grad[((.threadIdx.y * 13) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0.0)] += __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0[((416 * .threadIdx.y) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_0.0)]\r\n",
      "                                                    }\r\n",
      "                                                    for __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1.0 in 0 : 13 : 1 {\r\n",
      "                                                      // unroll\r\n",
      "                                                      for __reduce_p in 0 : 5 : 1 {\r\n",
      "                                                        if (((.threadIdx.x % (intrinsic(\"1 << (__reduce_p)\") * 2)) == 0) && ((.threadIdx.x + intrinsic(\"1 << (__reduce_p)\")) < 32)) {\r\n",
      "                                                          __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1[(((13 * .threadIdx.x) + (416 * .threadIdx.y)) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1.0)] += __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1[((((.threadIdx.y * 32) + (.threadIdx.x + intrinsic(\"1 << (__reduce_p)\"))) * 13) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1.0)]\r\n",
      "                                                        }\r\n",
      "                                                        intrinsic(\"__syncwarp()\")\r\n",
      "                                                      }\r\n",
      "                                                      y$2.grad[((.threadIdx.y * 13) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1.0)] += __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1[((416 * .threadIdx.y) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_1.0)]\r\n",
      "                                                    }\r\n",
      "                                                    for __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2.0 in 0 : 13 : 1 {\r\n",
      "                                                      // unroll\r\n",
      "                                                      for __reduce_p in 0 : 5 : 1 {\r\n",
      "                                                        if (((.threadIdx.x % (intrinsic(\"1 << (__reduce_p)\") * 2)) == 0) && ((.threadIdx.x + intrinsic(\"1 << (__reduce_p)\")) < 32)) {\r\n",
      "                                                          __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2[(((13 * .threadIdx.x) + (416 * .threadIdx.y)) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2.0)] += __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2[((((.threadIdx.y * 32) + (.threadIdx.x + intrinsic(\"1 << (__reduce_p)\"))) * 13) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2.0)]\r\n",
      "                                                        }\r\n",
      "                                                        intrinsic(\"__syncwarp()\")\r\n",
      "                                                      }\r\n",
      "                                                      y$1.grad[((.threadIdx.y * 13) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2.0)] += __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2[((416 * .threadIdx.y) + __reduce_fused.fused.fused.fused.fused.fused.fused.L_elem$3.recur$12:L_elem.recur$11:L_elem.recur$10:L_elem.#48.#42.#36.#30.1_2.0)]\r\n",
      "                                                    }\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                              intrinsic(\"__syncthreads()\")\r\n",
      "                                              // unroll\r\n",
      "                                              for p in 2 : -1 : -1 {\r\n",
      "out:\r\n",
      "                                                [cache] [GPUShared] out: f32[104] {\r\n",
      "out$1:\r\n",
      "                                                  [cache] [GPUShared] out$1.out$1: f32[104] {\r\n",
      "out$1.grad:\r\n",
      "                                                    [cache] [GPULocal] out$1.grad: f32[1] {\r\n",
      "y$5.grad:\r\n",
      "                                                      [cache] [GPULocal] y$5.grad: f32[1] {\r\n",
      "                                                        if (.threadIdx.x < 13) {\r\n",
      "                                                          out[((.threadIdx.y * 13) + .threadIdx.x)] = (x[((adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + p) + 36861)] * 13) + .threadIdx.x)] - x[((adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + ((p + 1) %% 3)) + 36861)] * 13) + .threadIdx.x)])\r\n",
      "                                                          out$1.out$1[((.threadIdx.y * 13) + .threadIdx.x)] = (x[((adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + p) + 36861)] * 13) + .threadIdx.x)] - x[((((-104 * .blockIdx.x) + .threadIdx.x) + (-13 * .threadIdx.y)) + 159731)])\r\n",
      "                                                          y$5.grad[0] = y$3.grad[(((-1 * .threadIdx.x) + (13 * .threadIdx.y)) + 12)]\r\n",
      "                                                        }\r\n",
      "                                                        intrinsic(\"__syncwarp()\")\r\n",
      "                                                        if (.threadIdx.x < 13) {\r\n",
      "                                                          out$1.grad[0] = ((out$1.out$1[(((-1 * .threadIdx.x) + (13 * .threadIdx.y)) + 12)] >= 0) ? y$5.grad[0] : (-1 * y$5.grad[0]))\r\n",
      "                                                          // atomic\r\n",
      "                                                          x.grad[(((-1 * .threadIdx.x) + (13 * adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + p) + 36861)])) + 12)] += out$1.grad[0]\r\n",
      "                                                        }\r\n",
      "                                                        intrinsic(\"__syncthreads()\")\r\n",
      "                                                        if (.threadIdx.x < 13) {\r\n",
      "                                                          // atomic\r\n",
      "                                                          x.grad[((((-104 * .blockIdx.x) + (-1 * .threadIdx.x)) + (-13 * .threadIdx.y)) + 159743)] += (-1 * out$1.grad[0])\r\n",
      "                                                        }\r\n",
      "out.grad:\r\n",
      "                                                        [cache] [GPULocal] out.grad: f32[1] {\r\n",
      "                                                          if (.threadIdx.x < 13) {\r\n",
      "y$4.grad:\r\n",
      "                                                            [cache] [GPULocal] y$4.grad: f32[1] {\r\n",
      "                                                              y$4.grad[0] = y$2.grad[(((-1 * .threadIdx.x) + (13 * .threadIdx.y)) + 12)]\r\n",
      "                                                              out.grad[0] = ((out[(((-1 * .threadIdx.x) + (13 * .threadIdx.y)) + 12)] >= 0) ? y$4.grad[0] : (-1 * y$4.grad[0]))\r\n",
      "                                                            }\r\n",
      "                                                          }\r\n",
      "                                                          intrinsic(\"__syncthreads()\")\r\n",
      "                                                          if (.threadIdx.x < 13) {\r\n",
      "                                                            // atomic\r\n",
      "                                                            x.grad[(((-1 * .threadIdx.x) + (13 * adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + p) + 36861)])) + 12)] += out.grad[0]\r\n",
      "                                                          }\r\n",
      "                                                          intrinsic(\"__syncthreads()\")\r\n",
      "                                                          if (.threadIdx.x < 13) {\r\n",
      "                                                            // atomic\r\n",
      "                                                            x.grad[(((-1 * .threadIdx.x) + (13 * adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + ((p + 1) %% 3)) + 36861)])) + 12)] += (-1 * out.grad[0])\r\n",
      "                                                          }\r\n",
      "                                                        }\r\n",
      "                                                        intrinsic(\"__syncthreads()\")\r\n",
      "                                                        if (.threadIdx.x < 13) {\r\n",
      "                                                          // atomic\r\n",
      "                                                          x.grad[(((-1 * .threadIdx.x) + (13 * adj[((((-24 * .blockIdx.x) + (-3 * .threadIdx.y)) + p) + 36861)])) + 12)] += y$1.grad[(((-1 * .threadIdx.x) + (13 * .threadIdx.y)) + 12)]\r\n",
      "                                                        }\r\n",
      "                                                      }\r\n",
      "                                                    }\r\n",
      "                                                  }\r\n",
      "                                                }\r\n",
      "                                                intrinsic(\"__syncthreads()\")\r\n",
      "                                              }\r\n",
      "                                              if (.threadIdx.x == 0) {\r\n",
      "fused.fused.recur$2:L_elem.recur$1:L_elem.recur:L_elem:\r\n",
      "                                                for recur$2:i in 0 : 13 : 1 {\r\n",
      "                                                  y$3.grad[(((13 * .threadIdx.y) + (-1 * recur$2:i)) + 12)] = 0\r\n",
      "                                                  y$2.grad[(((13 * .threadIdx.y) + (-1 * recur$2:i)) + 12)] = 0\r\n",
      "                                                  y$1.grad[(((13 * .threadIdx.y) + (-1 * recur$2:i)) + 12)] = 0\r\n",
      "                                                }\r\n",
      "                                              }\r\n",
      "                                            }\r\n",
      "                                          }\r\n",
      "                                        }\r\n",
      "                                      }\r\n",
      "                                    }\r\n",
      "                                  }\r\n",
      "                                }\r\n",
      "                              }\r\n",
      "                            }\r\n",
      "                          }\r\n",
      "                        }\r\n",
      "                      }\r\n",
      "                    }\r\n",
      "                  }\r\n",
      "                }\r\n",
      "              }\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "\u001b[33m  1\u001b[0m \r\n",
      "\u001b[33m  2\u001b[0m #include <gpu_runtime.h>\r\n",
      "\u001b[33m  3\u001b[0m \r\n",
      "\u001b[33m  4\u001b[0m extern __shared__ uint8_t __shmem[];\r\n",
      "\u001b[33m  5\u001b[0m \r\n",
      "\u001b[33m  6\u001b[0m extern \"C\" {\r\n",
      "\u001b[33m  7\u001b[0m __global__ void __launch_bounds__(13 * 8 * 1) kernel0(float (*restrict x_46grad), uint8_t *__glmem) {\r\n",
      "\u001b[33m  8\u001b[0m   x_46grad[((((-104 * (int)blockIdx.x) + (-1 * (int)threadIdx.x)) + (-13 * (int)threadIdx.y)) + 159743)] = 0;\r\n",
      "\u001b[33m  9\u001b[0m }\r\n",
      "\u001b[33m 10\u001b[0m \r\n",
      "\u001b[33m 11\u001b[0m __global__ void __launch_bounds__(32 * 1 * 1) kernel1(float (*restrict w3_46grad), float (*restrict w2_46grad), float (*restrict w0_46grad), float (*restrict w1_46grad), uint8_t *__glmem) {\r\n",
      "\u001b[33m 12\u001b[0m   w0_46grad[(((((-32 * (int)blockIdx.x) + (-32 * ((int)blockIdx.x % 2))) + (-1 * (int)threadIdx.x)) + (-32 * (((int)blockIdx.x + 1) % 2))) + 863)] = 0;\r\n",
      "\u001b[33m 13\u001b[0m   w1_46grad[(((((-32 * (int)blockIdx.x) + (-32 * ((int)blockIdx.x % 2))) + (-1 * (int)threadIdx.x)) + (-32 * (((int)blockIdx.x + 1) % 2))) + 863)] = 0;\r\n",
      "\u001b[33m 14\u001b[0m   w2_46grad[(((((-32 * (int)blockIdx.x) + (-32 * ((int)blockIdx.x % 2))) + (-1 * (int)threadIdx.x)) + (-32 * (((int)blockIdx.x + 1) % 2))) + 863)] = 0;\r\n",
      "\u001b[33m 15\u001b[0m   w3_46grad[(((((-32 * (int)blockIdx.x) + (-32 * ((int)blockIdx.x % 2))) + (-1 * (int)threadIdx.x)) + (-32 * (((int)blockIdx.x + 1) % 2))) + 863)] = 0;\r\n",
      "\u001b[33m 16\u001b[0m }\r\n",
      "\u001b[33m 17\u001b[0m \r\n",
      "\u001b[33m 18\u001b[0m __global__ void __launch_bounds__(32 * 8 * 1) kernel2(const float (*restrict w1), float (*restrict w2_46grad), const int32_t (*restrict adj), const float (*restrict w3), float (*restrict x_46grad), const float (*restrict x), float (*restrict y_46grad), const float (*restrict w0), float (*restrict w1_46grad), float (*restrict w3_46grad), float (*restrict w0_46grad), const float (*restrict w2), uint8_t *__glmem) {\r\n",
      "\u001b[33m 19\u001b[0m   float (*y_361) = (float(*))(__shmem + 0);\r\n",
      "\u001b[33m 20\u001b[0m   float (*y_361_46grad) = (float(*))(__shmem + 416);\r\n",
      "\u001b[33m 21\u001b[0m   float (*y_362) = (float(*))(__shmem + 832);\r\n",
      "\u001b[33m 22\u001b[0m   float (*y_362_46grad) = (float(*))(__shmem + 1248);\r\n",
      "\u001b[33m 23\u001b[0m   float (*y_363) = (float(*))(__shmem + 1664);\r\n",
      "\u001b[33m 24\u001b[0m   float (*y_363_46grad) = (float(*))(__shmem + 2080);\r\n",
      "\u001b[33m 25\u001b[0m   if (((int)threadIdx.x == 0)) {\r\n",
      "\u001b[33m 26\u001b[0m     for (int _46y_361_46grad_46i0 = 0; _46y_361_46grad_46i0 < 13; _46y_361_46grad_46i0++) {\r\n",
      "\u001b[33m 27\u001b[0m       y_361_46grad[(((13 * (int)threadIdx.y) + (-1 * _46y_361_46grad_46i0)) + 12)] = 0;\r\n",
      "\u001b[33m 28\u001b[0m       y_362_46grad[(((13 * (int)threadIdx.y) + (-1 * _46y_361_46grad_46i0)) + 12)] = 0;\r\n",
      "\u001b[33m 29\u001b[0m       y_363_46grad[(((13 * (int)threadIdx.y) + (-1 * _46y_361_46grad_46i0)) + 12)] = 0;\r\n",
      "\u001b[33m 30\u001b[0m       y_361[(((int)threadIdx.y * 13) + _46y_361_46grad_46i0)] = 0;\r\n",
      "\u001b[33m 31\u001b[0m       y_362[(((int)threadIdx.y * 13) + _46y_361_46grad_46i0)] = 0;\r\n",
      "\u001b[33m 32\u001b[0m       y_363[(((int)threadIdx.y * 13) + _46y_361_46grad_46i0)] = 0;\r\n",
      "\u001b[33m 33\u001b[0m     }\r\n",
      "\u001b[33m 34\u001b[0m   }\r\n",
      "\u001b[33m 35\u001b[0m   (__syncwarp());\r\n",
      "\u001b[33m 36\u001b[0m   if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m 37\u001b[0m #pragma unroll 3\r\n",
      "\u001b[33m 38\u001b[0m     for (int p = 0; p < 3; p++) {\r\n",
      "\u001b[33m 39\u001b[0m       y_361[(((int)threadIdx.y * 13) + (int)threadIdx.x)] += x[((adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + p) + 36861)] * 13) + (int)threadIdx.x)];\r\n",
      "\u001b[33m 40\u001b[0m       y_362[(((int)threadIdx.y * 13) + (int)threadIdx.x)] += runtime_abs((x[((adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + p) + 36861)] * 13) + (int)threadIdx.x)] - x[((adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + ((p + 1) % 3)) + 36861)] * 13) + (int)threadIdx.x)]));\r\n",
      "\u001b[33m 41\u001b[0m       y_363[(((int)threadIdx.y * 13) + (int)threadIdx.x)] += runtime_abs((x[((adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + p) + 36861)] * 13) + (int)threadIdx.x)] - x[((((-104 * (int)blockIdx.x) + (int)threadIdx.x) + (-13 * (int)threadIdx.y)) + 159731)]));\r\n",
      "\u001b[33m 42\u001b[0m     }\r\n",
      "\u001b[33m 43\u001b[0m   }\r\n",
      "\u001b[33m 44\u001b[0m   {\r\n",
      "\u001b[33m 45\u001b[0m     float (*____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2) = (float(*))(__shmem + 2496);\r\n",
      "\u001b[33m 46\u001b[0m     float (*____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1) = (float(*))(__shmem + 15808);\r\n",
      "\u001b[33m 47\u001b[0m     float (*____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0) = (float(*))(__shmem + 29120);\r\n",
      "\u001b[33m 48\u001b[0m     for (int ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460 = 0; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460 < 13; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460++) {\r\n",
      "\u001b[33m 49\u001b[0m       ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2[(((13 * (int)threadIdx.x) + (416 * (int)threadIdx.y)) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460)] = 0.000000f;\r\n",
      "\u001b[33m 50\u001b[0m     }\r\n",
      "\u001b[33m 51\u001b[0m     for (int ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460 = 0; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460 < 13; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460++) {\r\n",
      "\u001b[33m 52\u001b[0m       ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1[(((13 * (int)threadIdx.x) + (416 * (int)threadIdx.y)) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460)] = 0.000000f;\r\n",
      "\u001b[33m 53\u001b[0m     }\r\n",
      "\u001b[33m 54\u001b[0m     for (int ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460 = 0; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460 < 13; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460++) {\r\n",
      "\u001b[33m 55\u001b[0m       ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0[(((13 * (int)threadIdx.x) + (416 * (int)threadIdx.y)) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460)] = 0.000000f;\r\n",
      "\u001b[33m 56\u001b[0m     }\r\n",
      "\u001b[33m 57\u001b[0m     {\r\n",
      "\u001b[33m 58\u001b[0m       float x_46grad_46atomic__cache_46_35357[13];\r\n",
      "\u001b[33m 59\u001b[0m       for (int x_46grad_46atomic__cache_46_35357_46i0 = 0; x_46grad_46atomic__cache_46_35357_46i0 < 13; x_46grad_46atomic__cache_46_35357_46i0++) {\r\n",
      "\u001b[33m 60\u001b[0m         x_46grad_46atomic__cache_46_35357[x_46grad_46atomic__cache_46_35357_46i0] = 0.000000f;\r\n",
      "\u001b[33m 61\u001b[0m       }\r\n",
      "\u001b[33m 62\u001b[0m       (__syncwarp());\r\n",
      "\u001b[33m 63\u001b[0m #pragma unroll 2\r\n",
      "\u001b[33m 64\u001b[0m       for (int i_364_460 = 0; i_364_460 < 2; i_364_460++) {\r\n",
      "\u001b[33m 65\u001b[0m         float einsum_58Y_46grad[1];\r\n",
      "\u001b[33m 66\u001b[0m         {\r\n",
      "\u001b[33m 67\u001b[0m           float einsum_361_58Y_46grad[1];\r\n",
      "\u001b[33m 68\u001b[0m           {\r\n",
      "\u001b[33m 69\u001b[0m             float einsum_362_58Y_46grad[1];\r\n",
      "\u001b[33m 70\u001b[0m             {\r\n",
      "\u001b[33m 71\u001b[0m               float einsum_363_58Y_46grad[1];\r\n",
      "\u001b[33m 72\u001b[0m               {\r\n",
      "\u001b[33m 73\u001b[0m                 float out_362_46grad[1];\r\n",
      "\u001b[33m 74\u001b[0m                 {\r\n",
      "\u001b[33m 75\u001b[0m                   float out_363_46grad[1];\r\n",
      "\u001b[33m 76\u001b[0m                   {\r\n",
      "\u001b[33m 77\u001b[0m                     float out_364_46grad[1];\r\n",
      "\u001b[33m 78\u001b[0m                     out_364_46grad[0] = y_46grad[(((((-512 * (int)blockIdx.x) + (-1 * (int)threadIdx.x)) + (-64 * (int)threadIdx.y)) + (-32 * i_364_460)) + 786431)];\r\n",
      "\u001b[33m 79\u001b[0m                     out_363_46grad[0] = out_364_46grad[0];\r\n",
      "\u001b[33m 80\u001b[0m                     einsum_363_58Y_46grad[0] = out_364_46grad[0];\r\n",
      "\u001b[33m 81\u001b[0m                   }\r\n",
      "\u001b[33m 82\u001b[0m                   out_362_46grad[0] = out_363_46grad[0];\r\n",
      "\u001b[33m 83\u001b[0m                   einsum_362_58Y_46grad[0] = out_363_46grad[0];\r\n",
      "\u001b[33m 84\u001b[0m                 }\r\n",
      "\u001b[33m 85\u001b[0m                 einsum_58Y_46grad[0] = out_362_46grad[0];\r\n",
      "\u001b[33m 86\u001b[0m                 einsum_361_58Y_46grad[0] = out_362_46grad[0];\r\n",
      "\u001b[33m 87\u001b[0m               }\r\n",
      "\u001b[33m 88\u001b[0m               for (int einsum_363_58i_361 = 0; einsum_363_58i_361 < 13; einsum_363_58i_361++) {\r\n",
      "\u001b[33m 89\u001b[0m                 ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0[((((-1 * einsum_363_58i_361) + (13 * (int)threadIdx.x)) + (416 * (int)threadIdx.y)) + 12)] += (einsum_363_58Y_46grad[0] * w3[((((-64 * einsum_363_58i_361) + (-1 * (int)threadIdx.x)) + (-32 * i_364_460)) + 831)]);\r\n",
      "\u001b[33m 90\u001b[0m                 atomicAdd(&w3_46grad[((((-64 * einsum_363_58i_361) + (-1 * (int)threadIdx.x)) + (-32 * i_364_460)) + 831)], (einsum_363_58Y_46grad[0] * y_363[(((-1 * einsum_363_58i_361) + (13 * (int)threadIdx.y)) + 12)]));\r\n",
      "\u001b[33m 91\u001b[0m                 ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1[((((-1 * einsum_363_58i_361) + (13 * (int)threadIdx.x)) + (416 * (int)threadIdx.y)) + 12)] += (einsum_362_58Y_46grad[0] * w2[((((-64 * einsum_363_58i_361) + (-1 * (int)threadIdx.x)) + (-32 * i_364_460)) + 831)]);\r\n",
      "\u001b[33m 92\u001b[0m                 atomicAdd(&w2_46grad[((((-64 * einsum_363_58i_361) + (-1 * (int)threadIdx.x)) + (-32 * i_364_460)) + 831)], (einsum_362_58Y_46grad[0] * y_362[(((-1 * einsum_363_58i_361) + (13 * (int)threadIdx.y)) + 12)]));\r\n",
      "\u001b[33m 93\u001b[0m                 ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2[((((-1 * einsum_363_58i_361) + (13 * (int)threadIdx.x)) + (416 * (int)threadIdx.y)) + 12)] += (einsum_361_58Y_46grad[0] * w1[((((-64 * einsum_363_58i_361) + (-1 * (int)threadIdx.x)) + (-32 * i_364_460)) + 831)]);\r\n",
      "\u001b[33m 94\u001b[0m                 atomicAdd(&w1_46grad[((((-64 * einsum_363_58i_361) + (-1 * (int)threadIdx.x)) + (-32 * i_364_460)) + 831)], (einsum_361_58Y_46grad[0] * y_361[(((-1 * einsum_363_58i_361) + (13 * (int)threadIdx.y)) + 12)]));\r\n",
      "\u001b[33m 95\u001b[0m                 x_46grad_46atomic__cache_46_35357[((einsum_363_58i_361 * -1) + 12)] += (einsum_58Y_46grad[0] * w0[((((-64 * einsum_363_58i_361) + (-1 * (int)threadIdx.x)) + (-32 * i_364_460)) + 831)]);\r\n",
      "\u001b[33m 96\u001b[0m                 atomicAdd(&w0_46grad[((((-64 * einsum_363_58i_361) + (-1 * (int)threadIdx.x)) + (-32 * i_364_460)) + 831)], (einsum_58Y_46grad[0] * x[((((-1 * einsum_363_58i_361) + (-104 * (int)blockIdx.x)) + (-13 * (int)threadIdx.y)) + 159743)]));\r\n",
      "\u001b[33m 97\u001b[0m               }\r\n",
      "\u001b[33m 98\u001b[0m               einsum_363_58Y_46grad[0] = 0;\r\n",
      "\u001b[33m 99\u001b[0m             }\r\n",
      "\u001b[33m100\u001b[0m             einsum_362_58Y_46grad[0] = 0;\r\n",
      "\u001b[33m101\u001b[0m           }\r\n",
      "\u001b[33m102\u001b[0m           einsum_361_58Y_46grad[0] = 0;\r\n",
      "\u001b[33m103\u001b[0m         }\r\n",
      "\u001b[33m104\u001b[0m         einsum_58Y_46grad[0] = 0;\r\n",
      "\u001b[33m105\u001b[0m       }\r\n",
      "\u001b[33m106\u001b[0m       for (int x_46grad_46atomic__cache_46_35357_46i0 = 0; x_46grad_46atomic__cache_46_35357_46i0 < 13; x_46grad_46atomic__cache_46_35357_46i0++) {\r\n",
      "\u001b[33m107\u001b[0m         atomicAdd(&x_46grad[((((-104 * (int)blockIdx.x) + (-13 * (int)threadIdx.y)) + x_46grad_46atomic__cache_46_35357_46i0) + 159731)], x_46grad_46atomic__cache_46_35357[x_46grad_46atomic__cache_46_35357_46i0]);\r\n",
      "\u001b[33m108\u001b[0m       }\r\n",
      "\u001b[33m109\u001b[0m     }\r\n",
      "\u001b[33m110\u001b[0m     for (int ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460 = 0; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460 < 13; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460++) {\r\n",
      "\u001b[33m111\u001b[0m #pragma unroll 5\r\n",
      "\u001b[33m112\u001b[0m       for (int ____reduce__p = 0; ____reduce__p < 5; ____reduce__p++) {\r\n",
      "\u001b[33m113\u001b[0m         if (((runtime_mod((int)threadIdx.x, ((1 << (____reduce__p)) * 2)) == 0) && (((int)threadIdx.x + (1 << (____reduce__p))) < 32))) {\r\n",
      "\u001b[33m114\u001b[0m           ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0[(((13 * (int)threadIdx.x) + (416 * (int)threadIdx.y)) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460)] += ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0[(((((int)threadIdx.y * 32) + ((int)threadIdx.x + (1 << (____reduce__p)))) * 13) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460)];\r\n",
      "\u001b[33m115\u001b[0m         }\r\n",
      "\u001b[33m116\u001b[0m         (__syncwarp());\r\n",
      "\u001b[33m117\u001b[0m       }\r\n",
      "\u001b[33m118\u001b[0m       y_363_46grad[(((int)threadIdx.y * 13) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460)] += ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0[((416 * (int)threadIdx.y) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__0_460)];\r\n",
      "\u001b[33m119\u001b[0m     }\r\n",
      "\u001b[33m120\u001b[0m     for (int ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460 = 0; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460 < 13; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460++) {\r\n",
      "\u001b[33m121\u001b[0m #pragma unroll 5\r\n",
      "\u001b[33m122\u001b[0m       for (int ____reduce__p = 0; ____reduce__p < 5; ____reduce__p++) {\r\n",
      "\u001b[33m123\u001b[0m         if (((runtime_mod((int)threadIdx.x, ((1 << (____reduce__p)) * 2)) == 0) && (((int)threadIdx.x + (1 << (____reduce__p))) < 32))) {\r\n",
      "\u001b[33m124\u001b[0m           ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1[(((13 * (int)threadIdx.x) + (416 * (int)threadIdx.y)) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460)] += ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1[(((((int)threadIdx.y * 32) + ((int)threadIdx.x + (1 << (____reduce__p)))) * 13) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460)];\r\n",
      "\u001b[33m125\u001b[0m         }\r\n",
      "\u001b[33m126\u001b[0m         (__syncwarp());\r\n",
      "\u001b[33m127\u001b[0m       }\r\n",
      "\u001b[33m128\u001b[0m       y_362_46grad[(((int)threadIdx.y * 13) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460)] += ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1[((416 * (int)threadIdx.y) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__1_460)];\r\n",
      "\u001b[33m129\u001b[0m     }\r\n",
      "\u001b[33m130\u001b[0m     for (int ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460 = 0; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460 < 13; ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460++) {\r\n",
      "\u001b[33m131\u001b[0m #pragma unroll 5\r\n",
      "\u001b[33m132\u001b[0m       for (int ____reduce__p = 0; ____reduce__p < 5; ____reduce__p++) {\r\n",
      "\u001b[33m133\u001b[0m         if (((runtime_mod((int)threadIdx.x, ((1 << (____reduce__p)) * 2)) == 0) && (((int)threadIdx.x + (1 << (____reduce__p))) < 32))) {\r\n",
      "\u001b[33m134\u001b[0m           ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2[(((13 * (int)threadIdx.x) + (416 * (int)threadIdx.y)) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460)] += ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2[(((((int)threadIdx.y * 32) + ((int)threadIdx.x + (1 << (____reduce__p)))) * 13) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460)];\r\n",
      "\u001b[33m135\u001b[0m         }\r\n",
      "\u001b[33m136\u001b[0m         (__syncwarp());\r\n",
      "\u001b[33m137\u001b[0m       }\r\n",
      "\u001b[33m138\u001b[0m       y_361_46grad[(((int)threadIdx.y * 13) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460)] += ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2[((416 * (int)threadIdx.y) + ____reduce__fused_46fused_46fused_46fused_46fused_46fused_46fused_46L__elem_363_46recur_3612_58L__elem_46recur_3611_58L__elem_46recur_3610_58L__elem_46_3548_46_3542_46_3536_46_3530_461__2_460)];\r\n",
      "\u001b[33m139\u001b[0m     }\r\n",
      "\u001b[33m140\u001b[0m   }\r\n",
      "\u001b[33m141\u001b[0m   (__syncthreads());\r\n",
      "\u001b[33m142\u001b[0m #pragma unroll 3\r\n",
      "\u001b[33m143\u001b[0m   for (int p_46cnt = 0; p_46cnt < 3; p_46cnt++) {\r\n",
      "\u001b[33m144\u001b[0m     int p = 2 + p_46cnt * -1;\r\n",
      "\u001b[33m145\u001b[0m     {\r\n",
      "\u001b[33m146\u001b[0m       float (*out) = (float(*))(__shmem + 42432);\r\n",
      "\u001b[33m147\u001b[0m       float (*out_361_46out_361) = (float(*))(__shmem + 42848);\r\n",
      "\u001b[33m148\u001b[0m       float out_361_46grad[1];\r\n",
      "\u001b[33m149\u001b[0m       float y_365_46grad[1];\r\n",
      "\u001b[33m150\u001b[0m       if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m151\u001b[0m         out[(((int)threadIdx.y * 13) + (int)threadIdx.x)] = (x[((adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + p) + 36861)] * 13) + (int)threadIdx.x)] - x[((adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + ((p + 1) % 3)) + 36861)] * 13) + (int)threadIdx.x)]);\r\n",
      "\u001b[33m152\u001b[0m         out_361_46out_361[(((int)threadIdx.y * 13) + (int)threadIdx.x)] = (x[((adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + p) + 36861)] * 13) + (int)threadIdx.x)] - x[((((-104 * (int)blockIdx.x) + (int)threadIdx.x) + (-13 * (int)threadIdx.y)) + 159731)]);\r\n",
      "\u001b[33m153\u001b[0m         y_365_46grad[0] = y_363_46grad[(((-1 * (int)threadIdx.x) + (13 * (int)threadIdx.y)) + 12)];\r\n",
      "\u001b[33m154\u001b[0m       }\r\n",
      "\u001b[33m155\u001b[0m       (__syncwarp());\r\n",
      "\u001b[33m156\u001b[0m       if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m157\u001b[0m         out_361_46grad[0] = ((out_361_46out_361[(((-1 * (int)threadIdx.x) + (13 * (int)threadIdx.y)) + 12)] >= 0) ? y_365_46grad[0] : (-1 * y_365_46grad[0]));\r\n",
      "\u001b[33m158\u001b[0m         atomicAdd(&x_46grad[(((-1 * (int)threadIdx.x) + (13 * adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + p) + 36861)])) + 12)], out_361_46grad[0]);\r\n",
      "\u001b[33m159\u001b[0m       }\r\n",
      "\u001b[33m160\u001b[0m       (__syncthreads());\r\n",
      "\u001b[33m161\u001b[0m       if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m162\u001b[0m         atomicAdd(&x_46grad[((((-104 * (int)blockIdx.x) + (-1 * (int)threadIdx.x)) + (-13 * (int)threadIdx.y)) + 159743)], (-1 * out_361_46grad[0]));\r\n",
      "\u001b[33m163\u001b[0m       }\r\n",
      "\u001b[33m164\u001b[0m       {\r\n",
      "\u001b[33m165\u001b[0m         float out_46grad[1];\r\n",
      "\u001b[33m166\u001b[0m         if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m167\u001b[0m           float y_364_46grad[1];\r\n",
      "\u001b[33m168\u001b[0m           y_364_46grad[0] = y_362_46grad[(((-1 * (int)threadIdx.x) + (13 * (int)threadIdx.y)) + 12)];\r\n",
      "\u001b[33m169\u001b[0m           out_46grad[0] = ((out[(((-1 * (int)threadIdx.x) + (13 * (int)threadIdx.y)) + 12)] >= 0) ? y_364_46grad[0] : (-1 * y_364_46grad[0]));\r\n",
      "\u001b[33m170\u001b[0m         }\r\n",
      "\u001b[33m171\u001b[0m         (__syncthreads());\r\n",
      "\u001b[33m172\u001b[0m         if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m173\u001b[0m           atomicAdd(&x_46grad[(((-1 * (int)threadIdx.x) + (13 * adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + p) + 36861)])) + 12)], out_46grad[0]);\r\n",
      "\u001b[33m174\u001b[0m         }\r\n",
      "\u001b[33m175\u001b[0m         (__syncthreads());\r\n",
      "\u001b[33m176\u001b[0m         if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m177\u001b[0m           atomicAdd(&x_46grad[(((-1 * (int)threadIdx.x) + (13 * adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + ((p + 1) % 3)) + 36861)])) + 12)], (-1 * out_46grad[0]));\r\n",
      "\u001b[33m178\u001b[0m         }\r\n",
      "\u001b[33m179\u001b[0m       }\r\n",
      "\u001b[33m180\u001b[0m       (__syncthreads());\r\n",
      "\u001b[33m181\u001b[0m       if (((int)threadIdx.x < 13)) {\r\n",
      "\u001b[33m182\u001b[0m         atomicAdd(&x_46grad[(((-1 * (int)threadIdx.x) + (13 * adj[((((-24 * (int)blockIdx.x) + (-3 * (int)threadIdx.y)) + p) + 36861)])) + 12)], y_361_46grad[(((-1 * (int)threadIdx.x) + (13 * (int)threadIdx.y)) + 12)]);\r\n",
      "\u001b[33m183\u001b[0m       }\r\n",
      "\u001b[33m184\u001b[0m     }\r\n",
      "\u001b[33m185\u001b[0m     (__syncthreads());\r\n",
      "\u001b[33m186\u001b[0m   }\r\n",
      "\u001b[33m187\u001b[0m   if (((int)threadIdx.x == 0)) {\r\n",
      "\u001b[33m188\u001b[0m     for (int recur_362_58i = 0; recur_362_58i < 13; recur_362_58i++) {\r\n",
      "\u001b[33m189\u001b[0m       y_363_46grad[(((13 * (int)threadIdx.y) + (-1 * recur_362_58i)) + 12)] = 0;\r\n",
      "\u001b[33m190\u001b[0m       y_362_46grad[(((13 * (int)threadIdx.y) + (-1 * recur_362_58i)) + 12)] = 0;\r\n",
      "\u001b[33m191\u001b[0m       y_361_46grad[(((13 * (int)threadIdx.y) + (-1 * recur_362_58i)) + 12)] = 0;\r\n",
      "\u001b[33m192\u001b[0m     }\r\n",
      "\u001b[33m193\u001b[0m   }\r\n",
      "\u001b[33m194\u001b[0m }\r\n",
      "\u001b[33m195\u001b[0m \r\n",
      "\u001b[33m196\u001b[0m void run(void **_params, void **_returns, size_t **_retShapes, size_t *_retDims, GPUContext_t _ctx) {\r\n",
      "\u001b[33m197\u001b[0m   const int32_t (*restrict adj) = (int32_t(*))_params[0];\r\n",
      "\u001b[33m198\u001b[0m   const float (*restrict x) = (float(*))_params[1];\r\n",
      "\u001b[33m199\u001b[0m   float (*restrict x_46grad) = (float(*))_params[7];\r\n",
      "\u001b[33m200\u001b[0m   const float (*restrict w0) = (float(*))_params[2];\r\n",
      "\u001b[33m201\u001b[0m   float (*restrict w0_46grad) = (float(*))_params[8];\r\n",
      "\u001b[33m202\u001b[0m   const float (*restrict w1) = (float(*))_params[3];\r\n",
      "\u001b[33m203\u001b[0m   float (*restrict w1_46grad) = (float(*))_params[9];\r\n",
      "\u001b[33m204\u001b[0m   const float (*restrict w2) = (float(*))_params[4];\r\n",
      "\u001b[33m205\u001b[0m   float (*restrict w2_46grad) = (float(*))_params[11];\r\n",
      "\u001b[33m206\u001b[0m   const float (*restrict w3) = (float(*))_params[5];\r\n",
      "\u001b[33m207\u001b[0m   float (*restrict w3_46grad) = (float(*))_params[10];\r\n",
      "\u001b[33m208\u001b[0m   const float (*restrict y) = (float(*))_params[6];\r\n",
      "\u001b[33m209\u001b[0m   float (*restrict y_46grad) = (float(*))_params[12];\r\n",
      "\u001b[33m210\u001b[0m   {\r\n",
      "\u001b[33m211\u001b[0m     uint8_t *__glmem = NULL;\r\n",
      "\u001b[33m212\u001b[0m     cudaFuncSetAttribute(kernel0, cudaFuncAttributeMaxDynamicSharedMemorySize, 0);\r\n",
      "\u001b[33m213\u001b[0m     kernel0<<<dim3(1536, 1, 1), dim3(13, 8, 1), 0>>>(x_46grad, __glmem);\r\n",
      "\u001b[33m214\u001b[0m   }\r\n",
      "\u001b[33m215\u001b[0m   {\r\n",
      "\u001b[33m216\u001b[0m     uint8_t *__glmem = NULL;\r\n",
      "\u001b[33m217\u001b[0m     cudaFuncSetAttribute(kernel1, cudaFuncAttributeMaxDynamicSharedMemorySize, 0);\r\n",
      "\u001b[33m218\u001b[0m     kernel1<<<dim3(26, 1, 1), dim3(32, 1, 1), 0>>>(w3_46grad, w2_46grad, w0_46grad, w1_46grad, __glmem);\r\n",
      "\u001b[33m219\u001b[0m   }\r\n",
      "\u001b[33m220\u001b[0m   {\r\n",
      "\u001b[33m221\u001b[0m     uint8_t *__glmem = NULL;\r\n",
      "\u001b[33m222\u001b[0m     cudaFuncSetAttribute(kernel2, cudaFuncAttributeMaxDynamicSharedMemorySize, 43264);\r\n",
      "\u001b[33m223\u001b[0m     kernel2<<<dim3(1536, 1, 1), dim3(32, 8, 1), 43264>>>(w1, w2_46grad, adj, w3, x_46grad, x, y_46grad, w0, w1_46grad, w3_46grad, w0_46grad, w2, __glmem);\r\n",
      "\u001b[33m224\u001b[0m   }\r\n",
      "\u001b[33m225\u001b[0m }\r\n",
      "\u001b[33m226\u001b[0m \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m227\u001b[0m }/home/pldi22_ae/.ir/5ubZLP/run.cu(208): warning: variable \"y\" was declared but never referenced\n",
      "\n",
      "\n",
      "10 warmup, 100 repeats for evalution\n",
      "Inference Time = 0.043218135833740234 ms\n",
      "Forward Time = 0.043311119079589844 ms\n",
      "Backward Time = 0.5713033676147461 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/ours && srun -p PLDI main.sh gpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e98feda",
   "metadata": {},
   "source": [
    "### Pytorch (impl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4996b",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359ad4f4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100 repeats for evalution\n",
      "Impl1 Inference Time = 1.5073108673095703 ms\n",
      "Impl1 Forward Time = 1.68961763381958 ms\n",
      "Impl1 Backward Time = 6.992197036743164 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/pytorch_impl1 && srun -p PLDI main.sh cpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b785724",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5feb2527",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100 repeats for evalution\n",
      "Impl1 Inference Time = 0.7490968704223633 ms\n",
      "Impl1 Forward Time = 0.6979560852050781 ms\n",
      "Impl1 Backward Time = 1.2151646614074707 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/pytorch_impl1 && srun -p PLDI main.sh gpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba8edae",
   "metadata": {},
   "source": [
    "### Pytorch (impl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b3f3f",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40861564",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100 repeats for evalution\n",
      "Impl2 Inference Time = 1.838548183441162 ms\n",
      "Impl2 Forward Time = 2.163097858428955 ms\n",
      "Impl2 Backward Time = 9.183094501495361 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/pytorch_impl2 && srun -p PLDI main.sh cpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa13c7",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "195e690a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100 repeats for evalution\n",
      "Impl2 Inference Time = 1.1577057838439941 ms\n",
      "Impl2 Forward Time = 0.9626364707946777 ms\n",
      "Impl2 Backward Time = 1.9742012023925781 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/pytorch_impl2 && srun -p PLDI main.sh gpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363617e1",
   "metadata": {},
   "source": [
    "### Jax (impl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85ad4f",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4e667b8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100 repeats for evalution\n",
      "Inference Time = 2.666919231414795 ms\n",
      "Forward+Backward Time = 75.57671546936035 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/jax_impl1 && srun -p PLDI main.sh cpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c1b04",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da6e27f1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100 repeats for evalution\n",
      "Inference Time = 0.20483016967773438 ms\n",
      "Forward+Backward Time = 42.896907329559326 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/jax_impl1 && srun -p PLDI main.sh gpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f99496",
   "metadata": {},
   "source": [
    "### Jax (impl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c03308",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8adf286a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100 repeats for evalution\n",
      "Inference Time = 1.5279698371887207 ms\n",
      "Forward+Backward Time = 145.94613075256348 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/jax_impl2 && srun -p PLDI main.sh cpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd2f765",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "412f8360",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100 repeats for evalution\n",
      "Inference Time = 0.15556812286376953 ms\n",
      "Forward+Backward Time = 120.20254135131836 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/jax_impl2 && srun -p PLDI main.sh gpu --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e698ee",
   "metadata": {},
   "source": [
    "### TVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e77e7e",
   "metadata": {},
   "source": [
    "#### CPU\n",
    "pre-tune schedule: `~/TVM_pretune/subdivnet/ansor.cpu.2021-11-14.16-11-43.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e921256",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:autotvm:Finish loading 35 records\n",
      "INFO:te_compiler:Using injective.cpu for zeros based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for adv_index based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using matmul_mkl.x86 for nn.matmul based on highest priority (14)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(C, 0x7f27b4014f50)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using matmul_mkl.x86 for nn.matmul based on highest priority (14)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(C, 0x7f27b40476b0)\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 4.49\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 9.24\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 13.65\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 18.20\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 22.63\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 23.59\n",
      "GA Iter: 0\tMax score: 0.1549\tMin score: 0.1549\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.1549\tMin score: 0.1549\t#Pop: 1\t#M+: 0\t#M-: 9411\n",
      "EvolutionarySearch\t\t#s: 1\tTime elapsed: 2.81\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 1 programs to measure:\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!! TUNING             !!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "#Tuning trials 8000\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |      0 |\n",
      "|    1 |            - |              - |      0 |\n",
      "|    2 |            - |              - |      0 |\n",
      "|    3 |            - |              - |      0 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 0\tUsed time : 0 s\tNext ID: 0\t\n",
      ".E\n",
      "==================================================\n",
      "No: 1\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230595.98)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,13)\n",
      "    T_add = ...\n",
      "\n",
      "Time elapsed for measurement: 0.01 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pldi22_ae/.local/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.450000\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.002319\n",
      "DEBUG:auto_scheduler:XGB iter: 100\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000012\n",
      "DEBUG:auto_scheduler:XGB iter: 150\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000000\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [132] tr-a-peak@32:1.00000\ttr-p-rmse:0.00000 \n",
      "Time elapsed for training: 1.15 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 4\t#Target: 50\tfail_ct: 10236\tTime elapsed: 2.28\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 4\t#Target: 25\tfail_ct: 20476\tTime elapsed: 4.63\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 4\t#Target: 12\tfail_ct: 30716\tTime elapsed: 6.81\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 4\t#Target: 6\tfail_ct: 40956\tTime elapsed: 9.22\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 4\tfail_ct: 43004\tTime elapsed: 9.67\n",
      "GA Iter: 0\tMax score: 0.7776\tMin score: 0.0784\t#Pop: 4\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.8938\tMin score: 0.0784\t#Pop: 5\t#M+: 295\t#M-: 7398\n",
      "EvolutionarySearch\t\t#s: 5\tTime elapsed: 1.89\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 5 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |      0 |\n",
      "|    2 |            - |              - |      0 |\n",
      "|    3 |            - |              - |      0 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 1\tUsed time : 28 s\tNext ID: 1\t\n",
      ".E.E.E.E.E\n",
      "==================================================\n",
      "No: 2\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230608.72)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax2 (0,13)\n",
      "    T_strided_slice = ...\n",
      "  for ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 3\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230608.72)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax2 (0,13)\n",
      "    T_strided_slice = ...\n",
      "  vectorize ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 4\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230608.72)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,13)\n",
      "    T_strided_slice = ...\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 5\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230608.72)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax2 (0,13)\n",
      "    T_strided_slice = ...\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 6\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230608.72)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1@ax2@ (0,13)\n",
      "    T_strided_slice = ...\n",
      "  vectorize ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.02 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.135680\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.011874\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [28] tr-a-peak@32:1.00000\ttr-p-rmse:0.01177 \n",
      "Time elapsed for training: 0.12 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 4\t#Target: 50\tfail_ct: 10236\tTime elapsed: 2.28\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 4\t#Target: 25\tfail_ct: 20476\tTime elapsed: 4.54\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 4\t#Target: 12\tfail_ct: 30716\tTime elapsed: 6.62\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 4\t#Target: 6\tfail_ct: 40956\tTime elapsed: 8.76\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 4\tfail_ct: 43004\tTime elapsed: 9.21\n",
      "GA Iter: 0\tMax score: 0.9026\tMin score: 0.0845\t#Pop: 4\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9026\tMin score: 0.0845\t#Pop: 5\t#M+: 293\t#M-: 7244\n",
      "EvolutionarySearch\t\t#s: 5\tTime elapsed: 1.72\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 5 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |      0 |\n",
      "|    3 |            - |              - |      0 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 6\tUsed time : 40 s\tNext ID: 2\t\n",
      ".E.E.E.E.E\n",
      "==================================================\n",
      "No: 7\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230619.79)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax2 (0,13)\n",
      "    T_strided_slice = ...\n",
      "  vectorize ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 8\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230619.79)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax2 (0,13)\n",
      "    T_strided_slice = ...\n",
      "  for ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 9\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230619.79)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax2 (0,13)\n",
      "    T_strided_slice = ...\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 10\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230619.79)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,13)\n",
      "    T_strided_slice = ...\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 11\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230619.79)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1@ax2@ (0,13)\n",
      "    T_strided_slice = ...\n",
      "  vectorize ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.01 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.098198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.008645\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [28] tr-a-peak@32:1.00000\ttr-p-rmse:0.00860 \n",
      "Time elapsed for training: 0.09 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 1.21\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 2.27\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 3.30\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 4.35\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 5.41\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 5.63\n",
      "GA Iter: 0\tMax score: 0.2545\tMin score: 0.2545\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.2545\tMin score: 0.2545\t#Pop: 1\t#M+: 0\t#M-: 9227\n",
      "EvolutionarySearch\t\t#s: 1\tTime elapsed: 0.88\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 1 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |      0 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 11\tUsed time : 51 s\tNext ID: 3\t\n",
      ".E\n",
      "==================================================\n",
      "No: 12\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230626.41)\n",
      "==================================================\n",
      "Placeholder: \n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,13)\n",
      "    T_full = ...\n",
      "\n",
      "Time elapsed for measurement: 0.01 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.130655\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.007422\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [22] tr-a-peak@32:1.00000\ttr-p-rmse:0.00734 \n",
      "Time elapsed for training: 0.12 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 4\t#Target: 50\tfail_ct: 10236\tTime elapsed: 2.21\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 4\t#Target: 25\tfail_ct: 20476\tTime elapsed: 4.36\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 4\t#Target: 12\tfail_ct: 30716\tTime elapsed: 6.60\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 4\t#Target: 6\tfail_ct: 40956\tTime elapsed: 8.93\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 4\tfail_ct: 43004\tTime elapsed: 9.41\n",
      "GA Iter: 0\tMax score: 0.9676\tMin score: 0.0774\t#Pop: 4\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9676\tMin score: 0.0774\t#Pop: 4\t#M+: 27\t#M-: 9081\n",
      "EvolutionarySearch\t\t#s: 4\tTime elapsed: 1.64\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 4 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 12\tUsed time : 57 s\tNext ID: 4\t\n",
      ".E.E.E.E\n",
      "==================================================\n",
      "No: 13\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230637.60)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1@ax2@ (0,13)\n",
      "    T_strided_slice = ...\n",
      "  vectorize ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 14\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230637.60)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,13)\n",
      "    T_strided_slice = ...\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 15\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230637.60)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax2 (0,13)\n",
      "    T_strided_slice = ...\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 16\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230637.60)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax2 (0,13)\n",
      "    T_strided_slice = ...\n",
      "  vectorize ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.01 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.111886\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.006367\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [22] tr-a-peak@32:1.00000\ttr-p-rmse:0.00632 \n",
      "Time elapsed for training: 0.13 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 18\t#Target: 50\tfail_ct: 10222\tTime elapsed: 4.75\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 18\t#Target: 25\tfail_ct: 20462\tTime elapsed: 9.50\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Initial Population\t#s: 18\tfail_ct: 22510\tTime elapsed: 10.48\n",
      "GA Iter: 0\tMax score: 0.9817\tMin score: 0.1373\t#Pop: 18\t#M+: 0\t#M-: 0\n",
      "[22:17:28] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:28] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:28] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:28] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:28] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:28] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:28] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:17:28] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:17:28] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:17:28] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:17:28] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:17:28] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:29] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:29] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:29] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:29] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:29] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:29] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:29] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:29] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:29] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:29] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:29] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:29] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:29] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:29] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:29] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:29] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:30] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:30] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:30] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:30] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:30] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:17:30] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:17:30] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:17:30] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:17:30] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:17:30] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:17:30] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:17:30] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:31] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:31] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:31] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:31] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:17:31] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:17:31] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA Iter: 4\tMax score: 0.9817\tMin score: 0.1017\t#Pop: 37\t#M+: 279\t#M-: 7392\n",
      "EvolutionarySearch\t\t#s: 37\tTime elapsed: 3.90\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 37 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 16\tUsed time : 69 s\tNext ID: 5\t\n",
      ".E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E\n",
      "==================================================\n",
      "No: 17\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax1@ax2@ (0,13)\n",
      "      advanced_index = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 18\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 19\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 20\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 21\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 22\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 23\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 24\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 25\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 26\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 27\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 28\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 29\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 30\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 31\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 32\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 33\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 34\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax1@ax2@ (0,13)\n",
      "      advanced_index = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 35\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 36\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 37\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 38\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.23)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 39\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 40\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 41\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 42\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 43\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 44\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 45\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 46\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 47\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 48\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 49\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 50\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 51\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 52\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 53\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230652.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.09 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.189310\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.005344\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [22] tr-a-peak@32:1.00000\ttr-p-rmse:0.00531 \n",
      "Time elapsed for training: 0.21 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 1.74\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 3.50\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 5.26\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 7.14\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 8.88\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 9.23\n",
      "GA Iter: 0\tMax score: 0.8448\tMin score: 0.8448\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.8448\tMin score: 0.8448\t#Pop: 1\t#M+: 0\t#M-: 9348\n",
      "EvolutionarySearch\t\t#s: 1\tTime elapsed: 1.23\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 1 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 53\tUsed time : 83 s\tNext ID: 6\t\n",
      ".E\n",
      "==================================================\n",
      "No: 54\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230662.92)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,13)\n",
      "    T_add = ...\n",
      "\n",
      "Time elapsed for measurement: 0.01 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.191721\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.005033\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [22] tr-a-peak@32:1.00000\ttr-p-rmse:0.00500 \n",
      "Time elapsed for training: 0.17 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 4.64\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 9.28\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 13.93\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 18.47\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 23.05\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 23.96\n",
      "GA Iter: 0\tMax score: 0.8653\tMin score: 0.8653\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.8653\tMin score: 0.8653\t#Pop: 1\t#M+: 0\t#M-: 9283\n",
      "EvolutionarySearch\t\t#s: 1\tTime elapsed: 2.64\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 1 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 54\tUsed time : 94 s\tNext ID: 7\t\n",
      ".E\n",
      "==================================================\n",
      "No: 55\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230689.71)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,13)\n",
      "    T_add = ...\n",
      "\n",
      "Time elapsed for measurement: 0.02 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.194023\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.004937\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [22] tr-a-peak@32:1.00000\ttr-p-rmse:0.00490 \n",
      "Time elapsed for training: 0.16 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 4\tfail_ct: 2044\tTime elapsed: 0.43\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 255\t#M-: 7668\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 1.83\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.91\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 9472\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 2.67\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Initial Population\t#s: 4\tfail_ct: 2044\tTime elapsed: 0.44\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 246\t#M-: 7827\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 1.78\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.21\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 9405\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 0.99\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 4\tfail_ct: 2044\tTime elapsed: 0.50\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.1319\tMin score: 0.1319\t#Pop: 1\t#M+: 208\t#M-: 7945\n",
      "EvolutionarySearch\t\t#s: 1\tTime elapsed: 1.79\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 1 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 55\tUsed time : 121 s\tNext ID: 2\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 55\tUsed time : 123 s\tNext ID: 0\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 55\tUsed time : 127 s\tNext ID: 1\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 55\tUsed time : 129 s\tNext ID: 3\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 55\tUsed time : 130 s\tNext ID: 4\t\n",
      ".E\n",
      "==================================================\n",
      "No: 56\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230701.53)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax2 (0,13)\n",
      "    T_strided_slice = ...\n",
      "  for ax1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.01 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.192680\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.004922\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [22] tr-a-peak@32:1.00000\ttr-p-rmse:0.00489 \n",
      "Time elapsed for training: 0.16 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 18\tfail_ct: 2030\tTime elapsed: 0.95\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (0,12288)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      for ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (0,3)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (0,13)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:22] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:22] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:23] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:23] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:23] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:23] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:23] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:23] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:23] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:23] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:23] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:23] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:23] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:23] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:23] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:23] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:23] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:23] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (0,12288)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      for ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (0,3)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (0,13)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:24] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:24] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (0,12288)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      for ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (0,3)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (0,13)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:25] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:25] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA Iter: 4\tMax score: 0.9004\tMin score: 0.7190\t#Pop: 3\t#M+: 323\t#M-: 7243\n",
      "EvolutionarySearch\t\t#s: 3\tTime elapsed: 3.60\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 3 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |    128 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 56\tUsed time : 133 s\tNext ID: 5\t\n",
      ".E.E.E\n",
      "==================================================\n",
      "No: 57\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230706.26)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 58\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230706.26)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 59\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230706.26)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.01 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.193118\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.004753\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [22] tr-a-peak@32:1.00000\ttr-p-rmse:0.00472 \n",
      "Time elapsed for training: 0.20 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.38\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 9376\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 1.20\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.95\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 9221\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 2.67\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 4\tfail_ct: 2044\tTime elapsed: 0.44\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 144\t#M-: 8300\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 1.93\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 18\tfail_ct: 2030\tTime elapsed: 0.93\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "[22:18:35] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:35] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:35] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:35] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:35] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (0,12288)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      for ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (0,3)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (0,13)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:35] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:35] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (0,12288)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      for ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (0,3)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (0,13)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:35] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:35] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:35] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:35] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:35] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:36] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:36] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:37] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:37] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:37] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:37] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:37] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:37] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:37] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:37] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:37] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:37] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:37] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:37] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:37] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:37] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:37] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:37] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:37] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:37] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:38] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:38] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:38] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:38] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:38] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:38] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:38] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:38] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:38] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:38] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA Iter: 4\tMax score: 0.9399\tMin score: 0.5079\t#Pop: 2\t#M+: 316\t#M-: 7255\n",
      "EvolutionarySearch\t\t#s: 2\tTime elapsed: 3.71\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 2 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |    128 |\n",
      "|    5 |            - |              - |    128 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 59\tUsed time : 137 s\tNext ID: 6\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |    128 |\n",
      "|    5 |            - |              - |    128 |\n",
      "|    6 |            - |              - |    128 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 59\tUsed time : 139 s\tNext ID: 7\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |    128 |\n",
      "|    5 |            - |              - |    128 |\n",
      "|    6 |            - |              - |    128 |\n",
      "|    7 |            - |              - |    128 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 59\tUsed time : 143 s\tNext ID: 4\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |    192 |\n",
      "|    5 |            - |              - |    128 |\n",
      "|    6 |            - |              - |    128 |\n",
      "|    7 |            - |              - |    128 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 59\tUsed time : 145 s\tNext ID: 5\t\n",
      ".E.E\n",
      "==================================================\n",
      "No: 60\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230718.74)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 61\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646230718.74)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  vectorize ax1 (0,3)\n",
      "    T_reshape = ...\n",
      "parallel ax0 (0,12288)\n",
      "  for ax1 (0,3)\n",
      "    vectorize ax2 (0,13)\n",
      "      advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.01 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.193383\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.004646\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [22] tr-a-peak@32:1.00000\ttr-p-rmse:0.00462 \n",
      "Time elapsed for training: 0.17 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 18\tfail_ct: 2030\tTime elapsed: 0.95\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "[22:18:39] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:39] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:40] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:40] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:40] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:40] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:40] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:40] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:40] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:40] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:40] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:40] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:40] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:40] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:41] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:41] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:41] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:41] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:41] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:41] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "[22:18:41] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\r\n",
      "Placeholder: placeholder, placeholder\r\n",
      "parallel ax0 (None)\r\n",
      "  for ax0 (None)\r\n",
      "    for ax1 (None)\r\n",
      "      vectorize ax2 (None)\r\n",
      "        advanced_index = ...\r\n",
      "  for ax1 (None)\r\n",
      "    for ax0 (None)\r\n",
      "      vectorize ax1 (None)\r\n",
      "        T_reshape = ...\r\n",
      "    for ax2 (None)\r\n",
      "      T_reshape = ...\r\n",
      "\r\n",
      "with: [22:18:41] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \r\n",
      "---------------------------------------------------------------\r\n",
      "An error occurred during the execution of TVM.\r\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\r\n",
      "---------------------------------------------------------------\r\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\r\n",
      "Stack trace:\r\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\r\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\r\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\r\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\r\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\r\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\r\n",
      "  6: __pthread_once_slow\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\r\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\r\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\r\n",
      "  9: execute_native_thread_routine\r\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\r\n",
      "  10: start_thread\r\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\r\n",
      "  11: clone\r\n",
      "  12: 0xffffffffffffffff\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:41] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:41] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:41] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:41] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:41] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:41] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:42] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:42] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:42] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:42] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "[22:18:42] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (0,12288)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      for ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (0,3)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (0,13)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:42] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:42] /home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:\n",
      "Placeholder: placeholder, placeholder\n",
      "parallel ax0 (None)\n",
      "  for ax0 (None)\n",
      "    for ax1 (None)\n",
      "      vectorize ax2 (None)\n",
      "        advanced_index = ...\n",
      "  for ax1 (None)\n",
      "    for ax0 (None)\n",
      "      vectorize ax1 (None)\n",
      "        T_reshape = ...\n",
      "    for ax2 (None)\n",
      "      T_reshape = ...\n",
      "\n",
      "with: [22:18:42] /home/zhenly/App/tvm-211104/src/te/schedule/bound.cc:175: \n",
      "---------------------------------------------------------------\n",
      "An error occurred during the execution of TVM.\n",
      "For more information, please see: https://tvm.apache.org/docs/errors.html\n",
      "---------------------------------------------------------------\n",
      "  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(T_reshape, body=[placeholder[floormod(floordiv(((ax0*3) + ax1), 3), 12288), floormod(((ax0*3) + ax1), 3)]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3))], reduce_axis=[], tag=injective, attrs={}) along the loop nest specified by compute_at of consumer compute(advanced_index, body=[placeholder[T_reshape[ax0, ax1], ax2]], axis=[iter_var(ax0, range(min=0, ext=12288)), iter_var(ax1, range(min=0, ext=3)), iter_var(ax2, range(min=0, ext=13))], reduce_axis=[], tag=injective, attrs={})\n",
      "Stack trace:\n",
      "  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)\n",
      "  1: tvm::te::InferBound(tvm::te::Schedule const&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const\n",
      "  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const\n",
      "  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stat\n",
      "  5: _ZNSt13__future_base13_State_baseV29_M_do_setEPSt8functionIFSt10unique_ptrINS_12_Result_baseEN\n",
      "  6: __pthread_once_slow\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_once.c:116\n",
      "  7: _ZSt9call_onceIMNSt13__future_base13_State_baseV2EFvPSt8functionIFSt10unique_ptrINS0_12_Result_baseENS4_8_DeleterEEvEEPbEJ\n",
      "  8: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()\n",
      "  9: execute_native_thread_routine\n",
      "        at /tmp/root/spack-stage/spack-stage-gcc-8.4.0-wxwjau3zh2vgh3gbw56byro6skfjuhkz/spack-src/libstdc++-v3/src/c++11/thread.cc:80\n",
      "  10: start_thread\n",
      "        at /build/glibc-Cl5G7W/glibc-2.23/nptl/pthread_create.c:333\n",
      "  11: clone\n",
      "  12: 0xffffffffffffffff\n",
      "\n",
      "\n",
      "\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 312\t#M-: 7171\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 3.83\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "DEBUG:auto_scheduler:Finish loading 61 records\n",
      "DEBUG:autotvm:Finish loading 35 records\n",
      "INFO:te_compiler:Using injective.cpu for zeros based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for adv_index based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using matmul_mkl.x86 for nn.matmul based on highest priority (14)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(C, 0x24b99b0)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using matmul_mkl.x86 for nn.matmul based on highest priority (14)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(C, 0x24db460)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:te_compiler:Using matmul_mkl.x86 for nn.matmul based on highest priority (14)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(C, 0x2499790)\n",
      "INFO:te_compiler:Using matmul_mkl.x86 for nn.matmul based on highest priority (14)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(C, 0x2636520)\n",
      "INFO:te_compiler:Using matmul_mkl.x86 for nn.matmul based on highest priority (14)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(C, 0x29d26b0)\n",
      "INFO:te_compiler:Using matmul_mkl.x86 for nn.matmul based on highest priority (14)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(C, 0x29b7fc0)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for zeros based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for adv_index based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cpu for abs based on highest priority (10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:te_compiler:Using injective.cpu for add based on highest priority (10)\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |    192 |\n",
      "|    5 |            - |              - |    192 |\n",
      "|    6 |            - |              - |    128 |\n",
      "|    7 |            - |              - |    128 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 61\tUsed time : 150 s\tNext ID: 5\t\n",
      "Tuning time: 154.56919646263123s\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!! EVALUATING         !!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "10 warmup, 100 repeats for evalution\n",
      "Time (ms): {'mean': 1.4711199700832367, 'median': 1.5679040225222707, 'std': 0.3729912707795653}\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/tvm && srun -p PLDI main.sh cpu --tune --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2756e2",
   "metadata": {},
   "source": [
    "#### GPU\n",
    "pre-tune schedule: `~/TVM_pretune/subdivnet/ansor.gpu.2021-11-18.14-35-56.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43464c9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:autotvm:Download pre-tuned parameters package from https://raw.githubusercontent.com/tlc-pack/tophub/main/tophub/cuda_v0.10.log\n",
      "INFO:download:Downloading from url https://raw.githubusercontent.com/tlc-pack/tophub/main/tophub/cuda_v0.10.log to /home/pldi22_ae/.tvm/tophub/cuda_v0.10.log\n",
      "...100%, 0.47 MB, 1 KB/s, 252 seconds passedDEBUG:download:BUG:download:DEBUG:download:DEBUG:download:DEBUG:download:DEBUG:download:DEBUG:download:DEBUG:download:DEBUG:download:DEBUG:download:DEBUG:download:DEBUG:download:\n",
      "DEBUG:autotvm:Finish loading 825 records\n",
      "INFO:te_compiler:Using injective.cuda for zeros based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for adv_index based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using matmul_cublas.cuda for nn.matmul based on highest priority (25)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(matmul_cublas, 0x7f1a081735d0)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using matmul_cublas.cuda for nn.matmul based on highest priority (25)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(matmul_cublas, 0x7f1a0819a810)\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 4.57\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 9.16\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 13.70\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 18.22\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 22.78\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 23.70\n",
      "GA Iter: 0\tMax score: 0.3033\tMin score: 0.3033\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9412\tMin score: 0.0100\t#Pop: 16\t#M+: 1379\t#M-: 153\n",
      "EvolutionarySearch\t\t#s: 16\tTime elapsed: 2.65\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 16 programs to measure:\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!! TUNING             !!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "#Tuning trials 8000\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |      0 |\n",
      "|    1 |            - |              - |      0 |\n",
      "|    2 |            - |              - |      0 |\n",
      "|    3 |            - |              - |      0 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 0\tUsed time : 0 s\tNext ID: 0\t\n",
      ".E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E\n",
      "==================================================\n",
      "No: 1\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,159744)\n",
      "  T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 2\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,9984)\n",
      "  threadIdx.x ax0@ax1@.1 (0,16)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 3\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,26624)\n",
      "  threadIdx.x ax0@ax1@.1 (0,6)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 4\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,12288)\n",
      "  threadIdx.x ax0@ax1@.1 (0,13)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 5\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6656)\n",
      "  threadIdx.x ax0@ax1@.1 (0,24)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 6\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,79872)\n",
      "  threadIdx.x ax0@ax1@.1 (0,2)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 7\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,19968)\n",
      "  threadIdx.x ax0@ax1@.1 (0,8)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 8\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,2496)\n",
      "  threadIdx.x ax0@ax1@.1 (0,64)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 9\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,13312)\n",
      "  threadIdx.x ax0@ax1@.1 (0,12)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 10\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4992)\n",
      "  threadIdx.x ax0@ax1@.1 (0,32)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 11\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3072)\n",
      "  threadIdx.x ax0@ax1@.1 (0,52)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 12\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6144)\n",
      "  threadIdx.x ax0@ax1@.1 (0,26)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 13\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3328)\n",
      "  threadIdx.x ax0@ax1@.1 (0,48)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 14\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,53248)\n",
      "  threadIdx.x ax0@ax1@.1 (0,3)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 15\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4096)\n",
      "  threadIdx.x ax0@ax1@.1 (0,39)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 16\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231010.94)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,39936)\n",
      "  threadIdx.x ax0@ax1@.1 (0,4)\n",
      "    T_add = ...\n",
      "\n",
      "Time elapsed for measurement: 0.06 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pldi22_ae/.local/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.405882\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000012\n",
      "DEBUG:auto_scheduler:XGB iter: 100\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000000\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [66] tr-a-peak@32:1.00000\ttr-p-rmse:0.00000 \n",
      "Time elapsed for training: 0.17 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 1.81\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 3.58\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 5.57\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 7.37\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 9.07\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 9.42\n",
      "GA Iter: 0\tMax score: 0.6070\tMin score: 0.6070\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9188\tMin score: 0.0325\t#Pop: 16\t#M+: 1375\t#M-: 144\n",
      "EvolutionarySearch\t\t#s: 16\tTime elapsed: 1.25\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 16 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |      0 |\n",
      "|    2 |            - |              - |      0 |\n",
      "|    3 |            - |              - |      0 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 16\tUsed time : 27 s\tNext ID: 1\t\n",
      ".E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E\n",
      "==================================================\n",
      "No: 17\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,12288)\n",
      "  threadIdx.x ax0@ax1@.1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 18\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6144)\n",
      "  threadIdx.x ax0@ax1@.1 (0,26)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 19\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,159744)\n",
      "  T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 20\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,39936)\n",
      "  threadIdx.x ax0@ax1@.1 (0,4)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 21\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,9984)\n",
      "  threadIdx.x ax0@ax1@.1 (0,16)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 22\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,79872)\n",
      "  threadIdx.x ax0@ax1@.1 (0,2)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 23\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4992)\n",
      "  threadIdx.x ax0@ax1@.1 (0,32)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 24\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3072)\n",
      "  threadIdx.x ax0@ax1@.1 (0,52)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 25\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,26624)\n",
      "  threadIdx.x ax0@ax1@.1 (0,6)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 26\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3328)\n",
      "  threadIdx.x ax0@ax1@.1 (0,48)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 27\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,2496)\n",
      "  threadIdx.x ax0@ax1@.1 (0,64)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 28\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,19968)\n",
      "  threadIdx.x ax0@ax1@.1 (0,8)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 29\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,13312)\n",
      "  threadIdx.x ax0@ax1@.1 (0,12)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 30\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,53248)\n",
      "  threadIdx.x ax0@ax1@.1 (0,3)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 31\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6656)\n",
      "  threadIdx.x ax0@ax1@.1 (0,24)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 32\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231021.83)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4096)\n",
      "  threadIdx.x ax0@ax1@.1 (0,39)\n",
      "    T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.03 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.403030\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000008\n",
      "DEBUG:auto_scheduler:XGB iter: 100\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000000\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [64] tr-a-peak@32:1.00000\ttr-p-rmse:0.00000 \n",
      "Time elapsed for training: 0.12 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 1.80\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 3.55\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 5.47\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 7.44\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 9.46\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 9.84\n",
      "GA Iter: 0\tMax score: 0.4298\tMin score: 0.4298\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9866\tMin score: 0.1092\t#Pop: 16\t#M+: 1374\t#M-: 157\n",
      "EvolutionarySearch\t\t#s: 16\tTime elapsed: 1.40\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 16 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |      0 |\n",
      "|    3 |            - |              - |      0 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 32\tUsed time : 38 s\tNext ID: 2\t\n",
      ".E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E\n",
      "==================================================\n",
      "No: 33\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,159744)\n",
      "  T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 34\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,79872)\n",
      "  threadIdx.x ax0@ax1@.1 (0,2)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 35\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6144)\n",
      "  threadIdx.x ax0@ax1@.1 (0,26)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 36\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6656)\n",
      "  threadIdx.x ax0@ax1@.1 (0,24)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 37\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4096)\n",
      "  threadIdx.x ax0@ax1@.1 (0,39)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 38\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,2496)\n",
      "  threadIdx.x ax0@ax1@.1 (0,64)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 39\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,19968)\n",
      "  threadIdx.x ax0@ax1@.1 (0,8)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 40\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,26624)\n",
      "  threadIdx.x ax0@ax1@.1 (0,6)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 41\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4992)\n",
      "  threadIdx.x ax0@ax1@.1 (0,32)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 42\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,12288)\n",
      "  threadIdx.x ax0@ax1@.1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 43\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,13312)\n",
      "  threadIdx.x ax0@ax1@.1 (0,12)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 44\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3328)\n",
      "  threadIdx.x ax0@ax1@.1 (0,48)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 45\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.22)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,9984)\n",
      "  threadIdx.x ax0@ax1@.1 (0,16)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 46\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.23)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,53248)\n",
      "  threadIdx.x ax0@ax1@.1 (0,3)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 47\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.23)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,39936)\n",
      "  threadIdx.x ax0@ax1@.1 (0,4)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 48\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231033.23)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3072)\n",
      "  threadIdx.x ax0@ax1@.1 (0,52)\n",
      "    T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.03 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.402041\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000007\n",
      "DEBUG:auto_scheduler:XGB iter: 100\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000000\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [64] tr-a-peak@32:1.00000\ttr-p-rmse:0.00000 \n",
      "Time elapsed for training: 0.13 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 1.08\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 2.22\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 3.32\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 4.48\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 5.61\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 5.82\n",
      "GA Iter: 0\tMax score: 0.6982\tMin score: 0.6982\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9077\tMin score: 0.0171\t#Pop: 16\t#M+: 1371\t#M-: 152\n",
      "EvolutionarySearch\t\t#s: 16\tTime elapsed: 0.79\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 16 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |      0 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 48\tUsed time : 49 s\tNext ID: 3\t\n",
      ".E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E\n",
      "==================================================\n",
      "No: 49\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,26624)\n",
      "  threadIdx.x ax0@ax1@.1 (0,6)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 50\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,6144)\n",
      "  threadIdx.x ax0@ax1@.1 (0,26)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 51\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,9984)\n",
      "  threadIdx.x ax0@ax1@.1 (0,16)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 52\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,4992)\n",
      "  threadIdx.x ax0@ax1@.1 (0,32)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 53\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,3072)\n",
      "  threadIdx.x ax0@ax1@.1 (0,52)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 54\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,2496)\n",
      "  threadIdx.x ax0@ax1@.1 (0,64)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 55\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,53248)\n",
      "  threadIdx.x ax0@ax1@.1 (0,3)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 56\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,19968)\n",
      "  threadIdx.x ax0@ax1@.1 (0,8)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 57\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,12288)\n",
      "  threadIdx.x ax0@ax1@.1 (0,13)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 58\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,4096)\n",
      "  threadIdx.x ax0@ax1@.1 (0,39)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 59\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,39936)\n",
      "  threadIdx.x ax0@ax1@.1 (0,4)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 60\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,6656)\n",
      "  threadIdx.x ax0@ax1@.1 (0,24)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 61\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,159744)\n",
      "  T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 62\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,3328)\n",
      "  threadIdx.x ax0@ax1@.1 (0,48)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 63\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,79872)\n",
      "  threadIdx.x ax0@ax1@.1 (0,2)\n",
      "    T_full = ...\n",
      "\n",
      "==================================================\n",
      "No: 64\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231040.01)\n",
      "==================================================\n",
      "Placeholder: \n",
      "blockIdx.x ax0@ax1@.0 (0,13312)\n",
      "  threadIdx.x ax0@ax1@.1 (0,12)\n",
      "    T_full = ...\n",
      "\n",
      "Time elapsed for measurement: 0.03 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.401538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000007\n",
      "DEBUG:auto_scheduler:XGB iter: 100\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000000\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [62] tr-a-peak@32:1.00000\ttr-p-rmse:0.00000 \n",
      "Time elapsed for training: 0.12 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 1.81\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 3.67\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 5.42\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 7.36\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 9.28\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 9.67\n",
      "GA Iter: 0\tMax score: 0.5161\tMin score: 0.5161\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.8761\tMin score: 0.0371\t#Pop: 16\t#M+: 1352\t#M-: 151\n",
      "EvolutionarySearch\t\t#s: 16\tTime elapsed: 1.30\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 16 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |      0 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 64\tUsed time : 56 s\tNext ID: 4\t\n",
      ".E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E\n",
      "==================================================\n",
      "No: 65\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,39936)\n",
      "  threadIdx.x ax0@ax1@.1 (0,4)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 66\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,13312)\n",
      "  threadIdx.x ax0@ax1@.1 (0,12)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 67\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3328)\n",
      "  threadIdx.x ax0@ax1@.1 (0,48)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 68\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6656)\n",
      "  threadIdx.x ax0@ax1@.1 (0,24)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 69\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,159744)\n",
      "  T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 70\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4992)\n",
      "  threadIdx.x ax0@ax1@.1 (0,32)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 71\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4096)\n",
      "  threadIdx.x ax0@ax1@.1 (0,39)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 72\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,19968)\n",
      "  threadIdx.x ax0@ax1@.1 (0,8)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 73\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,12288)\n",
      "  threadIdx.x ax0@ax1@.1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 74\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3072)\n",
      "  threadIdx.x ax0@ax1@.1 (0,52)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 75\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,53248)\n",
      "  threadIdx.x ax0@ax1@.1 (0,3)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 76\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,2496)\n",
      "  threadIdx.x ax0@ax1@.1 (0,64)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 77\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6144)\n",
      "  threadIdx.x ax0@ax1@.1 (0,26)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 78\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,26624)\n",
      "  threadIdx.x ax0@ax1@.1 (0,6)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 79\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,9984)\n",
      "  threadIdx.x ax0@ax1@.1 (0,16)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 80\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231051.15)\n",
      "==================================================\n",
      "Placeholder: placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,79872)\n",
      "  threadIdx.x ax0@ax1@.1 (0,2)\n",
      "    T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.03 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.401235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000007\n",
      "DEBUG:auto_scheduler:XGB iter: 100\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000000\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [62] tr-a-peak@32:1.00000\ttr-p-rmse:0.00000 \n",
      "Time elapsed for training: 0.13 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 4.31\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 8.55\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 13.01\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 17.39\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 21.76\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 22.57\n",
      "GA Iter: 0\tMax score: 0.8840\tMin score: 0.8840\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9827\tMin score: 0.1619\t#Pop: 19\t#M+: 1364\t#M-: 138\n",
      "EvolutionarySearch\t\t#s: 19\tTime elapsed: 3.23\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 19 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |      0 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 80\tUsed time : 67 s\tNext ID: 5\t\n",
      ".E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E\n",
      "==================================================\n",
      "No: 81\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,29952)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,16)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 82\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,79872)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,6)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 83\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,239616)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,2)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 84\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,159744)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,3)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 85\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,14976)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,32)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 86\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,36864)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,13)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 87\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,26624)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,18)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 88\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,39936)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,12)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 89\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,18432)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,26)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 90\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,9984)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,48)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 91\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,479232)\n",
      "  T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 92\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,12288)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,39)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 93\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,9216)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,52)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 94\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,119808)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,4)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 95\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,7488)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,64)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 96\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,13312)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,36)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 97\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,59904)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,8)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 98\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,53248)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,9)\n",
      "    T_reshape = ...\n",
      "\n",
      "==================================================\n",
      "No: 99\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231077.15)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@ax2@.0 (0,19968)\n",
      "  threadIdx.x ax0@ax1@ax2@.1 (0,24)\n",
      "    T_reshape = ...\n",
      "\n",
      "Time elapsed for measurement: 0.06 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.401000\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000006\n",
      "DEBUG:auto_scheduler:XGB iter: 100\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000000\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [62] tr-a-peak@32:1.00000\ttr-p-rmse:0.00000 \n",
      "Time elapsed for training: 0.17 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 2.35\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 4.75\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 7.07\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 9.50\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 11.79\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 12.31\n",
      "GA Iter: 0\tMax score: 0.7867\tMin score: 0.7867\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9935\tMin score: 0.0022\t#Pop: 16\t#M+: 1366\t#M-: 160\n",
      "EvolutionarySearch\t\t#s: 16\tTime elapsed: 1.58\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 16 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |      0 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 99\tUsed time : 93 s\tNext ID: 6\t\n",
      ".E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E\n",
      "==================================================\n",
      "No: 100\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,26624)\n",
      "  threadIdx.x ax0@ax1@.1 (0,6)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 101\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,39936)\n",
      "  threadIdx.x ax0@ax1@.1 (0,4)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 102\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,79872)\n",
      "  threadIdx.x ax0@ax1@.1 (0,2)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 103\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4992)\n",
      "  threadIdx.x ax0@ax1@.1 (0,32)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 104\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,53248)\n",
      "  threadIdx.x ax0@ax1@.1 (0,3)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 105\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3328)\n",
      "  threadIdx.x ax0@ax1@.1 (0,48)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 106\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,12288)\n",
      "  threadIdx.x ax0@ax1@.1 (0,13)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 107\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,2496)\n",
      "  threadIdx.x ax0@ax1@.1 (0,64)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 108\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6656)\n",
      "  threadIdx.x ax0@ax1@.1 (0,24)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 109\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,159744)\n",
      "  T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 110\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,13312)\n",
      "  threadIdx.x ax0@ax1@.1 (0,12)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 111\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4096)\n",
      "  threadIdx.x ax0@ax1@.1 (0,39)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 112\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,9984)\n",
      "  threadIdx.x ax0@ax1@.1 (0,16)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 113\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6144)\n",
      "  threadIdx.x ax0@ax1@.1 (0,26)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 114\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3072)\n",
      "  threadIdx.x ax0@ax1@.1 (0,52)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 115\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231091.24)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,19968)\n",
      "  threadIdx.x ax0@ax1@.1 (0,8)\n",
      "    T_add = ...\n",
      "\n",
      "Time elapsed for measurement: 0.03 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.400862\n",
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000006\n",
      "DEBUG:auto_scheduler:XGB iter: 100\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000000\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [62] tr-a-peak@32:1.00000\ttr-p-rmse:0.00000 \n",
      "Time elapsed for training: 0.18 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 1\n",
      "Sample Iter: 5\t#Pop: 1\t#Target: 50\tfail_ct: 10239\tTime elapsed: 4.54\n",
      "#Target has been reduced to 25 due to too many failures or duplications\n",
      "Sample Iter: 10\t#Pop: 1\t#Target: 25\tfail_ct: 20479\tTime elapsed: 9.10\n",
      "#Target has been reduced to 12 due to too many failures or duplications\n",
      "Sample Iter: 15\t#Pop: 1\t#Target: 12\tfail_ct: 30719\tTime elapsed: 13.57\n",
      "#Target has been reduced to 6 due to too many failures or duplications\n",
      "Sample Iter: 20\t#Pop: 1\t#Target: 6\tfail_ct: 40959\tTime elapsed: 18.10\n",
      "#Target has been reduced to 3 due to too many failures or duplications\n",
      "Sample Iter: 25\t#Pop: 1\t#Target: 3\tfail_ct: 51199\tTime elapsed: 22.64\n",
      "#Target has been reduced to 1 due to too many failures or duplications\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 53247\tTime elapsed: 23.55\n",
      "GA Iter: 0\tMax score: 0.2595\tMin score: 0.2595\t#Pop: 1\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9791\tMin score: 0.0270\t#Pop: 16\t#M+: 1371\t#M-: 155\n",
      "EvolutionarySearch\t\t#s: 16\tTime elapsed: 2.62\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 16 programs to measure:\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |      0 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 115\tUsed time : 107 s\tNext ID: 7\t\n",
      ".E.E.E.E.E.E.E.E.E.E.E.E.E.E.E.E\n",
      "==================================================\n",
      "No: 116\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,13312)\n",
      "  threadIdx.x ax0@ax1@.1 (0,12)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 117\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6656)\n",
      "  threadIdx.x ax0@ax1@.1 (0,24)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 118\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,26624)\n",
      "  threadIdx.x ax0@ax1@.1 (0,6)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 119\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3072)\n",
      "  threadIdx.x ax0@ax1@.1 (0,52)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 120\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,12288)\n",
      "  threadIdx.x ax0@ax1@.1 (0,13)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 121\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,3328)\n",
      "  threadIdx.x ax0@ax1@.1 (0,48)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 122\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,39936)\n",
      "  threadIdx.x ax0@ax1@.1 (0,4)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 123\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,6144)\n",
      "  threadIdx.x ax0@ax1@.1 (0,26)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 124\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4992)\n",
      "  threadIdx.x ax0@ax1@.1 (0,32)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 125\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,4096)\n",
      "  threadIdx.x ax0@ax1@.1 (0,39)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 126\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,2496)\n",
      "  threadIdx.x ax0@ax1@.1 (0,64)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 127\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,9984)\n",
      "  threadIdx.x ax0@ax1@.1 (0,16)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 128\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,79872)\n",
      "  threadIdx.x ax0@ax1@.1 (0,2)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 129\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,19968)\n",
      "  threadIdx.x ax0@ax1@.1 (0,8)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 130\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,53248)\n",
      "  threadIdx.x ax0@ax1@.1 (0,3)\n",
      "    T_add = ...\n",
      "\n",
      "==================================================\n",
      "No: 131\tGFLOPS: 0.00 / 0.00\tresults: MeasureResult(error_type:CompileHostError, error_msg:ModuleNotFoundError(\"No module named 'cloudpickle'\"), all_cost:15.00, Tstamp:1646231117.65)\n",
      "==================================================\n",
      "Placeholder: placeholder, placeholder, placeholder, placeholder, placeholder\n",
      "blockIdx.x ax0@ax1@.0 (0,159744)\n",
      "  T_add = ...\n",
      "\n",
      "Time elapsed for measurement: 0.04 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "DEBUG:auto_scheduler:XGB iter:   0\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.400758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:auto_scheduler:XGB iter:  50\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000006\n",
      "DEBUG:auto_scheduler:XGB iter: 100\ttr-a-peak@32: 1.000000\ttr-p-rmse: 0.000000\n",
      "DEBUG:auto_scheduler:XGB stopped. Best iteration: [62] tr-a-peak@32:1.00000\ttr-p-rmse:0.00000 \n",
      "Time elapsed for training: 0.18 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.24\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 1368\t#M-: 151\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 0.82\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.95\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 1383\t#M-: 149\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 2.72\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.38\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 1367\t#M-: 160\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 1.29\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.36\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 1387\t#M-: 148\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 1.28\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.35\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 1380\t#M-: 163\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 1.30\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.89\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 1361\t#M-: 150\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 3.19\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.46\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 1374\t#M-: 153\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 1.60\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Task Scheduler ]\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Initial Population\t#s: 1\tfail_ct: 2047\tTime elapsed: 0.91\n",
      "GA Iter: 0\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: N/A\tMin score: N/A\t#Pop: 0\t#M+: 1381\t#M-: 161\n",
      "EvolutionarySearch\t\t#s: 0\tTime elapsed: 2.67\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 0 programs to measure:\n",
      "Time elapsed for measurement: 0.00 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Train cost model ]\n",
      "----------------------------------------------------------------------\n",
      "Time elapsed for training: 0.00 s\n",
      "DEBUG:auto_scheduler:Finish loading 131 records\n",
      "DEBUG:autotvm:Finish loading 825 records\n",
      "INFO:te_compiler:Using matmul_cublas.cuda for nn.matmul based on highest priority (25)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(matmul_cublas, 0x308bcc0)\n",
      "INFO:te_compiler:Using matmul_cublas.cuda for nn.matmul based on highest priority (25)\n",
      "INFO:auto_scheduler:Failed to create a ComputeDAG for auto_scheduler: Traceback (most recent call last):\n",
      "  4: TVMFuncCall\n",
      "  3: std::_Function_handler<void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::TypedPackedFunc<tvm::auto_scheduler::ComputeDAG (tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)>::AssignTypedLambda<tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}>(tvm::auto_scheduler::{lambda(tvm::runtime::Optional<tvm::runtime::Array<tvm::te::Tensor, void> >, tvm::runtime::Optional<tvm::te::Schedule>)#4}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}>::_M_invoke(std::_Any_data const&, tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&)\n",
      "  2: tvm::auto_scheduler::ComputeDAG::ComputeDAG(tvm::runtime::Array<tvm::te::Tensor, void>)\n",
      "  1: tvm::auto_scheduler::AccessAnalyzer::AccessAnalyzer(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  0: tvm::auto_scheduler::TopoSortOps(tvm::runtime::Array<tvm::te::Tensor, void> const&)\n",
      "  File \"/home/zhenly/App/tvm-211104/src/auto_scheduler/compute_dag.cc\", line 97\n",
      "TVMError: Unsupported op extern(matmul_cublas, 0x33df530)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for zeros based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for adv_index based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for strided_slice based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for reshape based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for subtract based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for abs based on highest priority (10)\n",
      "INFO:te_compiler:Using injective.cuda for add based on highest priority (10)\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |     64 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 131\tUsed time : 134 s\tNext ID: 3\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |     64 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 131\tUsed time : 135 s\tNext ID: 0\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |     64 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 131\tUsed time : 138 s\tNext ID: 1\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |     64 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 131\tUsed time : 140 s\tNext ID: 2\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |     64 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 131\tUsed time : 142 s\tNext ID: 4\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |    128 |\n",
      "|    5 |            - |              - |     64 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 131\tUsed time : 143 s\tNext ID: 5\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |    128 |\n",
      "|    5 |            - |              - |    128 |\n",
      "|    6 |            - |              - |     64 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 131\tUsed time : 148 s\tNext ID: 6\t\n",
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |            - |              - |    128 |\n",
      "|    1 |            - |              - |    128 |\n",
      "|    2 |            - |              - |    128 |\n",
      "|    3 |            - |              - |    128 |\n",
      "|    4 |            - |              - |    128 |\n",
      "|    5 |            - |              - |    128 |\n",
      "|    6 |            - |              - |    128 |\n",
      "|    7 |            - |              - |     64 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: - ms\tTrials: 131\tUsed time : 150 s\tNext ID: 7\t\n",
      "Tuning time: 153.17070627212524s\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!! EVALUATING         !!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "10 warmup, 100 repeats for evalution\n",
      "Time (ms): {'mean': 0.07716990308836102, 'median': 0.07656507659703493, 'std': 0.0032747886257332654}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\r\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/tvm && srun -p PLDI main.sh gpu --tune --warmup-repeat 10 --timing-repeat 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e66652",
   "metadata": {},
   "source": [
    "### Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef137c",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dad5dde",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100repeats for evalution\n",
      "Inference Time = 9.33748075 ms\n",
      "Done\n",
      "10 warmup, 100repeats for evalution\n",
      "Forward Time = 14.46729384 ms\n",
      "Done\n",
      "10 warmup, 100repeats for evalution\n",
      "Backward Time = 18.1738049 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/julia && srun -p PLDI main.sh cpu Inf 10 100 && echo \"Done\"\n",
    "!cd subdivnet/julia && srun -p PLDI main.sh cpu For 10 100 && echo \"Done\"\n",
    "!cd subdivnet/julia && srun -p PLDI main.sh cpu Bac 10 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b654122",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45d41840",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 warmup, 100repeats for evalution\n",
      "Inference Time = 0.47977002 ms\n",
      "Done\n",
      "10 warmup, 100repeats for evalution\n",
      "Forward Time = 1.54585167 ms\n",
      "Done\n",
      "10 warmup, 100repeats for evalution\n",
      "Backward Time = 0.92146392 ms\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/julia && srun -p PLDI main.sh gpu Inf 10 100 && echo \"Done\"\n",
    "!cd subdivnet/julia && srun -p PLDI main.sh gpu For 10 100 && echo \"Done\"\n",
    "!cd subdivnet/julia && srun -p PLDI main.sh gpu Bac 10 100 && echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773db1f",
   "metadata": {},
   "source": [
    "### Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7064bdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing y\n",
      "Comparing d_x\n",
      "Comparing d_w0\n",
      "Comparing d_w1\n",
      "Comparing d_w2\n",
      "Comparing d_w3\n",
      "All output matches\n",
      "Comparing y\n",
      "Comparing d_x\n",
      "Comparing d_w0\n",
      "Comparing d_w1\n",
      "Comparing d_w2\n",
      "Comparing d_w3\n",
      "All output matches\n",
      "Comparing y\n",
      "Comparing d_x\n",
      "Comparing d_w0\n",
      "Comparing d_w1\n",
      "Comparing d_w2\n",
      "Comparing d_w3\n",
      "All output matches\n",
      "Comparing y\n",
      "Comparing d_x\n",
      "Comparing d_w0\n",
      "Comparing d_w1\n",
      "Comparing d_w2\n",
      "Comparing d_w3\n",
      "All output matches\n",
      "Comparing y\n",
      "All output matches\n",
      "Comparing y\n",
      "Comparing d_x\n",
      "Comparing d_w0\n",
      "Comparing d_w1\n",
      "Comparing d_w2\n",
      "Comparing d_w3\n",
      "All output matches\n"
     ]
    }
   ],
   "source": [
    "!cd subdivnet/ && python compare.py ours pytorch_impl1\n",
    "!cd subdivnet/ && python compare.py ours pytorch_impl2\n",
    "!cd subdivnet/ && python compare.py ours jax_impl1\n",
    "!cd subdivnet/ && python compare.py ours jax_impl2\n",
    "!cd subdivnet/ && python compare.py ours tvm --infer-only\n",
    "!cd subdivnet/ && python compare.py ours julia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
